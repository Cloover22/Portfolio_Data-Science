{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902b0eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "# 전처리 모듈\n",
    "from preprocess import SV10Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2230c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 57.06it/s]\n"
     ]
    }
   ],
   "source": [
    "all_csv = ['/STORAGE/SHARE/seokho/SV10_배포용/지도학습/Train_Data/여수_total_real_maritime_trials_final.csv',\n",
    " '/STORAGE/SHARE/seokho/SV10_배포용/지도학습/Train_Data/영흥도_total_real_maritime_trials_final.csv']\n",
    "\n",
    "total = pd.DataFrame()\n",
    "\n",
    "for csv in tqdm(all_csv):\n",
    "    temp = pd.read_csv(csv, sep = ',', encoding = 'utf-8')\n",
    "    total = pd.concat([total, temp])\n",
    "    total.reset_index(inplace = True)\n",
    "    total.drop(labels = 'index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30698357",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = SV10Preprocess()\n",
    "total = preprocess.ecs_add_feature(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a32843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>szMsgSendDT</th>\n",
       "      <th>szMsgSeq</th>\n",
       "      <th>os_SHIP_CODE</th>\n",
       "      <th>os_dSOG</th>\n",
       "      <th>os_dCOG</th>\n",
       "      <th>os_dLat</th>\n",
       "      <th>os_dLon</th>\n",
       "      <th>dOsCPADist</th>\n",
       "      <th>dOsCPALat</th>\n",
       "      <th>dOsCPALon</th>\n",
       "      <th>...</th>\n",
       "      <th>szMessage</th>\n",
       "      <th>dRisk</th>\n",
       "      <th>dLat</th>\n",
       "      <th>dLon</th>\n",
       "      <th>dDCPA</th>\n",
       "      <th>dTCPA</th>\n",
       "      <th>lVulCnt</th>\n",
       "      <th>ANSWER</th>\n",
       "      <th>RNG</th>\n",
       "      <th>MaxRisk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.022103e+16</td>\n",
       "      <td>34601.0</td>\n",
       "      <td>TZ010f20</td>\n",
       "      <td>10.4</td>\n",
       "      <td>121.2</td>\n",
       "      <td>34.702265</td>\n",
       "      <td>127.801563</td>\n",
       "      <td>1.343333</td>\n",
       "      <td>34.690467</td>\n",
       "      <td>127.825150</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 12시 방향 2.86마일에서 선박이 11.7노트의 속도로 접근 중입니다.</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.689661</td>\n",
       "      <td>127.824396</td>\n",
       "      <td>0.122197</td>\n",
       "      <td>7.757654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.859705</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.022103e+16</td>\n",
       "      <td>34602.0</td>\n",
       "      <td>TZ010f1e</td>\n",
       "      <td>11.4</td>\n",
       "      <td>314.4</td>\n",
       "      <td>34.670835</td>\n",
       "      <td>127.844853</td>\n",
       "      <td>1.485167</td>\n",
       "      <td>34.688154</td>\n",
       "      <td>127.823445</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 12시 방향 2.83마일에서 선박이 10.4노트의 속도로 접근 중입니다.</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.689248</td>\n",
       "      <td>127.824422</td>\n",
       "      <td>0.163090</td>\n",
       "      <td>7.830188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.830856</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.022103e+16</td>\n",
       "      <td>34603.0</td>\n",
       "      <td>TZ010f20</td>\n",
       "      <td>11.5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>34.702172</td>\n",
       "      <td>127.801785</td>\n",
       "      <td>1.434306</td>\n",
       "      <td>34.691126</td>\n",
       "      <td>127.828034</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 12시 방향 2.83마일에서 선박이 11.0노트의 속도로 접근 중입니다.</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.688548</td>\n",
       "      <td>127.825942</td>\n",
       "      <td>0.372302</td>\n",
       "      <td>7.484357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.834945</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.022103e+16</td>\n",
       "      <td>34604.0</td>\n",
       "      <td>TZ010f1e</td>\n",
       "      <td>10.8</td>\n",
       "      <td>309.6</td>\n",
       "      <td>34.670972</td>\n",
       "      <td>127.844662</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>34.685250</td>\n",
       "      <td>127.823769</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 12시 방향 2.80마일에서 선박이 11.6노트의 속도로 접근 중입니다.</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.687594</td>\n",
       "      <td>127.825658</td>\n",
       "      <td>0.337835</td>\n",
       "      <td>7.481323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.803469</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.022103e+16</td>\n",
       "      <td>34606.0</td>\n",
       "      <td>TZ010f20</td>\n",
       "      <td>11.2</td>\n",
       "      <td>129.8</td>\n",
       "      <td>34.701988</td>\n",
       "      <td>127.802102</td>\n",
       "      <td>1.347111</td>\n",
       "      <td>34.687351</td>\n",
       "      <td>127.823372</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 12시 방향 2.80마일에서 선박이 11.8노트의 속도로 접근 중입니다.</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.686446</td>\n",
       "      <td>127.822531</td>\n",
       "      <td>0.136890</td>\n",
       "      <td>7.223421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.796682</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11854</th>\n",
       "      <td>2.022093e+16</td>\n",
       "      <td>83925.0</td>\n",
       "      <td>TZ010f1e</td>\n",
       "      <td>5.7</td>\n",
       "      <td>47.1</td>\n",
       "      <td>37.215032</td>\n",
       "      <td>126.474068</td>\n",
       "      <td>0.026917</td>\n",
       "      <td>37.215337</td>\n",
       "      <td>126.474479</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 4시 방향 0.03마일에서 선박이 11.4노트의 속도로 접근 중입니다.</td>\n",
       "      <td>93.0</td>\n",
       "      <td>37.215287</td>\n",
       "      <td>126.474656</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.289492</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11855</th>\n",
       "      <td>2.022093e+16</td>\n",
       "      <td>83926.0</td>\n",
       "      <td>TZ010f1f</td>\n",
       "      <td>11.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>37.214515</td>\n",
       "      <td>126.474280</td>\n",
       "      <td>0.044722</td>\n",
       "      <td>37.215218</td>\n",
       "      <td>126.474882</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 10시 방향 0.03마일에서 선박이 6.1노트의 속도로 접근 중입니다.</td>\n",
       "      <td>93.0</td>\n",
       "      <td>37.215276</td>\n",
       "      <td>126.474705</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.248733</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11856</th>\n",
       "      <td>2.022093e+16</td>\n",
       "      <td>83927.0</td>\n",
       "      <td>TZ010f1e</td>\n",
       "      <td>6.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>37.215118</td>\n",
       "      <td>126.474200</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>37.215328</td>\n",
       "      <td>126.474533</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 3시 방향 0.03마일에서 선박이 11.5노트의 속도로 접근 중입니다.</td>\n",
       "      <td>93.0</td>\n",
       "      <td>37.215269</td>\n",
       "      <td>126.474715</td>\n",
       "      <td>0.018811</td>\n",
       "      <td>0.212481</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.028127</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11857</th>\n",
       "      <td>2.022093e+16</td>\n",
       "      <td>83929.0</td>\n",
       "      <td>TZ010f1f</td>\n",
       "      <td>11.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.214760</td>\n",
       "      <td>126.474528</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>37.215032</td>\n",
       "      <td>126.474835</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 10시 방향 0.03마일에서 선박이 5.6노트의 속도로 접근 중입니다.</td>\n",
       "      <td>93.0</td>\n",
       "      <td>37.215140</td>\n",
       "      <td>126.474621</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>0.083391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027244</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11858</th>\n",
       "      <td>2.022093e+16</td>\n",
       "      <td>83930.0</td>\n",
       "      <td>TZ010f1e</td>\n",
       "      <td>5.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>37.215200</td>\n",
       "      <td>126.474327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.215200</td>\n",
       "      <td>126.474327</td>\n",
       "      <td>...</td>\n",
       "      <td>진행방향으로부터 3시 방향 0.02마일에서 선박이 11.5노트의 속도로 접근 중입니다.</td>\n",
       "      <td>93.0</td>\n",
       "      <td>37.215059</td>\n",
       "      <td>126.474517</td>\n",
       "      <td>0.024844</td>\n",
       "      <td>0.013140</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024882</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11859 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        szMsgSendDT  szMsgSeq os_SHIP_CODE  os_dSOG  os_dCOG    os_dLat  \\\n",
       "0      2.022103e+16   34601.0     TZ010f20     10.4    121.2  34.702265   \n",
       "1      2.022103e+16   34602.0     TZ010f1e     11.4    314.4  34.670835   \n",
       "2      2.022103e+16   34603.0     TZ010f20     11.5    117.0  34.702172   \n",
       "3      2.022103e+16   34604.0     TZ010f1e     10.8    309.6  34.670972   \n",
       "4      2.022103e+16   34606.0     TZ010f20     11.2    129.8  34.701988   \n",
       "...             ...       ...          ...      ...      ...        ...   \n",
       "11854  2.022093e+16   83925.0     TZ010f1e      5.7     47.1  37.215032   \n",
       "11855  2.022093e+16   83926.0     TZ010f1f     11.5     34.4  37.214515   \n",
       "11856  2.022093e+16   83927.0     TZ010f1e      6.1     51.8  37.215118   \n",
       "11857  2.022093e+16   83929.0     TZ010f1f     11.3     42.0  37.214760   \n",
       "11858  2.022093e+16   83930.0     TZ010f1e      5.2     45.9  37.215200   \n",
       "\n",
       "          os_dLon  dOsCPADist  dOsCPALat   dOsCPALon  ...  \\\n",
       "0      127.801563    1.343333  34.690467  127.825150  ...   \n",
       "1      127.844853    1.485167  34.688154  127.823445  ...   \n",
       "2      127.801785    1.434306  34.691126  127.828034  ...   \n",
       "3      127.844662    1.344000  34.685250  127.823769  ...   \n",
       "4      127.802102    1.347111  34.687351  127.823372  ...   \n",
       "...           ...         ...        ...         ...  ...   \n",
       "11854  126.474068    0.026917  37.215337  126.474479  ...   \n",
       "11855  126.474280    0.044722  37.215218  126.474882  ...   \n",
       "11856  126.474200    0.020333  37.215328  126.474533  ...   \n",
       "11857  126.474528    0.015694  37.215032  126.474835  ...   \n",
       "11858  126.474327    0.000000  37.215200  126.474327  ...   \n",
       "\n",
       "                                               szMessage dRisk       dLat  \\\n",
       "0      진행방향으로부터 12시 방향 2.86마일에서 선박이 11.7노트의 속도로 접근 중입니다.  86.0  34.689661   \n",
       "1      진행방향으로부터 12시 방향 2.83마일에서 선박이 10.4노트의 속도로 접근 중입니다.  86.0  34.689248   \n",
       "2      진행방향으로부터 12시 방향 2.83마일에서 선박이 11.0노트의 속도로 접근 중입니다.  86.0  34.688548   \n",
       "3      진행방향으로부터 12시 방향 2.80마일에서 선박이 11.6노트의 속도로 접근 중입니다.  86.0  34.687594   \n",
       "4      진행방향으로부터 12시 방향 2.80마일에서 선박이 11.8노트의 속도로 접근 중입니다.  86.0  34.686446   \n",
       "...                                                  ...   ...        ...   \n",
       "11854   진행방향으로부터 4시 방향 0.03마일에서 선박이 11.4노트의 속도로 접근 중입니다.  93.0  37.215287   \n",
       "11855   진행방향으로부터 10시 방향 0.03마일에서 선박이 6.1노트의 속도로 접근 중입니다.  93.0  37.215276   \n",
       "11856   진행방향으로부터 3시 방향 0.03마일에서 선박이 11.5노트의 속도로 접근 중입니다.  93.0  37.215269   \n",
       "11857   진행방향으로부터 10시 방향 0.03마일에서 선박이 5.6노트의 속도로 접근 중입니다.  93.0  37.215140   \n",
       "11858   진행방향으로부터 3시 방향 0.02마일에서 선박이 11.5노트의 속도로 접근 중입니다.  93.0  37.215059   \n",
       "\n",
       "             dLon     dDCPA     dTCPA  lVulCnt  ANSWER       RNG  MaxRisk  \n",
       "0      127.824396  0.122197  7.757654      1.0       0  2.859705     44.0  \n",
       "1      127.824422  0.163090  7.830188      1.0       0  2.830856     44.0  \n",
       "2      127.825942  0.372302  7.484357      0.0       0  2.834945     43.0  \n",
       "3      127.825658  0.337835  7.481323      0.0       0  2.803469     44.0  \n",
       "4      127.822531  0.136890  7.223421      0.0       0  2.796682     44.0  \n",
       "...           ...       ...       ...      ...     ...       ...      ...  \n",
       "11854  126.474656  0.017955  0.289492      2.0       3  0.034437     93.0  \n",
       "11855  126.474705  0.018265  0.248733      2.0       3  0.034710     93.0  \n",
       "11856  126.474715  0.018811  0.212481      2.0       3  0.028127     93.0  \n",
       "11857  126.474621  0.024219  0.083391      2.0       3  0.027244     93.0  \n",
       "11858  126.474517  0.024844  0.013140      2.0       3  0.024882     93.0  \n",
       "\n",
       "[11859 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecs = total\n",
    "ecs.loc[ecs['MaxRisk'] == 0, 'ANSWER'] = 0    # 오류값 전처리\n",
    "ecs = ecs.drop_duplicates()  # 오류값 전처리 하면 중복값 생김\n",
    "ecs.reset_index(drop = True, inplace = True)\n",
    "ecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe5ceb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [03:29<00:00,  4.19s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Not random , Sequential\n",
    "'''\n",
    "all_csv = glob('/STORAGE/DATA/01_KRISO_G_MAPPED_DATA/CollisionAlarm/*.csv')\n",
    "\n",
    "selected_csv = all_csv[:50]\n",
    "\n",
    "total_ = pd.DataFrame()\n",
    "\n",
    "\n",
    "for csv in tqdm(selected_csv):\n",
    "    temp = pd.read_csv(csv, sep = ',', encoding = 'utf-8')\n",
    "    total_ = pd.concat([total_, temp])\n",
    "    \n",
    "total_.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "concat 데이터 load\n",
    "'''\n",
    "all_csv = glob('/STORAGE/SHARE/Intern/jjlee/SV10/Tabnet/concat/*.csv')\n",
    "\n",
    "total_ = pd.DataFrame()\n",
    "\n",
    "for csv in tqdm(all_csv):\n",
    "    temp = pd.read_csv(csv, sep = ',', encoding = 'utf-8')\n",
    "    total_ = pd.concat([total_, temp])\n",
    " \n",
    "total_.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "total_.reset_index(drop = True, inplace = True)\n",
    "total_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8094ecb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing HO 10045 : END\n",
      "Data preprocessing CR 20291 : END\n",
      "Data preprocessing OT 1585 : END\n",
      "Data Classify: END\n",
      "Match Port Polygon: END\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>szMsgSendDT</th>\n",
       "      <th>szMsgSeq</th>\n",
       "      <th>os_SHIP_CODE</th>\n",
       "      <th>os_dSOG</th>\n",
       "      <th>os_dCOG</th>\n",
       "      <th>os_dLat</th>\n",
       "      <th>os_dLon</th>\n",
       "      <th>dOsCPADist</th>\n",
       "      <th>dOsCPALat</th>\n",
       "      <th>dOsCPALon</th>\n",
       "      <th>...</th>\n",
       "      <th>dRisk</th>\n",
       "      <th>dLat</th>\n",
       "      <th>dLon</th>\n",
       "      <th>dDCPA</th>\n",
       "      <th>dTCPA</th>\n",
       "      <th>lVulCnt</th>\n",
       "      <th>RNG</th>\n",
       "      <th>MaxRisk</th>\n",
       "      <th>isinPort1</th>\n",
       "      <th>isinPort2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220629083622382</td>\n",
       "      <td>38954</td>\n",
       "      <td>AB0102a4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>133.0</td>\n",
       "      <td>34.304360</td>\n",
       "      <td>126.797020</td>\n",
       "      <td>1.597056</td>\n",
       "      <td>34.286207</td>\n",
       "      <td>126.820476</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.285771</td>\n",
       "      <td>126.820812</td>\n",
       "      <td>0.062045</td>\n",
       "      <td>10.771757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220629083626515</td>\n",
       "      <td>39338</td>\n",
       "      <td>AB0102a4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>132.0</td>\n",
       "      <td>34.304257</td>\n",
       "      <td>126.797165</td>\n",
       "      <td>1.597056</td>\n",
       "      <td>34.286207</td>\n",
       "      <td>126.820476</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.285771</td>\n",
       "      <td>126.820812</td>\n",
       "      <td>0.062045</td>\n",
       "      <td>10.771757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220629083632553</td>\n",
       "      <td>39907</td>\n",
       "      <td>AB0102a4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>129.0</td>\n",
       "      <td>34.304097</td>\n",
       "      <td>126.797402</td>\n",
       "      <td>0.543889</td>\n",
       "      <td>34.298392</td>\n",
       "      <td>126.805891</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.297932</td>\n",
       "      <td>126.806394</td>\n",
       "      <td>0.074551</td>\n",
       "      <td>3.669288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220629083639686</td>\n",
       "      <td>40556</td>\n",
       "      <td>AB0102a4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>131.0</td>\n",
       "      <td>34.303902</td>\n",
       "      <td>126.797653</td>\n",
       "      <td>0.543889</td>\n",
       "      <td>34.298392</td>\n",
       "      <td>126.805891</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.297932</td>\n",
       "      <td>126.806394</td>\n",
       "      <td>0.074551</td>\n",
       "      <td>3.669288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086014</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220629083646634</td>\n",
       "      <td>41157</td>\n",
       "      <td>AB0102a4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>34.303703</td>\n",
       "      <td>126.797897</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>34.295803</td>\n",
       "      <td>126.808848</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.295355</td>\n",
       "      <td>126.809208</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>4.828227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098437</td>\n",
       "      <td>69.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25417</th>\n",
       "      <td>20230406181815603</td>\n",
       "      <td>20356</td>\n",
       "      <td>AB0907c6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.441678</td>\n",
       "      <td>126.522740</td>\n",
       "      <td>0.087808</td>\n",
       "      <td>3.661734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259428</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25418</th>\n",
       "      <td>20230406181818597</td>\n",
       "      <td>20755</td>\n",
       "      <td>AB0907c6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.441678</td>\n",
       "      <td>126.522740</td>\n",
       "      <td>0.087808</td>\n",
       "      <td>3.661734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259428</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25419</th>\n",
       "      <td>20230406181821575</td>\n",
       "      <td>21133</td>\n",
       "      <td>AB0907c6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.441678</td>\n",
       "      <td>126.522740</td>\n",
       "      <td>0.087808</td>\n",
       "      <td>3.661734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259428</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25420</th>\n",
       "      <td>20230406181824724</td>\n",
       "      <td>21544</td>\n",
       "      <td>AB0907c6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.441678</td>\n",
       "      <td>126.522740</td>\n",
       "      <td>0.087808</td>\n",
       "      <td>3.661734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259428</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25421</th>\n",
       "      <td>20230406181827719</td>\n",
       "      <td>21951</td>\n",
       "      <td>AB0907c6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.442383</td>\n",
       "      <td>126.522498</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.441678</td>\n",
       "      <td>126.522740</td>\n",
       "      <td>0.087808</td>\n",
       "      <td>3.661734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259428</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25422 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             szMsgSendDT  szMsgSeq os_SHIP_CODE  os_dSOG  os_dCOG    os_dLat  \\\n",
       "0      20220629083622382     38954     AB0102a4      8.9    133.0  34.304360   \n",
       "1      20220629083626515     39338     AB0102a4      8.8    132.0  34.304257   \n",
       "2      20220629083632553     39907     AB0102a4      8.9    129.0  34.304097   \n",
       "3      20220629083639686     40556     AB0102a4      8.9    131.0  34.303902   \n",
       "4      20220629083646634     41157     AB0102a4      9.0    131.0  34.303703   \n",
       "...                  ...       ...          ...      ...      ...        ...   \n",
       "25417  20230406181815603     20356     AB0907c6      0.0    249.0  36.442383   \n",
       "25418  20230406181818597     20755     AB0907c6      0.0    249.0  36.442383   \n",
       "25419  20230406181821575     21133     AB0907c6      0.0    249.0  36.442383   \n",
       "25420  20230406181824724     21544     AB0907c6      0.0    249.0  36.442383   \n",
       "25421  20230406181827719     21951     AB0907c6      0.0    249.0  36.442383   \n",
       "\n",
       "          os_dLon  dOsCPADist  dOsCPALat   dOsCPALon  ...  dRisk       dLat  \\\n",
       "0      126.797020    1.597056  34.286207  126.820476  ...   86.0  34.285771   \n",
       "1      126.797165    1.597056  34.286207  126.820476  ...   86.0  34.285771   \n",
       "2      126.797402    0.543889  34.298392  126.805891  ...   86.0  34.297932   \n",
       "3      126.797653    0.543889  34.298392  126.805891  ...   86.0  34.297932   \n",
       "4      126.797897    0.722500  34.295803  126.808848  ...   86.0  34.295355   \n",
       "...           ...         ...        ...         ...  ...    ...        ...   \n",
       "25417  126.522498    0.000000  36.442383  126.522498  ...   86.0  36.441678   \n",
       "25418  126.522498    0.000000  36.442383  126.522498  ...   86.0  36.441678   \n",
       "25419  126.522498    0.000000  36.442383  126.522498  ...   86.0  36.441678   \n",
       "25420  126.522498    0.000000  36.442383  126.522498  ...   86.0  36.441678   \n",
       "25421  126.522498    0.000000  36.442383  126.522498  ...   86.0  36.441678   \n",
       "\n",
       "             dLon     dDCPA      dTCPA  lVulCnt       RNG  MaxRisk  isinPort1  \\\n",
       "0      126.820812  0.062045  10.771757        0  0.100991      0.0      False   \n",
       "1      126.820812  0.062045  10.771757        0  0.093390      0.0      False   \n",
       "2      126.806394  0.074551   3.669288        0  0.099188     75.0      False   \n",
       "3      126.806394  0.074551   3.669288        0  0.086014     75.0      False   \n",
       "4      126.809208  0.064652   4.828227        0  0.098437     69.0      False   \n",
       "...           ...       ...        ...      ...       ...      ...        ...   \n",
       "25417  126.522740  0.087808   3.661734        0  0.259428     81.0      False   \n",
       "25418  126.522740  0.087808   3.661734        0  0.259428     81.0      False   \n",
       "25419  126.522740  0.087808   3.661734        0  0.259428     81.0      False   \n",
       "25420  126.522740  0.087808   3.661734        0  0.259428     81.0      False   \n",
       "25421  126.522740  0.087808   3.661734        0  0.259428     81.0      False   \n",
       "\n",
       "       isinPort2  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "25417      False  \n",
       "25418      False  \n",
       "25419      False  \n",
       "25420      False  \n",
       "25421      False  \n",
       "\n",
       "[25422 rows x 36 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = SV10Preprocess()\n",
    "\n",
    "total_.drop_duplicates(inplace = True)\n",
    "# 전처리 1\n",
    "set_features = preprocess._set_features(total_)\n",
    "# 전처리 2\n",
    "a_ship = set_features[set_features.os_SHIP_CODE.str.startswith('A') & set_features.st_SHIP_CODE.str.startswith('A')]\n",
    "# 전처리 3\n",
    "classify = preprocess._classify_Sp_ST(a_ship)\n",
    "# 전처리 4\n",
    "final = preprocess._isin_Port_Return(classify)\n",
    "\n",
    "# SV10 전처리 객체지향을 통해서 오직 해상 위에서 충돌에 대한 데이터만 가져온 최종 데이터 프레임이다.\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bfe8219b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>szMsgSendDT</th>\n",
       "      <th>szMsgSeq</th>\n",
       "      <th>os_SHIP_CODE</th>\n",
       "      <th>os_dSOG</th>\n",
       "      <th>os_dCOG</th>\n",
       "      <th>os_dLat</th>\n",
       "      <th>os_dLon</th>\n",
       "      <th>dOsCPADist</th>\n",
       "      <th>dOsCPALat</th>\n",
       "      <th>dOsCPALon</th>\n",
       "      <th>...</th>\n",
       "      <th>dRisk</th>\n",
       "      <th>dLat</th>\n",
       "      <th>dLon</th>\n",
       "      <th>dDCPA</th>\n",
       "      <th>dTCPA</th>\n",
       "      <th>lVulCnt</th>\n",
       "      <th>RNG</th>\n",
       "      <th>MaxRisk</th>\n",
       "      <th>isinPort1</th>\n",
       "      <th>isinPort2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220630100615355</td>\n",
       "      <td>5778</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>7.3</td>\n",
       "      <td>292.0</td>\n",
       "      <td>36.920582</td>\n",
       "      <td>125.790435</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>36.922607</td>\n",
       "      <td>125.784190</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.922062</td>\n",
       "      <td>125.784581</td>\n",
       "      <td>0.075520</td>\n",
       "      <td>2.667009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100338</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220630100621696</td>\n",
       "      <td>6255</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>6.3</td>\n",
       "      <td>290.0</td>\n",
       "      <td>36.920655</td>\n",
       "      <td>125.790215</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>36.922151</td>\n",
       "      <td>125.785095</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.921815</td>\n",
       "      <td>125.785126</td>\n",
       "      <td>0.040439</td>\n",
       "      <td>2.500303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220630100628590</td>\n",
       "      <td>6779</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>7.7</td>\n",
       "      <td>288.0</td>\n",
       "      <td>36.920727</td>\n",
       "      <td>125.789925</td>\n",
       "      <td>0.594611</td>\n",
       "      <td>36.923789</td>\n",
       "      <td>125.778186</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.923257</td>\n",
       "      <td>125.778536</td>\n",
       "      <td>0.072179</td>\n",
       "      <td>4.645560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096586</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220630100634550</td>\n",
       "      <td>7275</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>6.4</td>\n",
       "      <td>286.0</td>\n",
       "      <td>36.920788</td>\n",
       "      <td>125.789703</td>\n",
       "      <td>0.302222</td>\n",
       "      <td>36.922177</td>\n",
       "      <td>125.783673</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.921980</td>\n",
       "      <td>125.783649</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>2.849741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094155</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220630100640649</td>\n",
       "      <td>7729</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>7.2</td>\n",
       "      <td>279.0</td>\n",
       "      <td>36.920833</td>\n",
       "      <td>125.789452</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>36.922095</td>\n",
       "      <td>125.779528</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.922300</td>\n",
       "      <td>125.779765</td>\n",
       "      <td>0.033460</td>\n",
       "      <td>4.042677</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092713</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>20230214063533543</td>\n",
       "      <td>73398</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580418</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580418</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580436</td>\n",
       "      <td>128.555126</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.528939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131048</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>20230214063540590</td>\n",
       "      <td>74079</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>34.580450</td>\n",
       "      <td>128.554973</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.408212</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103146</td>\n",
       "      <td>91.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>20230214063547634</td>\n",
       "      <td>74755</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580429</td>\n",
       "      <td>128.555117</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.445943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082082</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>20230214063553705</td>\n",
       "      <td>75330</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580426</td>\n",
       "      <td>128.555084</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.355907</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13244</th>\n",
       "      <td>20230214063559958</td>\n",
       "      <td>75963</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580428</td>\n",
       "      <td>128.555044</td>\n",
       "      <td>0.020621</td>\n",
       "      <td>0.316888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13245 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             szMsgSendDT  szMsgSeq os_SHIP_CODE  os_dSOG  os_dCOG    os_dLat  \\\n",
       "0      20220630100615355      5778     AB110bdb      7.3    292.0  36.920582   \n",
       "1      20220630100621696      6255     AB110bdb      6.3    290.0  36.920655   \n",
       "2      20220630100628590      6779     AB110bdb      7.7    288.0  36.920727   \n",
       "3      20220630100634550      7275     AB110bdb      6.4    286.0  36.920788   \n",
       "4      20220630100640649      7729     AB110bdb      7.2    279.0  36.920833   \n",
       "...                  ...       ...          ...      ...      ...        ...   \n",
       "13240  20230214063533543     73398     AB020455      0.0      0.0  34.580418   \n",
       "13241  20230214063540590     74079     AB020455      0.0      0.0  34.580422   \n",
       "13242  20230214063547634     74755     AB020455      0.0      0.0  34.580422   \n",
       "13243  20230214063553705     75330     AB020455      0.0      0.0  34.580422   \n",
       "13244  20230214063559958     75963     AB020455      0.0      0.0  34.580422   \n",
       "\n",
       "          os_dLon  dOsCPADist  dOsCPALat   dOsCPALon  ...  dRisk       dLat  \\\n",
       "0      125.790435    0.324444  36.922607  125.784190  ...   86.0  36.922062   \n",
       "1      125.790215    0.262500  36.922151  125.785095  ...   86.0  36.921815   \n",
       "2      125.789925    0.594611  36.923789  125.778186  ...   86.0  36.923257   \n",
       "3      125.789703    0.302222  36.922177  125.783673  ...   86.0  36.921980   \n",
       "4      125.789452    0.484000  36.922095  125.779528  ...   86.0  36.922300   \n",
       "...           ...         ...        ...         ...  ...    ...        ...   \n",
       "13240  128.555252    0.000000  34.580418  128.555252  ...   92.0  34.580436   \n",
       "13241  128.555252    0.000000  34.580422  128.555252  ...   91.0  34.580450   \n",
       "13242  128.555252    0.000000  34.580422  128.555252  ...   92.0  34.580429   \n",
       "13243  128.555252    0.000000  34.580422  128.555252  ...   92.0  34.580426   \n",
       "13244  128.555252    0.000000  34.580422  128.555252  ...   92.0  34.580428   \n",
       "\n",
       "             dLon     dDCPA     dTCPA  lVulCnt       RNG  MaxRisk  isinPort1  \\\n",
       "0      125.784581  0.075520  2.667009        1  0.100338     77.0      False   \n",
       "1      125.785126  0.040439  2.500303        0  0.098029     79.0      False   \n",
       "2      125.778536  0.072179  4.645560        0  0.096586     72.0      False   \n",
       "3      125.783649  0.023678  2.849741        0  0.094155     77.0      False   \n",
       "4      125.779765  0.033460  4.042677        0  0.092713     75.0      False   \n",
       "...           ...       ...       ...      ...       ...      ...        ...   \n",
       "13240  128.555126  0.012272  0.528939        1  0.131048     92.0      False   \n",
       "13241  128.554973  0.027791  0.408212        1  0.103146     91.0      False   \n",
       "13242  128.555117  0.013205  0.445943        1  0.082082     92.0      False   \n",
       "13243  128.555084  0.016653  0.355907        1  0.065045     92.0      False   \n",
       "13244  128.555044  0.020621  0.316888        1  0.049882     92.0      False   \n",
       "\n",
       "       isinPort2  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "13240      False  \n",
       "13241      False  \n",
       "13242      False  \n",
       "13243      False  \n",
       "13244      False  \n",
       "\n",
       "[13245 rows x 36 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "비지도\n",
    "'''\n",
    "#final = pd.read_csv('0_50.csv')\n",
    "#final = pd.read_csv('50_100.csv')\n",
    "final = pd.read_csv('100_150.csv')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "57d6c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>szMsgSendDT</th>\n",
       "      <th>szMsgSeq</th>\n",
       "      <th>os_SHIP_CODE</th>\n",
       "      <th>os_dSOG</th>\n",
       "      <th>os_dCOG</th>\n",
       "      <th>os_dLat</th>\n",
       "      <th>os_dLon</th>\n",
       "      <th>dOsCPADist</th>\n",
       "      <th>dOsCPALat</th>\n",
       "      <th>dOsCPALon</th>\n",
       "      <th>...</th>\n",
       "      <th>dRisk</th>\n",
       "      <th>dLat</th>\n",
       "      <th>dLon</th>\n",
       "      <th>dDCPA</th>\n",
       "      <th>dTCPA</th>\n",
       "      <th>lVulCnt</th>\n",
       "      <th>RNG</th>\n",
       "      <th>MaxRisk</th>\n",
       "      <th>isinPort1</th>\n",
       "      <th>isinPort2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220630100615355</td>\n",
       "      <td>5778</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>7.3</td>\n",
       "      <td>292.0</td>\n",
       "      <td>36.920582</td>\n",
       "      <td>125.790435</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>36.922607</td>\n",
       "      <td>125.784190</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.922062</td>\n",
       "      <td>125.784581</td>\n",
       "      <td>0.075520</td>\n",
       "      <td>2.667009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100338</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220630100621696</td>\n",
       "      <td>6255</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>6.3</td>\n",
       "      <td>290.0</td>\n",
       "      <td>36.920655</td>\n",
       "      <td>125.790215</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>36.922151</td>\n",
       "      <td>125.785095</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.921815</td>\n",
       "      <td>125.785126</td>\n",
       "      <td>0.040439</td>\n",
       "      <td>2.500303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220630100628590</td>\n",
       "      <td>6779</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>7.7</td>\n",
       "      <td>288.0</td>\n",
       "      <td>36.920727</td>\n",
       "      <td>125.789925</td>\n",
       "      <td>0.594611</td>\n",
       "      <td>36.923789</td>\n",
       "      <td>125.778186</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.923257</td>\n",
       "      <td>125.778536</td>\n",
       "      <td>0.072179</td>\n",
       "      <td>4.645560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096586</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220630100634550</td>\n",
       "      <td>7275</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>6.4</td>\n",
       "      <td>286.0</td>\n",
       "      <td>36.920788</td>\n",
       "      <td>125.789703</td>\n",
       "      <td>0.302222</td>\n",
       "      <td>36.922177</td>\n",
       "      <td>125.783673</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.921980</td>\n",
       "      <td>125.783649</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>2.849741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094155</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20220630100640649</td>\n",
       "      <td>7729</td>\n",
       "      <td>AB110bdb</td>\n",
       "      <td>7.2</td>\n",
       "      <td>279.0</td>\n",
       "      <td>36.920833</td>\n",
       "      <td>125.789452</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>36.922095</td>\n",
       "      <td>125.779528</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.922300</td>\n",
       "      <td>125.779765</td>\n",
       "      <td>0.033460</td>\n",
       "      <td>4.042677</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092713</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>20230214063533543</td>\n",
       "      <td>73398</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580418</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580418</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580436</td>\n",
       "      <td>128.555126</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.528939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131048</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>20230214063540590</td>\n",
       "      <td>74079</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>34.580450</td>\n",
       "      <td>128.554973</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.408212</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103146</td>\n",
       "      <td>91.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>20230214063547634</td>\n",
       "      <td>74755</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580429</td>\n",
       "      <td>128.555117</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.445943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082082</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>20230214063553705</td>\n",
       "      <td>75330</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580426</td>\n",
       "      <td>128.555084</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.355907</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13244</th>\n",
       "      <td>20230214063559958</td>\n",
       "      <td>75963</td>\n",
       "      <td>AB020455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.580422</td>\n",
       "      <td>128.555252</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.580428</td>\n",
       "      <td>128.555044</td>\n",
       "      <td>0.020621</td>\n",
       "      <td>0.316888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13245 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             szMsgSendDT  szMsgSeq os_SHIP_CODE  os_dSOG  os_dCOG    os_dLat  \\\n",
       "0      20220630100615355      5778     AB110bdb      7.3    292.0  36.920582   \n",
       "1      20220630100621696      6255     AB110bdb      6.3    290.0  36.920655   \n",
       "2      20220630100628590      6779     AB110bdb      7.7    288.0  36.920727   \n",
       "3      20220630100634550      7275     AB110bdb      6.4    286.0  36.920788   \n",
       "4      20220630100640649      7729     AB110bdb      7.2    279.0  36.920833   \n",
       "...                  ...       ...          ...      ...      ...        ...   \n",
       "13240  20230214063533543     73398     AB020455      0.0      0.0  34.580418   \n",
       "13241  20230214063540590     74079     AB020455      0.0      0.0  34.580422   \n",
       "13242  20230214063547634     74755     AB020455      0.0      0.0  34.580422   \n",
       "13243  20230214063553705     75330     AB020455      0.0      0.0  34.580422   \n",
       "13244  20230214063559958     75963     AB020455      0.0      0.0  34.580422   \n",
       "\n",
       "          os_dLon  dOsCPADist  dOsCPALat   dOsCPALon  ...  dRisk       dLat  \\\n",
       "0      125.790435    0.324444  36.922607  125.784190  ...   86.0  36.922062   \n",
       "1      125.790215    0.262500  36.922151  125.785095  ...   86.0  36.921815   \n",
       "2      125.789925    0.594611  36.923789  125.778186  ...   86.0  36.923257   \n",
       "3      125.789703    0.302222  36.922177  125.783673  ...   86.0  36.921980   \n",
       "4      125.789452    0.484000  36.922095  125.779528  ...   86.0  36.922300   \n",
       "...           ...         ...        ...         ...  ...    ...        ...   \n",
       "13240  128.555252    0.000000  34.580418  128.555252  ...   92.0  34.580436   \n",
       "13241  128.555252    0.000000  34.580422  128.555252  ...   91.0  34.580450   \n",
       "13242  128.555252    0.000000  34.580422  128.555252  ...   92.0  34.580429   \n",
       "13243  128.555252    0.000000  34.580422  128.555252  ...   92.0  34.580426   \n",
       "13244  128.555252    0.000000  34.580422  128.555252  ...   92.0  34.580428   \n",
       "\n",
       "             dLon     dDCPA     dTCPA  lVulCnt       RNG  MaxRisk  isinPort1  \\\n",
       "0      125.784581  0.075520  2.667009        1  0.100338     77.0      False   \n",
       "1      125.785126  0.040439  2.500303        0  0.098029     79.0      False   \n",
       "2      125.778536  0.072179  4.645560        0  0.096586     72.0      False   \n",
       "3      125.783649  0.023678  2.849741        0  0.094155     77.0      False   \n",
       "4      125.779765  0.033460  4.042677        0  0.092713     75.0      False   \n",
       "...           ...       ...       ...      ...       ...      ...        ...   \n",
       "13240  128.555126  0.012272  0.528939        1  0.131048     92.0      False   \n",
       "13241  128.554973  0.027791  0.408212        1  0.103146     91.0      False   \n",
       "13242  128.555117  0.013205  0.445943        1  0.082082     92.0      False   \n",
       "13243  128.555084  0.016653  0.355907        1  0.065045     92.0      False   \n",
       "13244  128.555044  0.020621  0.316888        1  0.049882     92.0      False   \n",
       "\n",
       "       isinPort2  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "13240      False  \n",
       "13241      False  \n",
       "13242      False  \n",
       "13243      False  \n",
       "13244      False  \n",
       "\n",
       "[13245 rows x 36 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collison = copy.deepcopy(final)\n",
    "collison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f67a760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "위치 경도 좌표 제거 o \n",
    "'''\n",
    "# 비지도 학습 전 전처리 (dtype object remove)\n",
    "sample_size = round(len(ecs) * 0.5)  # 2:1 비율\n",
    "x_train = collison.sample(n = sample_size, random_state = 42)\n",
    "\n",
    "# collison feature 선별\n",
    "x_train = x_train[['dOsCPADist','dTsCPADist', 'dOsRisk', 'dTsRisk',\n",
    "                 'izCategory','dDCPA', 'dTCPA', 'RNG', 'MaxRisk']]\n",
    "x_train.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09dd9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "coli_x_train, coli_x_val = train_test_split(x_train, test_size = 0.2)\n",
    "coli_x_train = coli_x_train.values\n",
    "coli_x_val = coli_x_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c40a4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.02352 | val_0_unsup_loss_numpy: 299.5007019042969|  0:00:00s\n",
      "epoch 1  | loss: 1.86102 | val_0_unsup_loss_numpy: 12.507490158081055|  0:00:00s\n",
      "epoch 2  | loss: 1.67321 | val_0_unsup_loss_numpy: 2.030210018157959|  0:00:00s\n",
      "epoch 3  | loss: 1.49051 | val_0_unsup_loss_numpy: 1.4044300317764282|  0:00:00s\n",
      "epoch 4  | loss: 1.32542 | val_0_unsup_loss_numpy: 1.1342999935150146|  0:00:00s\n",
      "epoch 5  | loss: 1.11897 | val_0_unsup_loss_numpy: 1.035230040550232|  0:00:01s\n",
      "epoch 6  | loss: 0.95718 | val_0_unsup_loss_numpy: 0.8552299737930298|  0:00:01s\n",
      "epoch 7  | loss: 0.86607 | val_0_unsup_loss_numpy: 0.7294300198554993|  0:00:01s\n",
      "epoch 8  | loss: 0.81229 | val_0_unsup_loss_numpy: 0.64656001329422|  0:00:01s\n",
      "epoch 9  | loss: 0.788   | val_0_unsup_loss_numpy: 0.667639970779419|  0:00:01s\n",
      "epoch 10 | loss: 0.77808 | val_0_unsup_loss_numpy: 0.6343799829483032|  0:00:01s\n",
      "epoch 11 | loss: 0.76944 | val_0_unsup_loss_numpy: 0.6381499767303467|  0:00:02s\n",
      "epoch 12 | loss: 0.76804 | val_0_unsup_loss_numpy: 0.6406400203704834|  0:00:02s\n",
      "epoch 13 | loss: 0.7585  | val_0_unsup_loss_numpy: 0.6265400052070618|  0:00:02s\n",
      "epoch 14 | loss: 0.748   | val_0_unsup_loss_numpy: 0.5962799787521362|  0:00:02s\n",
      "epoch 15 | loss: 0.74093 | val_0_unsup_loss_numpy: 0.6076200008392334|  0:00:02s\n",
      "epoch 16 | loss: 0.74155 | val_0_unsup_loss_numpy: 0.5945500135421753|  0:00:03s\n",
      "epoch 17 | loss: 0.71841 | val_0_unsup_loss_numpy: 0.5819100141525269|  0:00:03s\n",
      "epoch 18 | loss: 0.71881 | val_0_unsup_loss_numpy: 0.5631999969482422|  0:00:03s\n",
      "epoch 19 | loss: 0.71524 | val_0_unsup_loss_numpy: 0.6147300004959106|  0:00:03s\n",
      "epoch 20 | loss: 0.71213 | val_0_unsup_loss_numpy: 0.6136800050735474|  0:00:03s\n",
      "epoch 21 | loss: 0.70538 | val_0_unsup_loss_numpy: 0.5791299939155579|  0:00:03s\n",
      "epoch 22 | loss: 0.70664 | val_0_unsup_loss_numpy: 0.5551300048828125|  0:00:04s\n",
      "epoch 23 | loss: 0.73174 | val_0_unsup_loss_numpy: 0.6000099778175354|  0:00:04s\n",
      "epoch 24 | loss: 0.73307 | val_0_unsup_loss_numpy: 0.5646799802780151|  0:00:04s\n",
      "epoch 25 | loss: 0.73125 | val_0_unsup_loss_numpy: 0.5700200200080872|  0:00:04s\n",
      "epoch 26 | loss: 0.73462 | val_0_unsup_loss_numpy: 0.523169994354248|  0:00:04s\n",
      "epoch 27 | loss: 0.72243 | val_0_unsup_loss_numpy: 0.5436199903488159|  0:00:05s\n",
      "epoch 28 | loss: 0.71576 | val_0_unsup_loss_numpy: 0.5771700143814087|  0:00:05s\n",
      "epoch 29 | loss: 0.71593 | val_0_unsup_loss_numpy: 0.5507000088691711|  0:00:05s\n",
      "epoch 30 | loss: 0.70625 | val_0_unsup_loss_numpy: 0.514739990234375|  0:00:05s\n",
      "epoch 31 | loss: 0.68969 | val_0_unsup_loss_numpy: 0.5379499793052673|  0:00:05s\n",
      "epoch 32 | loss: 0.69558 | val_0_unsup_loss_numpy: 0.5644299983978271|  0:00:05s\n",
      "epoch 33 | loss: 0.69464 | val_0_unsup_loss_numpy: 0.6209400296211243|  0:00:06s\n",
      "epoch 34 | loss: 0.68328 | val_0_unsup_loss_numpy: 0.586080014705658|  0:00:06s\n",
      "epoch 35 | loss: 0.68579 | val_0_unsup_loss_numpy: 0.5731199979782104|  0:00:06s\n",
      "epoch 36 | loss: 0.68712 | val_0_unsup_loss_numpy: 0.5248100161552429|  0:00:06s\n",
      "epoch 37 | loss: 0.67912 | val_0_unsup_loss_numpy: 0.5538899898529053|  0:00:06s\n",
      "epoch 38 | loss: 0.68524 | val_0_unsup_loss_numpy: 0.5539900064468384|  0:00:06s\n",
      "epoch 39 | loss: 0.67981 | val_0_unsup_loss_numpy: 0.5698000192642212|  0:00:07s\n",
      "epoch 40 | loss: 0.68245 | val_0_unsup_loss_numpy: 0.5228899717330933|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_unsup_loss_numpy = 0.514739990234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# 비지도\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=coli_x_train,\n",
    "    eval_set = [coli_x_val],\n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=100 , patience=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59e022",
   "metadata": {},
   "source": [
    "# Supervised Learning(Tabnet) with ECS (Labeled)\n",
    "## 지도 학습만 수행하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3987198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지도 전처리\n",
    "ecs = ecs[['dOsCPADist','dTsCPADist', 'dOsRisk', 'dTsRisk',\n",
    "                 'izCategory','dDCPA', 'dTCPA', 'RNG', 'MaxRisk', 'ANSWER']]\n",
    "# ecs.reset_index(drop = True, inplace = True)\n",
    "y = ecs['ANSWER']\n",
    "train_ecs = ecs.drop(['ANSWER'], axis = 1) # ecs 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1a411c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11859, 9)\n",
      "(11859,)\n"
     ]
    }
   ],
   "source": [
    "print(train_ecs.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04151111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 train data set:  (9487, 9) (9487,)\n",
      "SMOTE 적용 후 train data set:  (14700, 9) (14700,)\n",
      "SMOTE 적용 후 label 값 분포: \n",
      " 3    3675\n",
      "0    3675\n",
      "1    3675\n",
      "2    3675\n",
      "Name: ANSWER, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_ecs, y,\n",
    "                                                    test_size=0.2, random_state = 1234)\n",
    "# 학습 데이터 불균형 처리\n",
    "def SMOTE(X, y, strategy = 'auto'):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote = SMOTE(sampling_strategy= strategy)\n",
    "    X_smote, y_smote = smote.fit_resample(X, y)\n",
    "    print('SMOTE 적용 전 train data set: ', X.shape, y.shape)\n",
    "    print('SMOTE 적용 후 train data set: ', X_smote.shape, y_smote.shape)\n",
    "    print('SMOTE 적용 후 label 값 분포: \\n', pd.Series(y_smote).value_counts())\n",
    "    return X_smote, y_smote\n",
    "x_train, y_train = SMOTE(x_train,y_train)\n",
    "\n",
    "#### Test / Validation\n",
    "x_test1, x_val, y_test1, y_val = train_test_split(x_test,y_test,\n",
    "                                                  test_size=0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30c2e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "smote 이후 x_train 과 y_train을 합쳐서 무작위로 50%만 추출 하여서\n",
    "x_train_50 / y_train_50 으로 저장 하였음\n",
    "'''\n",
    "x_train['ANSWER'] = y_train\n",
    "\n",
    "sample_size = round(len(x_train) * 0.5)  # 전체 데이터의 70%\n",
    "x_train_50 = x_train.sample(n=sample_size, random_state=42)\n",
    "x_train_50.reset_index(drop = True, inplace = True)\n",
    "\n",
    "y_train_50 = x_train_50['ANSWER']\n",
    "x_train_50 = x_train_50.drop(['ANSWER'], axis = 1)\n",
    "\n",
    "x_train_50 = x_train_50.values\n",
    "y_train_50 = y_train_50.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30a116fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14700, 10)\n",
      "(2372, 9)\n",
      "(14700,)\n",
      "(2372, 9)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x_test 는 test 데이터 셋 고정\n",
    "'''\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67878f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "x_test1 = x_test1.values\n",
    "x_val = x_val.values\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "y_test1 = y_test1.values\n",
    "y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cdd54d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.28486 | train_accuracy: 0.33963 | valid_accuracy: 0.33231 |  0:00:00s\n",
      "epoch 1  | loss: 1.05009 | train_accuracy: 0.18861 | valid_accuracy: 0.19184 |  0:00:00s\n",
      "epoch 2  | loss: 0.97203 | train_accuracy: 0.35153 | valid_accuracy: 0.35748 |  0:00:00s\n",
      "epoch 3  | loss: 0.93223 | train_accuracy: 0.45026 | valid_accuracy: 0.4585  |  0:00:01s\n",
      "epoch 4  | loss: 0.91446 | train_accuracy: 0.45213 | valid_accuracy: 0.45544 |  0:00:01s\n",
      "epoch 5  | loss: 0.88871 | train_accuracy: 0.50391 | valid_accuracy: 0.50986 |  0:00:01s\n",
      "epoch 6  | loss: 0.87    | train_accuracy: 0.47143 | valid_accuracy: 0.47483 |  0:00:01s\n",
      "epoch 7  | loss: 0.86416 | train_accuracy: 0.44532 | valid_accuracy: 0.44252 |  0:00:01s\n",
      "epoch 8  | loss: 0.85529 | train_accuracy: 0.5057  | valid_accuracy: 0.51122 |  0:00:01s\n",
      "epoch 9  | loss: 0.85715 | train_accuracy: 0.475   | valid_accuracy: 0.48537 |  0:00:02s\n",
      "epoch 10 | loss: 0.85753 | train_accuracy: 0.48546 | valid_accuracy: 0.49456 |  0:00:02s\n",
      "epoch 11 | loss: 0.84225 | train_accuracy: 0.53665 | valid_accuracy: 0.52891 |  0:00:02s\n",
      "epoch 12 | loss: 0.82549 | train_accuracy: 0.58503 | valid_accuracy: 0.57789 |  0:00:02s\n",
      "epoch 13 | loss: 0.83803 | train_accuracy: 0.5494  | valid_accuracy: 0.53095 |  0:00:02s\n",
      "epoch 14 | loss: 0.84762 | train_accuracy: 0.5534  | valid_accuracy: 0.55306 |  0:00:03s\n",
      "epoch 15 | loss: 0.8437  | train_accuracy: 0.60289 | valid_accuracy: 0.58878 |  0:00:03s\n",
      "epoch 16 | loss: 0.83542 | train_accuracy: 0.59107 | valid_accuracy: 0.58367 |  0:00:03s\n",
      "epoch 17 | loss: 0.84577 | train_accuracy: 0.60604 | valid_accuracy: 0.6034  |  0:00:03s\n",
      "epoch 18 | loss: 0.84079 | train_accuracy: 0.61318 | valid_accuracy: 0.60442 |  0:00:03s\n",
      "epoch 19 | loss: 0.82606 | train_accuracy: 0.62143 | valid_accuracy: 0.61565 |  0:00:04s\n",
      "epoch 20 | loss: 0.8263  | train_accuracy: 0.6284  | valid_accuracy: 0.62211 |  0:00:04s\n",
      "epoch 21 | loss: 0.81663 | train_accuracy: 0.61173 | valid_accuracy: 0.61156 |  0:00:04s\n",
      "epoch 22 | loss: 0.80923 | train_accuracy: 0.62177 | valid_accuracy: 0.62381 |  0:00:04s\n",
      "epoch 23 | loss: 0.79995 | train_accuracy: 0.61752 | valid_accuracy: 0.61224 |  0:00:04s\n",
      "epoch 24 | loss: 0.80365 | train_accuracy: 0.60876 | valid_accuracy: 0.60782 |  0:00:05s\n",
      "epoch 25 | loss: 0.81427 | train_accuracy: 0.62832 | valid_accuracy: 0.62959 |  0:00:05s\n",
      "epoch 26 | loss: 0.80509 | train_accuracy: 0.62832 | valid_accuracy: 0.62517 |  0:00:05s\n",
      "epoch 27 | loss: 0.79983 | train_accuracy: 0.64167 | valid_accuracy: 0.63299 |  0:00:05s\n",
      "epoch 28 | loss: 0.78913 | train_accuracy: 0.6466  | valid_accuracy: 0.6449  |  0:00:05s\n",
      "epoch 29 | loss: 0.78977 | train_accuracy: 0.63299 | valid_accuracy: 0.62687 |  0:00:05s\n",
      "epoch 30 | loss: 0.78955 | train_accuracy: 0.62772 | valid_accuracy: 0.62653 |  0:00:06s\n",
      "epoch 31 | loss: 0.79599 | train_accuracy: 0.63393 | valid_accuracy: 0.6398  |  0:00:06s\n",
      "epoch 32 | loss: 0.79446 | train_accuracy: 0.64439 | valid_accuracy: 0.63503 |  0:00:06s\n",
      "epoch 33 | loss: 0.78026 | train_accuracy: 0.64889 | valid_accuracy: 0.63673 |  0:00:06s\n",
      "epoch 34 | loss: 0.77318 | train_accuracy: 0.65306 | valid_accuracy: 0.64014 |  0:00:06s\n",
      "epoch 35 | loss: 0.7855  | train_accuracy: 0.64439 | valid_accuracy: 0.63265 |  0:00:07s\n",
      "epoch 36 | loss: 0.77808 | train_accuracy: 0.65017 | valid_accuracy: 0.63469 |  0:00:07s\n",
      "epoch 37 | loss: 0.79385 | train_accuracy: 0.65901 | valid_accuracy: 0.6466  |  0:00:07s\n",
      "epoch 38 | loss: 0.76818 | train_accuracy: 0.67287 | valid_accuracy: 0.65544 |  0:00:07s\n",
      "epoch 39 | loss: 0.76453 | train_accuracy: 0.66233 | valid_accuracy: 0.64966 |  0:00:07s\n",
      "epoch 40 | loss: 0.76634 | train_accuracy: 0.67194 | valid_accuracy: 0.65068 |  0:00:08s\n",
      "epoch 41 | loss: 0.77065 | train_accuracy: 0.66216 | valid_accuracy: 0.65544 |  0:00:08s\n",
      "epoch 42 | loss: 0.76031 | train_accuracy: 0.6682  | valid_accuracy: 0.64762 |  0:00:08s\n",
      "epoch 43 | loss: 0.76176 | train_accuracy: 0.67092 | valid_accuracy: 0.65476 |  0:00:08s\n",
      "epoch 44 | loss: 0.75482 | train_accuracy: 0.67245 | valid_accuracy: 0.65612 |  0:00:08s\n",
      "epoch 45 | loss: 0.76911 | train_accuracy: 0.66335 | valid_accuracy: 0.65816 |  0:00:08s\n",
      "epoch 46 | loss: 0.77225 | train_accuracy: 0.66956 | valid_accuracy: 0.65    |  0:00:09s\n",
      "epoch 47 | loss: 0.76145 | train_accuracy: 0.66633 | valid_accuracy: 0.64966 |  0:00:09s\n",
      "epoch 48 | loss: 0.77082 | train_accuracy: 0.67551 | valid_accuracy: 0.65918 |  0:00:09s\n",
      "epoch 49 | loss: 0.75897 | train_accuracy: 0.67951 | valid_accuracy: 0.65714 |  0:00:09s\n",
      "epoch 50 | loss: 0.74924 | train_accuracy: 0.68121 | valid_accuracy: 0.66293 |  0:00:09s\n",
      "epoch 51 | loss: 0.74821 | train_accuracy: 0.6818  | valid_accuracy: 0.66701 |  0:00:10s\n",
      "epoch 52 | loss: 0.75182 | train_accuracy: 0.67491 | valid_accuracy: 0.65714 |  0:00:10s\n",
      "epoch 53 | loss: 0.75292 | train_accuracy: 0.66922 | valid_accuracy: 0.65408 |  0:00:10s\n",
      "epoch 54 | loss: 0.75798 | train_accuracy: 0.65884 | valid_accuracy: 0.64218 |  0:00:10s\n",
      "epoch 55 | loss: 0.74551 | train_accuracy: 0.67874 | valid_accuracy: 0.66497 |  0:00:10s\n",
      "epoch 56 | loss: 0.73778 | train_accuracy: 0.67985 | valid_accuracy: 0.66599 |  0:00:11s\n",
      "epoch 57 | loss: 0.74444 | train_accuracy: 0.67696 | valid_accuracy: 0.6568  |  0:00:11s\n",
      "epoch 58 | loss: 0.73965 | train_accuracy: 0.68044 | valid_accuracy: 0.66122 |  0:00:11s\n",
      "epoch 59 | loss: 0.73956 | train_accuracy: 0.68648 | valid_accuracy: 0.67075 |  0:00:11s\n",
      "epoch 60 | loss: 0.73568 | train_accuracy: 0.66803 | valid_accuracy: 0.66395 |  0:00:11s\n",
      "epoch 61 | loss: 0.72335 | train_accuracy: 0.66981 | valid_accuracy: 0.65034 |  0:00:11s\n",
      "epoch 62 | loss: 0.73526 | train_accuracy: 0.67789 | valid_accuracy: 0.66361 |  0:00:12s\n",
      "epoch 63 | loss: 0.73524 | train_accuracy: 0.68563 | valid_accuracy: 0.65612 |  0:00:12s\n",
      "epoch 64 | loss: 0.7379  | train_accuracy: 0.69881 | valid_accuracy: 0.67891 |  0:00:12s\n",
      "epoch 65 | loss: 0.72043 | train_accuracy: 0.6858  | valid_accuracy: 0.66224 |  0:00:12s\n",
      "epoch 66 | loss: 0.72782 | train_accuracy: 0.68597 | valid_accuracy: 0.65986 |  0:00:12s\n",
      "epoch 67 | loss: 0.72481 | train_accuracy: 0.69906 | valid_accuracy: 0.67313 |  0:00:13s\n",
      "epoch 68 | loss: 0.73686 | train_accuracy: 0.70026 | valid_accuracy: 0.67653 |  0:00:13s\n",
      "epoch 69 | loss: 0.73125 | train_accuracy: 0.70102 | valid_accuracy: 0.68061 |  0:00:13s\n",
      "epoch 70 | loss: 0.73529 | train_accuracy: 0.69048 | valid_accuracy: 0.67585 |  0:00:13s\n",
      "epoch 71 | loss: 0.73445 | train_accuracy: 0.69855 | valid_accuracy: 0.68027 |  0:00:13s\n",
      "epoch 72 | loss: 0.73088 | train_accuracy: 0.69881 | valid_accuracy: 0.68061 |  0:00:14s\n",
      "epoch 73 | loss: 0.72475 | train_accuracy: 0.70128 | valid_accuracy: 0.68061 |  0:00:14s\n",
      "epoch 74 | loss: 0.71624 | train_accuracy: 0.70213 | valid_accuracy: 0.67959 |  0:00:14s\n",
      "epoch 75 | loss: 0.71546 | train_accuracy: 0.70519 | valid_accuracy: 0.67687 |  0:00:14s\n",
      "epoch 76 | loss: 0.71623 | train_accuracy: 0.69532 | valid_accuracy: 0.66395 |  0:00:14s\n",
      "epoch 77 | loss: 0.71633 | train_accuracy: 0.69821 | valid_accuracy: 0.68061 |  0:00:14s\n",
      "epoch 78 | loss: 0.72059 | train_accuracy: 0.68793 | valid_accuracy: 0.66395 |  0:00:15s\n",
      "epoch 79 | loss: 0.71391 | train_accuracy: 0.69719 | valid_accuracy: 0.66565 |  0:00:15s\n",
      "epoch 80 | loss: 0.71147 | train_accuracy: 0.69796 | valid_accuracy: 0.67211 |  0:00:15s\n",
      "epoch 81 | loss: 0.71275 | train_accuracy: 0.68869 | valid_accuracy: 0.67007 |  0:00:15s\n",
      "epoch 82 | loss: 0.71349 | train_accuracy: 0.70085 | valid_accuracy: 0.66565 |  0:00:15s\n",
      "epoch 83 | loss: 0.71172 | train_accuracy: 0.69813 | valid_accuracy: 0.67211 |  0:00:16s\n",
      "epoch 84 | loss: 0.71446 | train_accuracy: 0.70757 | valid_accuracy: 0.67993 |  0:00:16s\n",
      "epoch 85 | loss: 0.70691 | train_accuracy: 0.70893 | valid_accuracy: 0.68435 |  0:00:16s\n",
      "epoch 86 | loss: 0.70079 | train_accuracy: 0.70391 | valid_accuracy: 0.68197 |  0:00:16s\n",
      "epoch 87 | loss: 0.70218 | train_accuracy: 0.71437 | valid_accuracy: 0.68571 |  0:00:16s\n",
      "epoch 88 | loss: 0.70205 | train_accuracy: 0.70757 | valid_accuracy: 0.67211 |  0:00:17s\n",
      "epoch 89 | loss: 0.71719 | train_accuracy: 0.70238 | valid_accuracy: 0.67959 |  0:00:17s\n",
      "epoch 90 | loss: 0.70929 | train_accuracy: 0.70595 | valid_accuracy: 0.68265 |  0:00:17s\n",
      "epoch 91 | loss: 0.70465 | train_accuracy: 0.69796 | valid_accuracy: 0.67619 |  0:00:17s\n",
      "epoch 92 | loss: 0.69778 | train_accuracy: 0.70196 | valid_accuracy: 0.68095 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.69848 | train_accuracy: 0.70247 | valid_accuracy: 0.67483 |  0:00:17s\n",
      "epoch 94 | loss: 0.69854 | train_accuracy: 0.70323 | valid_accuracy: 0.68333 |  0:00:18s\n",
      "epoch 95 | loss: 0.71066 | train_accuracy: 0.69728 | valid_accuracy: 0.68571 |  0:00:18s\n",
      "epoch 96 | loss: 0.70644 | train_accuracy: 0.70204 | valid_accuracy: 0.67721 |  0:00:18s\n",
      "epoch 97 | loss: 0.70371 | train_accuracy: 0.70451 | valid_accuracy: 0.68231 |  0:00:18s\n",
      "epoch 98 | loss: 0.69816 | train_accuracy: 0.69031 | valid_accuracy: 0.67007 |  0:00:18s\n",
      "epoch 99 | loss: 0.70326 | train_accuracy: 0.69396 | valid_accuracy: 0.66735 |  0:00:19s\n",
      "epoch 100| loss: 0.69601 | train_accuracy: 0.70374 | valid_accuracy: 0.68435 |  0:00:19s\n",
      "epoch 101| loss: 0.69194 | train_accuracy: 0.71012 | valid_accuracy: 0.68639 |  0:00:19s\n",
      "epoch 102| loss: 0.68271 | train_accuracy: 0.71318 | valid_accuracy: 0.68265 |  0:00:19s\n",
      "epoch 103| loss: 0.69233 | train_accuracy: 0.71182 | valid_accuracy: 0.68401 |  0:00:19s\n",
      "epoch 104| loss: 0.68956 | train_accuracy: 0.68605 | valid_accuracy: 0.66667 |  0:00:20s\n",
      "epoch 105| loss: 0.70077 | train_accuracy: 0.69643 | valid_accuracy: 0.67211 |  0:00:20s\n",
      "epoch 106| loss: 0.69372 | train_accuracy: 0.6983  | valid_accuracy: 0.68333 |  0:00:20s\n",
      "epoch 107| loss: 0.69401 | train_accuracy: 0.70408 | valid_accuracy: 0.67483 |  0:00:20s\n",
      "epoch 108| loss: 0.697   | train_accuracy: 0.71267 | valid_accuracy: 0.67857 |  0:00:20s\n",
      "epoch 109| loss: 0.70606 | train_accuracy: 0.68452 | valid_accuracy: 0.65646 |  0:00:20s\n",
      "epoch 110| loss: 0.69816 | train_accuracy: 0.70085 | valid_accuracy: 0.67925 |  0:00:21s\n",
      "epoch 111| loss: 0.69523 | train_accuracy: 0.7006  | valid_accuracy: 0.67551 |  0:00:21s\n",
      "epoch 112| loss: 0.69554 | train_accuracy: 0.71063 | valid_accuracy: 0.68571 |  0:00:21s\n",
      "epoch 113| loss: 0.69372 | train_accuracy: 0.70782 | valid_accuracy: 0.67687 |  0:00:21s\n",
      "epoch 114| loss: 0.69736 | train_accuracy: 0.69991 | valid_accuracy: 0.66939 |  0:00:21s\n",
      "epoch 115| loss: 0.69539 | train_accuracy: 0.704   | valid_accuracy: 0.68333 |  0:00:22s\n",
      "epoch 116| loss: 0.68541 | train_accuracy: 0.7119  | valid_accuracy: 0.68741 |  0:00:22s\n",
      "epoch 117| loss: 0.67697 | train_accuracy: 0.71735 | valid_accuracy: 0.69354 |  0:00:22s\n",
      "epoch 118| loss: 0.6846  | train_accuracy: 0.70179 | valid_accuracy: 0.67755 |  0:00:22s\n",
      "epoch 119| loss: 0.68446 | train_accuracy: 0.71037 | valid_accuracy: 0.68163 |  0:00:22s\n",
      "epoch 120| loss: 0.67584 | train_accuracy: 0.71097 | valid_accuracy: 0.68673 |  0:00:23s\n",
      "epoch 121| loss: 0.67805 | train_accuracy: 0.71105 | valid_accuracy: 0.68469 |  0:00:23s\n",
      "epoch 122| loss: 0.67958 | train_accuracy: 0.71896 | valid_accuracy: 0.6966  |  0:00:23s\n",
      "epoch 123| loss: 0.67583 | train_accuracy: 0.71429 | valid_accuracy: 0.69014 |  0:00:23s\n",
      "epoch 124| loss: 0.67499 | train_accuracy: 0.71939 | valid_accuracy: 0.69218 |  0:00:23s\n",
      "epoch 125| loss: 0.67865 | train_accuracy: 0.70349 | valid_accuracy: 0.67789 |  0:00:23s\n",
      "epoch 126| loss: 0.676   | train_accuracy: 0.7233  | valid_accuracy: 0.69762 |  0:00:24s\n",
      "epoch 127| loss: 0.6788  | train_accuracy: 0.71667 | valid_accuracy: 0.69286 |  0:00:24s\n",
      "epoch 128| loss: 0.67121 | train_accuracy: 0.72568 | valid_accuracy: 0.70272 |  0:00:24s\n",
      "epoch 129| loss: 0.67421 | train_accuracy: 0.71752 | valid_accuracy: 0.68946 |  0:00:24s\n",
      "epoch 130| loss: 0.66481 | train_accuracy: 0.71531 | valid_accuracy: 0.69048 |  0:00:24s\n",
      "epoch 131| loss: 0.67341 | train_accuracy: 0.71973 | valid_accuracy: 0.69762 |  0:00:25s\n",
      "epoch 132| loss: 0.67029 | train_accuracy: 0.70842 | valid_accuracy: 0.68163 |  0:00:25s\n",
      "epoch 133| loss: 0.68007 | train_accuracy: 0.7182  | valid_accuracy: 0.68878 |  0:00:25s\n",
      "epoch 134| loss: 0.67212 | train_accuracy: 0.72313 | valid_accuracy: 0.69116 |  0:00:25s\n",
      "epoch 135| loss: 0.66435 | train_accuracy: 0.71514 | valid_accuracy: 0.69014 |  0:00:25s\n",
      "epoch 136| loss: 0.66435 | train_accuracy: 0.72177 | valid_accuracy: 0.69354 |  0:00:26s\n",
      "epoch 137| loss: 0.66368 | train_accuracy: 0.72049 | valid_accuracy: 0.69524 |  0:00:26s\n",
      "epoch 138| loss: 0.65623 | train_accuracy: 0.71633 | valid_accuracy: 0.69694 |  0:00:26s\n",
      "epoch 139| loss: 0.66488 | train_accuracy: 0.71862 | valid_accuracy: 0.69524 |  0:00:26s\n",
      "epoch 140| loss: 0.6635  | train_accuracy: 0.71361 | valid_accuracy: 0.68537 |  0:00:26s\n",
      "epoch 141| loss: 0.66497 | train_accuracy: 0.71709 | valid_accuracy: 0.69898 |  0:00:26s\n",
      "epoch 142| loss: 0.67143 | train_accuracy: 0.71633 | valid_accuracy: 0.69082 |  0:00:27s\n",
      "epoch 143| loss: 0.66214 | train_accuracy: 0.72287 | valid_accuracy: 0.69524 |  0:00:27s\n",
      "epoch 144| loss: 0.66651 | train_accuracy: 0.72185 | valid_accuracy: 0.69524 |  0:00:27s\n",
      "epoch 145| loss: 0.67004 | train_accuracy: 0.73095 | valid_accuracy: 0.70238 |  0:00:27s\n",
      "epoch 146| loss: 0.66787 | train_accuracy: 0.72041 | valid_accuracy: 0.69762 |  0:00:27s\n",
      "epoch 147| loss: 0.66033 | train_accuracy: 0.72058 | valid_accuracy: 0.68673 |  0:00:28s\n",
      "epoch 148| loss: 0.6694  | train_accuracy: 0.72611 | valid_accuracy: 0.69592 |  0:00:28s\n",
      "epoch 149| loss: 0.66381 | train_accuracy: 0.71122 | valid_accuracy: 0.69388 |  0:00:28s\n",
      "epoch 150| loss: 0.65946 | train_accuracy: 0.71752 | valid_accuracy: 0.68776 |  0:00:28s\n",
      "epoch 151| loss: 0.65185 | train_accuracy: 0.71658 | valid_accuracy: 0.6966  |  0:00:28s\n",
      "epoch 152| loss: 0.65541 | train_accuracy: 0.72628 | valid_accuracy: 0.69626 |  0:00:29s\n",
      "epoch 153| loss: 0.66047 | train_accuracy: 0.72024 | valid_accuracy: 0.69286 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 153 with best_epoch = 128 and best_valid_accuracy = 0.70272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "128\n",
      "epoch 0  | loss: 1.22897 | train_accuracy: 0.2807  | valid_accuracy: 0.28878 |  0:00:00s\n",
      "epoch 1  | loss: 1.02667 | train_accuracy: 0.35196 | valid_accuracy: 0.3602  |  0:00:00s\n",
      "epoch 2  | loss: 0.96234 | train_accuracy: 0.27653 | valid_accuracy: 0.28333 |  0:00:00s\n",
      "epoch 3  | loss: 0.92638 | train_accuracy: 0.29379 | valid_accuracy: 0.29456 |  0:00:00s\n",
      "epoch 4  | loss: 0.90491 | train_accuracy: 0.30332 | valid_accuracy: 0.2983  |  0:00:00s\n",
      "epoch 5  | loss: 0.9012  | train_accuracy: 0.33257 | valid_accuracy: 0.32449 |  0:00:01s\n",
      "epoch 6  | loss: 0.88153 | train_accuracy: 0.37857 | valid_accuracy: 0.37109 |  0:00:01s\n",
      "epoch 7  | loss: 0.86937 | train_accuracy: 0.3966  | valid_accuracy: 0.38401 |  0:00:01s\n",
      "epoch 8  | loss: 0.87775 | train_accuracy: 0.36029 | valid_accuracy: 0.36327 |  0:00:01s\n",
      "epoch 9  | loss: 0.87009 | train_accuracy: 0.4409  | valid_accuracy: 0.44932 |  0:00:01s\n",
      "epoch 10 | loss: 0.87791 | train_accuracy: 0.37262 | valid_accuracy: 0.36701 |  0:00:02s\n",
      "epoch 11 | loss: 0.86011 | train_accuracy: 0.44983 | valid_accuracy: 0.44252 |  0:00:02s\n",
      "epoch 12 | loss: 0.85395 | train_accuracy: 0.49022 | valid_accuracy: 0.48435 |  0:00:02s\n",
      "epoch 13 | loss: 0.84064 | train_accuracy: 0.52126 | valid_accuracy: 0.51565 |  0:00:02s\n",
      "epoch 14 | loss: 0.83786 | train_accuracy: 0.52338 | valid_accuracy: 0.52755 |  0:00:02s\n",
      "epoch 15 | loss: 0.83095 | train_accuracy: 0.51616 | valid_accuracy: 0.5102  |  0:00:02s\n",
      "epoch 16 | loss: 0.8257  | train_accuracy: 0.55561 | valid_accuracy: 0.55612 |  0:00:03s\n",
      "epoch 17 | loss: 0.83192 | train_accuracy: 0.57177 | valid_accuracy: 0.57925 |  0:00:03s\n",
      "epoch 18 | loss: 0.84479 | train_accuracy: 0.54124 | valid_accuracy: 0.53741 |  0:00:03s\n",
      "epoch 19 | loss: 0.83079 | train_accuracy: 0.54388 | valid_accuracy: 0.53129 |  0:00:03s\n",
      "epoch 20 | loss: 0.81535 | train_accuracy: 0.55774 | valid_accuracy: 0.55102 |  0:00:03s\n",
      "epoch 21 | loss: 0.81682 | train_accuracy: 0.59915 | valid_accuracy: 0.5949  |  0:00:04s\n",
      "epoch 22 | loss: 0.80543 | train_accuracy: 0.5943  | valid_accuracy: 0.5966  |  0:00:04s\n",
      "epoch 23 | loss: 0.80511 | train_accuracy: 0.58002 | valid_accuracy: 0.58401 |  0:00:04s\n",
      "epoch 24 | loss: 0.80334 | train_accuracy: 0.61565 | valid_accuracy: 0.61361 |  0:00:04s\n",
      "epoch 25 | loss: 0.81681 | train_accuracy: 0.61522 | valid_accuracy: 0.60952 |  0:00:04s\n",
      "epoch 26 | loss: 0.80576 | train_accuracy: 0.63061 | valid_accuracy: 0.63639 |  0:00:05s\n",
      "epoch 27 | loss: 0.80722 | train_accuracy: 0.61539 | valid_accuracy: 0.61769 |  0:00:05s\n",
      "epoch 28 | loss: 0.80862 | train_accuracy: 0.62406 | valid_accuracy: 0.62245 |  0:00:05s\n",
      "epoch 29 | loss: 0.79923 | train_accuracy: 0.64014 | valid_accuracy: 0.63163 |  0:00:05s\n",
      "epoch 30 | loss: 0.79452 | train_accuracy: 0.64974 | valid_accuracy: 0.64286 |  0:00:05s\n",
      "epoch 31 | loss: 0.79503 | train_accuracy: 0.63605 | valid_accuracy: 0.62789 |  0:00:06s\n",
      "epoch 32 | loss: 0.78709 | train_accuracy: 0.64804 | valid_accuracy: 0.64252 |  0:00:06s\n",
      "epoch 33 | loss: 0.77962 | train_accuracy: 0.64575 | valid_accuracy: 0.63912 |  0:00:06s\n",
      "epoch 34 | loss: 0.7792  | train_accuracy: 0.6443  | valid_accuracy: 0.63537 |  0:00:06s\n",
      "epoch 35 | loss: 0.78467 | train_accuracy: 0.65051 | valid_accuracy: 0.64796 |  0:00:06s\n",
      "epoch 36 | loss: 0.77687 | train_accuracy: 0.65995 | valid_accuracy: 0.65068 |  0:00:06s\n",
      "epoch 37 | loss: 0.78112 | train_accuracy: 0.65468 | valid_accuracy: 0.64524 |  0:00:07s\n",
      "epoch 38 | loss: 0.78141 | train_accuracy: 0.65799 | valid_accuracy: 0.6517  |  0:00:07s\n",
      "epoch 39 | loss: 0.76785 | train_accuracy: 0.65638 | valid_accuracy: 0.66088 |  0:00:07s\n",
      "epoch 40 | loss: 0.76188 | train_accuracy: 0.66429 | valid_accuracy: 0.6568  |  0:00:07s\n",
      "epoch 41 | loss: 0.76265 | train_accuracy: 0.66531 | valid_accuracy: 0.64864 |  0:00:07s\n",
      "epoch 42 | loss: 0.76278 | train_accuracy: 0.66207 | valid_accuracy: 0.64932 |  0:00:08s\n",
      "epoch 43 | loss: 0.76021 | train_accuracy: 0.66582 | valid_accuracy: 0.65272 |  0:00:08s\n",
      "epoch 44 | loss: 0.76009 | train_accuracy: 0.66216 | valid_accuracy: 0.65476 |  0:00:08s\n",
      "epoch 45 | loss: 0.75507 | train_accuracy: 0.66922 | valid_accuracy: 0.66395 |  0:00:08s\n",
      "epoch 46 | loss: 0.75658 | train_accuracy: 0.66463 | valid_accuracy: 0.65204 |  0:00:08s\n",
      "epoch 47 | loss: 0.75625 | train_accuracy: 0.67645 | valid_accuracy: 0.65884 |  0:00:09s\n",
      "epoch 48 | loss: 0.75323 | train_accuracy: 0.67764 | valid_accuracy: 0.66361 |  0:00:09s\n",
      "epoch 49 | loss: 0.75305 | train_accuracy: 0.65629 | valid_accuracy: 0.65918 |  0:00:09s\n",
      "epoch 50 | loss: 0.74365 | train_accuracy: 0.6744  | valid_accuracy: 0.65748 |  0:00:09s\n",
      "epoch 51 | loss: 0.74602 | train_accuracy: 0.67066 | valid_accuracy: 0.66054 |  0:00:09s\n",
      "epoch 52 | loss: 0.7487  | train_accuracy: 0.67304 | valid_accuracy: 0.66224 |  0:00:09s\n",
      "epoch 53 | loss: 0.74638 | train_accuracy: 0.65714 | valid_accuracy: 0.65    |  0:00:10s\n",
      "epoch 54 | loss: 0.74124 | train_accuracy: 0.67815 | valid_accuracy: 0.67415 |  0:00:10s\n",
      "epoch 55 | loss: 0.75001 | train_accuracy: 0.67075 | valid_accuracy: 0.66871 |  0:00:10s\n",
      "epoch 56 | loss: 0.74383 | train_accuracy: 0.67406 | valid_accuracy: 0.65918 |  0:00:10s\n",
      "epoch 57 | loss: 0.74152 | train_accuracy: 0.67007 | valid_accuracy: 0.66837 |  0:00:10s\n",
      "epoch 58 | loss: 0.74546 | train_accuracy: 0.67262 | valid_accuracy: 0.66156 |  0:00:11s\n",
      "epoch 59 | loss: 0.73689 | train_accuracy: 0.68452 | valid_accuracy: 0.67143 |  0:00:11s\n",
      "epoch 60 | loss: 0.73269 | train_accuracy: 0.67645 | valid_accuracy: 0.67313 |  0:00:11s\n",
      "epoch 61 | loss: 0.72632 | train_accuracy: 0.67772 | valid_accuracy: 0.67789 |  0:00:11s\n",
      "epoch 62 | loss: 0.72586 | train_accuracy: 0.67713 | valid_accuracy: 0.67993 |  0:00:11s\n",
      "epoch 63 | loss: 0.73689 | train_accuracy: 0.67526 | valid_accuracy: 0.66497 |  0:00:12s\n",
      "epoch 64 | loss: 0.7298  | train_accuracy: 0.66837 | valid_accuracy: 0.65952 |  0:00:12s\n",
      "epoch 65 | loss: 0.73448 | train_accuracy: 0.68138 | valid_accuracy: 0.66837 |  0:00:12s\n",
      "epoch 66 | loss: 0.73229 | train_accuracy: 0.67942 | valid_accuracy: 0.67007 |  0:00:12s\n",
      "epoch 67 | loss: 0.7364  | train_accuracy: 0.6818  | valid_accuracy: 0.66905 |  0:00:12s\n",
      "epoch 68 | loss: 0.72824 | train_accuracy: 0.68469 | valid_accuracy: 0.67313 |  0:00:12s\n",
      "epoch 69 | loss: 0.72458 | train_accuracy: 0.68248 | valid_accuracy: 0.67245 |  0:00:13s\n",
      "epoch 70 | loss: 0.72026 | train_accuracy: 0.67551 | valid_accuracy: 0.66871 |  0:00:13s\n",
      "epoch 71 | loss: 0.71272 | train_accuracy: 0.6909  | valid_accuracy: 0.67483 |  0:00:13s\n",
      "epoch 72 | loss: 0.71894 | train_accuracy: 0.68946 | valid_accuracy: 0.68435 |  0:00:13s\n",
      "epoch 73 | loss: 0.71979 | train_accuracy: 0.68036 | valid_accuracy: 0.67721 |  0:00:13s\n",
      "epoch 74 | loss: 0.71347 | train_accuracy: 0.69116 | valid_accuracy: 0.68197 |  0:00:14s\n",
      "epoch 75 | loss: 0.71447 | train_accuracy: 0.6915  | valid_accuracy: 0.67721 |  0:00:14s\n",
      "epoch 76 | loss: 0.7221  | train_accuracy: 0.67764 | valid_accuracy: 0.66667 |  0:00:14s\n",
      "epoch 77 | loss: 0.73327 | train_accuracy: 0.65808 | valid_accuracy: 0.65782 |  0:00:14s\n",
      "epoch 78 | loss: 0.72117 | train_accuracy: 0.69022 | valid_accuracy: 0.68129 |  0:00:14s\n",
      "epoch 79 | loss: 0.7214  | train_accuracy: 0.68699 | valid_accuracy: 0.69082 |  0:00:15s\n",
      "epoch 80 | loss: 0.72143 | train_accuracy: 0.67764 | valid_accuracy: 0.67381 |  0:00:15s\n",
      "epoch 81 | loss: 0.72574 | train_accuracy: 0.68673 | valid_accuracy: 0.67857 |  0:00:15s\n",
      "epoch 82 | loss: 0.72054 | train_accuracy: 0.68342 | valid_accuracy: 0.67993 |  0:00:15s\n",
      "epoch 83 | loss: 0.71987 | train_accuracy: 0.69073 | valid_accuracy: 0.68299 |  0:00:15s\n",
      "epoch 84 | loss: 0.71273 | train_accuracy: 0.69192 | valid_accuracy: 0.68469 |  0:00:16s\n",
      "epoch 85 | loss: 0.71996 | train_accuracy: 0.69005 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 86 | loss: 0.71905 | train_accuracy: 0.68997 | valid_accuracy: 0.67721 |  0:00:16s\n",
      "epoch 87 | loss: 0.71053 | train_accuracy: 0.69362 | valid_accuracy: 0.68367 |  0:00:16s\n",
      "epoch 88 | loss: 0.71383 | train_accuracy: 0.69107 | valid_accuracy: 0.66633 |  0:00:16s\n",
      "epoch 89 | loss: 0.73171 | train_accuracy: 0.68308 | valid_accuracy: 0.67959 |  0:00:16s\n",
      "epoch 90 | loss: 0.72967 | train_accuracy: 0.66599 | valid_accuracy: 0.6619  |  0:00:17s\n",
      "epoch 91 | loss: 0.70722 | train_accuracy: 0.68886 | valid_accuracy: 0.68163 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 | loss: 0.71202 | train_accuracy: 0.696   | valid_accuracy: 0.67755 |  0:00:17s\n",
      "epoch 93 | loss: 0.7134  | train_accuracy: 0.6835  | valid_accuracy: 0.67959 |  0:00:17s\n",
      "epoch 94 | loss: 0.71516 | train_accuracy: 0.69456 | valid_accuracy: 0.68673 |  0:00:17s\n",
      "epoch 95 | loss: 0.70909 | train_accuracy: 0.69201 | valid_accuracy: 0.67857 |  0:00:18s\n",
      "epoch 96 | loss: 0.71061 | train_accuracy: 0.7034  | valid_accuracy: 0.68673 |  0:00:18s\n",
      "epoch 97 | loss: 0.71227 | train_accuracy: 0.69184 | valid_accuracy: 0.69286 |  0:00:18s\n",
      "epoch 98 | loss: 0.70259 | train_accuracy: 0.69566 | valid_accuracy: 0.68197 |  0:00:18s\n",
      "epoch 99 | loss: 0.70399 | train_accuracy: 0.70068 | valid_accuracy: 0.69728 |  0:00:18s\n",
      "epoch 100| loss: 0.69776 | train_accuracy: 0.6875  | valid_accuracy: 0.68129 |  0:00:19s\n",
      "epoch 101| loss: 0.69736 | train_accuracy: 0.69243 | valid_accuracy: 0.68061 |  0:00:19s\n",
      "epoch 102| loss: 0.69761 | train_accuracy: 0.69651 | valid_accuracy: 0.68844 |  0:00:19s\n",
      "epoch 103| loss: 0.69237 | train_accuracy: 0.70799 | valid_accuracy: 0.69218 |  0:00:19s\n",
      "epoch 104| loss: 0.7003  | train_accuracy: 0.6881  | valid_accuracy: 0.68333 |  0:00:19s\n",
      "epoch 105| loss: 0.6936  | train_accuracy: 0.69906 | valid_accuracy: 0.69252 |  0:00:20s\n",
      "epoch 106| loss: 0.6923  | train_accuracy: 0.70315 | valid_accuracy: 0.69184 |  0:00:20s\n",
      "epoch 107| loss: 0.68895 | train_accuracy: 0.70714 | valid_accuracy: 0.69728 |  0:00:20s\n",
      "epoch 108| loss: 0.68325 | train_accuracy: 0.70842 | valid_accuracy: 0.70442 |  0:00:20s\n",
      "epoch 109| loss: 0.68483 | train_accuracy: 0.70935 | valid_accuracy: 0.69728 |  0:00:20s\n",
      "epoch 110| loss: 0.6835  | train_accuracy: 0.69796 | valid_accuracy: 0.68469 |  0:00:20s\n",
      "epoch 111| loss: 0.69327 | train_accuracy: 0.7051  | valid_accuracy: 0.69082 |  0:00:21s\n",
      "epoch 112| loss: 0.69009 | train_accuracy: 0.70442 | valid_accuracy: 0.69218 |  0:00:21s\n",
      "epoch 113| loss: 0.68527 | train_accuracy: 0.69872 | valid_accuracy: 0.69116 |  0:00:21s\n",
      "epoch 114| loss: 0.68376 | train_accuracy: 0.7068  | valid_accuracy: 0.69116 |  0:00:21s\n",
      "epoch 115| loss: 0.68486 | train_accuracy: 0.70714 | valid_accuracy: 0.69762 |  0:00:21s\n",
      "epoch 116| loss: 0.68512 | train_accuracy: 0.71556 | valid_accuracy: 0.71259 |  0:00:22s\n",
      "epoch 117| loss: 0.67879 | train_accuracy: 0.70502 | valid_accuracy: 0.69388 |  0:00:22s\n",
      "epoch 118| loss: 0.68063 | train_accuracy: 0.70791 | valid_accuracy: 0.69286 |  0:00:22s\n",
      "epoch 119| loss: 0.69342 | train_accuracy: 0.70119 | valid_accuracy: 0.68027 |  0:00:22s\n",
      "epoch 120| loss: 0.68886 | train_accuracy: 0.70391 | valid_accuracy: 0.69694 |  0:00:22s\n",
      "epoch 121| loss: 0.68004 | train_accuracy: 0.70825 | valid_accuracy: 0.69286 |  0:00:22s\n",
      "epoch 122| loss: 0.67721 | train_accuracy: 0.70876 | valid_accuracy: 0.6949  |  0:00:23s\n",
      "epoch 123| loss: 0.67465 | train_accuracy: 0.71327 | valid_accuracy: 0.6983  |  0:00:23s\n",
      "epoch 124| loss: 0.68255 | train_accuracy: 0.71233 | valid_accuracy: 0.6966  |  0:00:23s\n",
      "epoch 125| loss: 0.67598 | train_accuracy: 0.71046 | valid_accuracy: 0.69354 |  0:00:23s\n",
      "epoch 126| loss: 0.67907 | train_accuracy: 0.70952 | valid_accuracy: 0.69932 |  0:00:23s\n",
      "epoch 127| loss: 0.67348 | train_accuracy: 0.71769 | valid_accuracy: 0.70544 |  0:00:24s\n",
      "epoch 128| loss: 0.67476 | train_accuracy: 0.70884 | valid_accuracy: 0.70782 |  0:00:24s\n",
      "epoch 129| loss: 0.67186 | train_accuracy: 0.71752 | valid_accuracy: 0.70748 |  0:00:24s\n",
      "epoch 130| loss: 0.6739  | train_accuracy: 0.71845 | valid_accuracy: 0.70442 |  0:00:24s\n",
      "epoch 131| loss: 0.66412 | train_accuracy: 0.71956 | valid_accuracy: 0.70646 |  0:00:24s\n",
      "epoch 132| loss: 0.66405 | train_accuracy: 0.71599 | valid_accuracy: 0.71054 |  0:00:25s\n",
      "epoch 133| loss: 0.67247 | train_accuracy: 0.71267 | valid_accuracy: 0.7051  |  0:00:25s\n",
      "epoch 134| loss: 0.66981 | train_accuracy: 0.72066 | valid_accuracy: 0.71361 |  0:00:25s\n",
      "epoch 135| loss: 0.67524 | train_accuracy: 0.7216  | valid_accuracy: 0.70306 |  0:00:25s\n",
      "epoch 136| loss: 0.67334 | train_accuracy: 0.7199  | valid_accuracy: 0.70374 |  0:00:25s\n",
      "epoch 137| loss: 0.66232 | train_accuracy: 0.71803 | valid_accuracy: 0.70714 |  0:00:26s\n",
      "epoch 138| loss: 0.67148 | train_accuracy: 0.71122 | valid_accuracy: 0.70034 |  0:00:26s\n",
      "epoch 139| loss: 0.66616 | train_accuracy: 0.7176  | valid_accuracy: 0.69966 |  0:00:26s\n",
      "epoch 140| loss: 0.66233 | train_accuracy: 0.72253 | valid_accuracy: 0.70816 |  0:00:26s\n",
      "epoch 141| loss: 0.66046 | train_accuracy: 0.72202 | valid_accuracy: 0.7051  |  0:00:26s\n",
      "epoch 142| loss: 0.66312 | train_accuracy: 0.72066 | valid_accuracy: 0.71088 |  0:00:26s\n",
      "epoch 143| loss: 0.65978 | train_accuracy: 0.72662 | valid_accuracy: 0.71497 |  0:00:27s\n",
      "epoch 144| loss: 0.65859 | train_accuracy: 0.72321 | valid_accuracy: 0.70782 |  0:00:27s\n",
      "epoch 145| loss: 0.66004 | train_accuracy: 0.72389 | valid_accuracy: 0.71939 |  0:00:27s\n",
      "epoch 146| loss: 0.66051 | train_accuracy: 0.72194 | valid_accuracy: 0.70748 |  0:00:27s\n",
      "epoch 147| loss: 0.6631  | train_accuracy: 0.7233  | valid_accuracy: 0.70442 |  0:00:27s\n",
      "epoch 148| loss: 0.66553 | train_accuracy: 0.72891 | valid_accuracy: 0.72041 |  0:00:28s\n",
      "epoch 149| loss: 0.66737 | train_accuracy: 0.71692 | valid_accuracy: 0.71224 |  0:00:28s\n",
      "epoch 150| loss: 0.66871 | train_accuracy: 0.71879 | valid_accuracy: 0.70374 |  0:00:28s\n",
      "epoch 151| loss: 0.6571  | train_accuracy: 0.72611 | valid_accuracy: 0.71156 |  0:00:28s\n",
      "epoch 152| loss: 0.65452 | train_accuracy: 0.72007 | valid_accuracy: 0.70476 |  0:00:28s\n",
      "epoch 153| loss: 0.66046 | train_accuracy: 0.72432 | valid_accuracy: 0.71701 |  0:00:29s\n",
      "epoch 154| loss: 0.657   | train_accuracy: 0.72024 | valid_accuracy: 0.7119  |  0:00:29s\n",
      "epoch 155| loss: 0.65496 | train_accuracy: 0.72253 | valid_accuracy: 0.70544 |  0:00:29s\n",
      "epoch 156| loss: 0.65454 | train_accuracy: 0.7301  | valid_accuracy: 0.71293 |  0:00:29s\n",
      "epoch 157| loss: 0.64661 | train_accuracy: 0.72466 | valid_accuracy: 0.7119  |  0:00:29s\n",
      "epoch 158| loss: 0.6482  | train_accuracy: 0.72628 | valid_accuracy: 0.72007 |  0:00:29s\n",
      "epoch 159| loss: 0.65966 | train_accuracy: 0.72543 | valid_accuracy: 0.71293 |  0:00:30s\n",
      "epoch 160| loss: 0.64893 | train_accuracy: 0.72381 | valid_accuracy: 0.70816 |  0:00:30s\n",
      "epoch 161| loss: 0.65966 | train_accuracy: 0.72951 | valid_accuracy: 0.72279 |  0:00:30s\n",
      "epoch 162| loss: 0.64702 | train_accuracy: 0.71998 | valid_accuracy: 0.70714 |  0:00:30s\n",
      "epoch 163| loss: 0.6522  | train_accuracy: 0.72713 | valid_accuracy: 0.71633 |  0:00:30s\n",
      "epoch 164| loss: 0.65155 | train_accuracy: 0.72721 | valid_accuracy: 0.71327 |  0:00:31s\n",
      "epoch 165| loss: 0.65472 | train_accuracy: 0.71658 | valid_accuracy: 0.7     |  0:00:31s\n",
      "epoch 166| loss: 0.65172 | train_accuracy: 0.72798 | valid_accuracy: 0.71497 |  0:00:31s\n",
      "epoch 167| loss: 0.63989 | train_accuracy: 0.73163 | valid_accuracy: 0.72143 |  0:00:31s\n",
      "epoch 168| loss: 0.63765 | train_accuracy: 0.73316 | valid_accuracy: 0.71327 |  0:00:31s\n",
      "epoch 169| loss: 0.64347 | train_accuracy: 0.7324  | valid_accuracy: 0.71224 |  0:00:32s\n",
      "epoch 170| loss: 0.65179 | train_accuracy: 0.73206 | valid_accuracy: 0.71769 |  0:00:32s\n",
      "epoch 171| loss: 0.64755 | train_accuracy: 0.73282 | valid_accuracy: 0.71633 |  0:00:32s\n",
      "epoch 172| loss: 0.63887 | train_accuracy: 0.7369  | valid_accuracy: 0.72211 |  0:00:32s\n",
      "epoch 173| loss: 0.6489  | train_accuracy: 0.72934 | valid_accuracy: 0.7051  |  0:00:32s\n",
      "epoch 174| loss: 0.64052 | train_accuracy: 0.73138 | valid_accuracy: 0.71803 |  0:00:32s\n",
      "epoch 175| loss: 0.6403  | train_accuracy: 0.7324  | valid_accuracy: 0.72177 |  0:00:33s\n",
      "epoch 176| loss: 0.63848 | train_accuracy: 0.72798 | valid_accuracy: 0.71871 |  0:00:33s\n",
      "epoch 177| loss: 0.64016 | train_accuracy: 0.73665 | valid_accuracy: 0.72177 |  0:00:33s\n",
      "epoch 178| loss: 0.6426  | train_accuracy: 0.73656 | valid_accuracy: 0.71701 |  0:00:33s\n",
      "epoch 179| loss: 0.6464  | train_accuracy: 0.73478 | valid_accuracy: 0.72619 |  0:00:33s\n",
      "epoch 180| loss: 0.64821 | train_accuracy: 0.73929 | valid_accuracy: 0.72313 |  0:00:34s\n",
      "epoch 181| loss: 0.64023 | train_accuracy: 0.73852 | valid_accuracy: 0.72075 |  0:00:34s\n",
      "epoch 182| loss: 0.63675 | train_accuracy: 0.73818 | valid_accuracy: 0.71973 |  0:00:34s\n",
      "epoch 183| loss: 0.63175 | train_accuracy: 0.74048 | valid_accuracy: 0.72619 |  0:00:34s\n",
      "epoch 184| loss: 0.63748 | train_accuracy: 0.73265 | valid_accuracy: 0.72517 |  0:00:34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185| loss: 0.63872 | train_accuracy: 0.73529 | valid_accuracy: 0.71701 |  0:00:35s\n",
      "epoch 186| loss: 0.64016 | train_accuracy: 0.73707 | valid_accuracy: 0.72347 |  0:00:35s\n",
      "epoch 187| loss: 0.6296  | train_accuracy: 0.73639 | valid_accuracy: 0.72381 |  0:00:35s\n",
      "epoch 188| loss: 0.62972 | train_accuracy: 0.73716 | valid_accuracy: 0.72721 |  0:00:35s\n",
      "epoch 189| loss: 0.63513 | train_accuracy: 0.7307  | valid_accuracy: 0.71667 |  0:00:35s\n",
      "epoch 190| loss: 0.63995 | train_accuracy: 0.73325 | valid_accuracy: 0.72551 |  0:00:35s\n",
      "epoch 191| loss: 0.64164 | train_accuracy: 0.73656 | valid_accuracy: 0.71939 |  0:00:36s\n",
      "epoch 192| loss: 0.62936 | train_accuracy: 0.73818 | valid_accuracy: 0.72483 |  0:00:36s\n",
      "epoch 193| loss: 0.62855 | train_accuracy: 0.73673 | valid_accuracy: 0.72245 |  0:00:36s\n",
      "epoch 194| loss: 0.63478 | train_accuracy: 0.7415  | valid_accuracy: 0.72483 |  0:00:36s\n",
      "epoch 195| loss: 0.63967 | train_accuracy: 0.73682 | valid_accuracy: 0.72245 |  0:00:36s\n",
      "epoch 196| loss: 0.63542 | train_accuracy: 0.73537 | valid_accuracy: 0.71973 |  0:00:37s\n",
      "epoch 197| loss: 0.63105 | train_accuracy: 0.74082 | valid_accuracy: 0.72449 |  0:00:37s\n",
      "epoch 198| loss: 0.63196 | train_accuracy: 0.74065 | valid_accuracy: 0.72857 |  0:00:37s\n",
      "epoch 199| loss: 0.63733 | train_accuracy: 0.73759 | valid_accuracy: 0.72653 |  0:00:37s\n",
      "epoch 200| loss: 0.64059 | train_accuracy: 0.73478 | valid_accuracy: 0.72517 |  0:00:37s\n",
      "epoch 201| loss: 0.6282  | train_accuracy: 0.73665 | valid_accuracy: 0.72415 |  0:00:38s\n",
      "epoch 202| loss: 0.6341  | train_accuracy: 0.7369  | valid_accuracy: 0.72279 |  0:00:38s\n",
      "epoch 203| loss: 0.6338  | train_accuracy: 0.73716 | valid_accuracy: 0.72585 |  0:00:38s\n",
      "epoch 204| loss: 0.63186 | train_accuracy: 0.73818 | valid_accuracy: 0.72381 |  0:00:38s\n",
      "epoch 205| loss: 0.63058 | train_accuracy: 0.73648 | valid_accuracy: 0.72619 |  0:00:38s\n",
      "epoch 206| loss: 0.63294 | train_accuracy: 0.73801 | valid_accuracy: 0.72891 |  0:00:38s\n",
      "epoch 207| loss: 0.63431 | train_accuracy: 0.73155 | valid_accuracy: 0.71871 |  0:00:39s\n",
      "epoch 208| loss: 0.63069 | train_accuracy: 0.74082 | valid_accuracy: 0.72313 |  0:00:39s\n",
      "epoch 209| loss: 0.61769 | train_accuracy: 0.7415  | valid_accuracy: 0.72653 |  0:00:39s\n",
      "epoch 210| loss: 0.62024 | train_accuracy: 0.74694 | valid_accuracy: 0.73707 |  0:00:39s\n",
      "epoch 211| loss: 0.63146 | train_accuracy: 0.73937 | valid_accuracy: 0.72177 |  0:00:39s\n",
      "epoch 212| loss: 0.63329 | train_accuracy: 0.74039 | valid_accuracy: 0.72585 |  0:00:40s\n",
      "epoch 213| loss: 0.62764 | train_accuracy: 0.7432  | valid_accuracy: 0.73333 |  0:00:40s\n",
      "epoch 214| loss: 0.63386 | train_accuracy: 0.73784 | valid_accuracy: 0.72415 |  0:00:40s\n",
      "epoch 215| loss: 0.6284  | train_accuracy: 0.73741 | valid_accuracy: 0.72687 |  0:00:40s\n",
      "epoch 216| loss: 0.62152 | train_accuracy: 0.74303 | valid_accuracy: 0.73027 |  0:00:40s\n",
      "epoch 217| loss: 0.62547 | train_accuracy: 0.73903 | valid_accuracy: 0.73061 |  0:00:41s\n",
      "epoch 218| loss: 0.6212  | train_accuracy: 0.74005 | valid_accuracy: 0.72891 |  0:00:41s\n",
      "epoch 219| loss: 0.62713 | train_accuracy: 0.73997 | valid_accuracy: 0.72993 |  0:00:41s\n",
      "epoch 220| loss: 0.62285 | train_accuracy: 0.74388 | valid_accuracy: 0.73027 |  0:00:41s\n",
      "epoch 221| loss: 0.63052 | train_accuracy: 0.74456 | valid_accuracy: 0.73469 |  0:00:41s\n",
      "epoch 222| loss: 0.63707 | train_accuracy: 0.7449  | valid_accuracy: 0.72959 |  0:00:42s\n",
      "epoch 223| loss: 0.61972 | train_accuracy: 0.74388 | valid_accuracy: 0.72483 |  0:00:42s\n",
      "epoch 224| loss: 0.62285 | train_accuracy: 0.74694 | valid_accuracy: 0.73571 |  0:00:42s\n",
      "epoch 225| loss: 0.62006 | train_accuracy: 0.74422 | valid_accuracy: 0.72857 |  0:00:42s\n",
      "epoch 226| loss: 0.62307 | train_accuracy: 0.74991 | valid_accuracy: 0.73333 |  0:00:42s\n",
      "epoch 227| loss: 0.62512 | train_accuracy: 0.74745 | valid_accuracy: 0.73401 |  0:00:42s\n",
      "epoch 228| loss: 0.62733 | train_accuracy: 0.74711 | valid_accuracy: 0.73231 |  0:00:43s\n",
      "epoch 229| loss: 0.6246  | train_accuracy: 0.74396 | valid_accuracy: 0.73367 |  0:00:43s\n",
      "epoch 230| loss: 0.62157 | train_accuracy: 0.7483  | valid_accuracy: 0.73605 |  0:00:43s\n",
      "epoch 231| loss: 0.6173  | train_accuracy: 0.74515 | valid_accuracy: 0.73673 |  0:00:43s\n",
      "epoch 232| loss: 0.62403 | train_accuracy: 0.74303 | valid_accuracy: 0.73129 |  0:00:43s\n",
      "epoch 233| loss: 0.6334  | train_accuracy: 0.74541 | valid_accuracy: 0.72993 |  0:00:44s\n",
      "epoch 234| loss: 0.61483 | train_accuracy: 0.73954 | valid_accuracy: 0.72993 |  0:00:44s\n",
      "epoch 235| loss: 0.61718 | train_accuracy: 0.74549 | valid_accuracy: 0.73741 |  0:00:44s\n",
      "epoch 236| loss: 0.62094 | train_accuracy: 0.74541 | valid_accuracy: 0.73435 |  0:00:44s\n",
      "epoch 237| loss: 0.62615 | train_accuracy: 0.74677 | valid_accuracy: 0.72823 |  0:00:44s\n",
      "epoch 238| loss: 0.62579 | train_accuracy: 0.74685 | valid_accuracy: 0.73265 |  0:00:45s\n",
      "epoch 239| loss: 0.61865 | train_accuracy: 0.74957 | valid_accuracy: 0.73605 |  0:00:45s\n",
      "epoch 240| loss: 0.61777 | train_accuracy: 0.74643 | valid_accuracy: 0.73095 |  0:00:45s\n",
      "epoch 241| loss: 0.61535 | train_accuracy: 0.74787 | valid_accuracy: 0.73912 |  0:00:45s\n",
      "epoch 242| loss: 0.62443 | train_accuracy: 0.74804 | valid_accuracy: 0.73163 |  0:00:45s\n",
      "epoch 243| loss: 0.61682 | train_accuracy: 0.74218 | valid_accuracy: 0.72551 |  0:00:45s\n",
      "epoch 244| loss: 0.62163 | train_accuracy: 0.74473 | valid_accuracy: 0.73265 |  0:00:46s\n",
      "epoch 245| loss: 0.62143 | train_accuracy: 0.74507 | valid_accuracy: 0.73367 |  0:00:46s\n",
      "epoch 246| loss: 0.62098 | train_accuracy: 0.74719 | valid_accuracy: 0.73129 |  0:00:46s\n",
      "epoch 247| loss: 0.6131  | train_accuracy: 0.74643 | valid_accuracy: 0.72959 |  0:00:46s\n",
      "epoch 248| loss: 0.61704 | train_accuracy: 0.74685 | valid_accuracy: 0.73401 |  0:00:46s\n",
      "epoch 249| loss: 0.61103 | train_accuracy: 0.74566 | valid_accuracy: 0.73231 |  0:00:47s\n",
      "epoch 250| loss: 0.61914 | train_accuracy: 0.74796 | valid_accuracy: 0.73503 |  0:00:47s\n",
      "epoch 251| loss: 0.62115 | train_accuracy: 0.74779 | valid_accuracy: 0.73027 |  0:00:47s\n",
      "epoch 252| loss: 0.61869 | train_accuracy: 0.75009 | valid_accuracy: 0.73639 |  0:00:47s\n",
      "epoch 253| loss: 0.61289 | train_accuracy: 0.746   | valid_accuracy: 0.73469 |  0:00:47s\n",
      "epoch 254| loss: 0.61731 | train_accuracy: 0.74626 | valid_accuracy: 0.72959 |  0:00:47s\n",
      "epoch 255| loss: 0.61234 | train_accuracy: 0.75068 | valid_accuracy: 0.73027 |  0:00:48s\n",
      "epoch 256| loss: 0.61481 | train_accuracy: 0.74711 | valid_accuracy: 0.73027 |  0:00:48s\n",
      "epoch 257| loss: 0.61519 | train_accuracy: 0.74779 | valid_accuracy: 0.73469 |  0:00:48s\n",
      "epoch 258| loss: 0.60986 | train_accuracy: 0.74762 | valid_accuracy: 0.73537 |  0:00:48s\n",
      "epoch 259| loss: 0.60988 | train_accuracy: 0.74906 | valid_accuracy: 0.73673 |  0:00:48s\n",
      "epoch 260| loss: 0.60534 | train_accuracy: 0.7506  | valid_accuracy: 0.73639 |  0:00:49s\n",
      "epoch 261| loss: 0.60947 | train_accuracy: 0.75442 | valid_accuracy: 0.74184 |  0:00:49s\n",
      "epoch 262| loss: 0.61421 | train_accuracy: 0.75026 | valid_accuracy: 0.73605 |  0:00:49s\n",
      "epoch 263| loss: 0.61166 | train_accuracy: 0.75272 | valid_accuracy: 0.73639 |  0:00:49s\n",
      "epoch 264| loss: 0.61196 | train_accuracy: 0.75179 | valid_accuracy: 0.73571 |  0:00:49s\n",
      "epoch 265| loss: 0.61136 | train_accuracy: 0.75349 | valid_accuracy: 0.7398  |  0:00:50s\n",
      "epoch 266| loss: 0.6051  | train_accuracy: 0.75128 | valid_accuracy: 0.7398  |  0:00:50s\n",
      "epoch 267| loss: 0.61283 | train_accuracy: 0.7506  | valid_accuracy: 0.73435 |  0:00:50s\n",
      "epoch 268| loss: 0.6094  | train_accuracy: 0.75298 | valid_accuracy: 0.73673 |  0:00:50s\n",
      "epoch 269| loss: 0.60917 | train_accuracy: 0.75408 | valid_accuracy: 0.74082 |  0:00:50s\n",
      "epoch 270| loss: 0.6146  | train_accuracy: 0.75187 | valid_accuracy: 0.73605 |  0:00:51s\n",
      "epoch 271| loss: 0.60772 | train_accuracy: 0.75    | valid_accuracy: 0.72959 |  0:00:51s\n",
      "epoch 272| loss: 0.61539 | train_accuracy: 0.74983 | valid_accuracy: 0.72925 |  0:00:51s\n",
      "epoch 273| loss: 0.6058  | train_accuracy: 0.75536 | valid_accuracy: 0.73571 |  0:00:51s\n",
      "epoch 274| loss: 0.61316 | train_accuracy: 0.75119 | valid_accuracy: 0.73571 |  0:00:51s\n",
      "epoch 275| loss: 0.61022 | train_accuracy: 0.75068 | valid_accuracy: 0.73776 |  0:00:52s\n",
      "epoch 276| loss: 0.60658 | train_accuracy: 0.75315 | valid_accuracy: 0.73367 |  0:00:52s\n",
      "epoch 277| loss: 0.61195 | train_accuracy: 0.75153 | valid_accuracy: 0.73503 |  0:00:52s\n",
      "epoch 278| loss: 0.60862 | train_accuracy: 0.75281 | valid_accuracy: 0.73605 |  0:00:52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 279| loss: 0.60713 | train_accuracy: 0.75145 | valid_accuracy: 0.73503 |  0:00:52s\n",
      "epoch 280| loss: 0.6083  | train_accuracy: 0.75315 | valid_accuracy: 0.73776 |  0:00:52s\n",
      "epoch 281| loss: 0.6099  | train_accuracy: 0.75162 | valid_accuracy: 0.74014 |  0:00:53s\n",
      "epoch 282| loss: 0.61879 | train_accuracy: 0.75247 | valid_accuracy: 0.73571 |  0:00:53s\n",
      "epoch 283| loss: 0.61651 | train_accuracy: 0.75587 | valid_accuracy: 0.73878 |  0:00:53s\n",
      "epoch 284| loss: 0.60699 | train_accuracy: 0.75306 | valid_accuracy: 0.73946 |  0:00:53s\n",
      "epoch 285| loss: 0.61322 | train_accuracy: 0.75306 | valid_accuracy: 0.74014 |  0:00:53s\n",
      "epoch 286| loss: 0.60401 | train_accuracy: 0.75391 | valid_accuracy: 0.73333 |  0:00:54s\n",
      "\n",
      "Early stopping occurred at epoch 286 with best_epoch = 261 and best_valid_accuracy = 0.74184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n",
      "261\n",
      "epoch 0  | loss: 1.28497 | train_accuracy: 0.27253 | valid_accuracy: 0.28231 |  0:00:00s\n",
      "epoch 1  | loss: 1.03348 | train_accuracy: 0.28019 | valid_accuracy: 0.28946 |  0:00:00s\n",
      "epoch 2  | loss: 0.97065 | train_accuracy: 0.28053 | valid_accuracy: 0.2915  |  0:00:00s\n",
      "epoch 3  | loss: 0.94297 | train_accuracy: 0.26395 | valid_accuracy: 0.26837 |  0:00:00s\n",
      "epoch 4  | loss: 0.93189 | train_accuracy: 0.27696 | valid_accuracy: 0.28367 |  0:00:00s\n",
      "epoch 5  | loss: 0.91414 | train_accuracy: 0.27942 | valid_accuracy: 0.28163 |  0:00:01s\n",
      "epoch 6  | loss: 0.90624 | train_accuracy: 0.30272 | valid_accuracy: 0.30204 |  0:00:01s\n",
      "epoch 7  | loss: 0.89721 | train_accuracy: 0.31803 | valid_accuracy: 0.32517 |  0:00:01s\n",
      "epoch 8  | loss: 0.88523 | train_accuracy: 0.40799 | valid_accuracy: 0.40204 |  0:00:01s\n",
      "epoch 9  | loss: 0.8809  | train_accuracy: 0.38946 | valid_accuracy: 0.39388 |  0:00:01s\n",
      "epoch 10 | loss: 0.87957 | train_accuracy: 0.38818 | valid_accuracy: 0.38673 |  0:00:02s\n",
      "epoch 11 | loss: 0.87314 | train_accuracy: 0.39311 | valid_accuracy: 0.40646 |  0:00:02s\n",
      "epoch 12 | loss: 0.86774 | train_accuracy: 0.40935 | valid_accuracy: 0.4085  |  0:00:02s\n",
      "epoch 13 | loss: 0.85067 | train_accuracy: 0.44354 | valid_accuracy: 0.4432  |  0:00:02s\n",
      "epoch 14 | loss: 0.8442  | train_accuracy: 0.47551 | valid_accuracy: 0.46769 |  0:00:02s\n",
      "epoch 15 | loss: 0.8501  | train_accuracy: 0.51429 | valid_accuracy: 0.51054 |  0:00:03s\n",
      "epoch 16 | loss: 0.8294  | train_accuracy: 0.56454 | valid_accuracy: 0.55986 |  0:00:03s\n",
      "epoch 17 | loss: 0.82253 | train_accuracy: 0.5733  | valid_accuracy: 0.57551 |  0:00:03s\n",
      "epoch 18 | loss: 0.82247 | train_accuracy: 0.59311 | valid_accuracy: 0.58844 |  0:00:03s\n",
      "epoch 19 | loss: 0.8292  | train_accuracy: 0.60417 | valid_accuracy: 0.6068  |  0:00:03s\n",
      "epoch 20 | loss: 0.82745 | train_accuracy: 0.59524 | valid_accuracy: 0.5949  |  0:00:03s\n",
      "epoch 21 | loss: 0.81068 | train_accuracy: 0.60587 | valid_accuracy: 0.59592 |  0:00:04s\n",
      "epoch 22 | loss: 0.80607 | train_accuracy: 0.59456 | valid_accuracy: 0.58231 |  0:00:04s\n",
      "epoch 23 | loss: 0.80648 | train_accuracy: 0.61854 | valid_accuracy: 0.61429 |  0:00:04s\n",
      "epoch 24 | loss: 0.79732 | train_accuracy: 0.61037 | valid_accuracy: 0.61361 |  0:00:04s\n",
      "epoch 25 | loss: 0.79362 | train_accuracy: 0.62993 | valid_accuracy: 0.62279 |  0:00:04s\n",
      "epoch 26 | loss: 0.78857 | train_accuracy: 0.6352  | valid_accuracy: 0.62857 |  0:00:05s\n",
      "epoch 27 | loss: 0.77762 | train_accuracy: 0.6102  | valid_accuracy: 0.5949  |  0:00:05s\n",
      "epoch 28 | loss: 0.77637 | train_accuracy: 0.60706 | valid_accuracy: 0.60238 |  0:00:05s\n",
      "epoch 29 | loss: 0.78284 | train_accuracy: 0.63631 | valid_accuracy: 0.63741 |  0:00:05s\n",
      "epoch 30 | loss: 0.78206 | train_accuracy: 0.61913 | valid_accuracy: 0.61361 |  0:00:05s\n",
      "epoch 31 | loss: 0.78251 | train_accuracy: 0.64056 | valid_accuracy: 0.64694 |  0:00:06s\n",
      "epoch 32 | loss: 0.77871 | train_accuracy: 0.65298 | valid_accuracy: 0.64932 |  0:00:06s\n",
      "epoch 33 | loss: 0.77007 | train_accuracy: 0.65604 | valid_accuracy: 0.65034 |  0:00:06s\n",
      "epoch 34 | loss: 0.76734 | train_accuracy: 0.64039 | valid_accuracy: 0.64422 |  0:00:06s\n",
      "epoch 35 | loss: 0.76078 | train_accuracy: 0.65051 | valid_accuracy: 0.65408 |  0:00:06s\n",
      "epoch 36 | loss: 0.7626  | train_accuracy: 0.65128 | valid_accuracy: 0.65646 |  0:00:07s\n",
      "epoch 37 | loss: 0.76851 | train_accuracy: 0.66718 | valid_accuracy: 0.66565 |  0:00:07s\n",
      "epoch 38 | loss: 0.7672  | train_accuracy: 0.65731 | valid_accuracy: 0.65272 |  0:00:07s\n",
      "epoch 39 | loss: 0.77722 | train_accuracy: 0.6449  | valid_accuracy: 0.6381  |  0:00:07s\n",
      "epoch 40 | loss: 0.7792  | train_accuracy: 0.66743 | valid_accuracy: 0.6602  |  0:00:07s\n",
      "epoch 41 | loss: 0.76101 | train_accuracy: 0.6608  | valid_accuracy: 0.66735 |  0:00:07s\n",
      "epoch 42 | loss: 0.75917 | train_accuracy: 0.66573 | valid_accuracy: 0.66327 |  0:00:08s\n",
      "epoch 43 | loss: 0.76189 | train_accuracy: 0.65289 | valid_accuracy: 0.64694 |  0:00:08s\n",
      "epoch 44 | loss: 0.7583  | train_accuracy: 0.67364 | valid_accuracy: 0.67619 |  0:00:08s\n",
      "epoch 45 | loss: 0.75298 | train_accuracy: 0.66803 | valid_accuracy: 0.66837 |  0:00:08s\n",
      "epoch 46 | loss: 0.75157 | train_accuracy: 0.67041 | valid_accuracy: 0.66497 |  0:00:08s\n",
      "epoch 47 | loss: 0.74795 | train_accuracy: 0.66641 | valid_accuracy: 0.66293 |  0:00:09s\n",
      "epoch 48 | loss: 0.74722 | train_accuracy: 0.6716  | valid_accuracy: 0.66599 |  0:00:09s\n",
      "epoch 49 | loss: 0.74366 | train_accuracy: 0.67526 | valid_accuracy: 0.66599 |  0:00:09s\n",
      "epoch 50 | loss: 0.73482 | train_accuracy: 0.67704 | valid_accuracy: 0.67449 |  0:00:09s\n",
      "epoch 51 | loss: 0.73982 | train_accuracy: 0.67066 | valid_accuracy: 0.67245 |  0:00:09s\n",
      "epoch 52 | loss: 0.73776 | train_accuracy: 0.68554 | valid_accuracy: 0.68912 |  0:00:10s\n",
      "epoch 53 | loss: 0.74358 | train_accuracy: 0.6773  | valid_accuracy: 0.67687 |  0:00:10s\n",
      "epoch 54 | loss: 0.73141 | train_accuracy: 0.67296 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 55 | loss: 0.73179 | train_accuracy: 0.68452 | valid_accuracy: 0.68163 |  0:00:10s\n",
      "epoch 56 | loss: 0.7224  | train_accuracy: 0.6932  | valid_accuracy: 0.69286 |  0:00:10s\n",
      "epoch 57 | loss: 0.72047 | train_accuracy: 0.6801  | valid_accuracy: 0.67483 |  0:00:11s\n",
      "epoch 58 | loss: 0.73005 | train_accuracy: 0.69252 | valid_accuracy: 0.6949  |  0:00:11s\n",
      "epoch 59 | loss: 0.72389 | train_accuracy: 0.68588 | valid_accuracy: 0.6881  |  0:00:11s\n",
      "epoch 60 | loss: 0.72646 | train_accuracy: 0.6824  | valid_accuracy: 0.68707 |  0:00:11s\n",
      "epoch 61 | loss: 0.73264 | train_accuracy: 0.6932  | valid_accuracy: 0.69456 |  0:00:11s\n",
      "epoch 62 | loss: 0.72439 | train_accuracy: 0.68571 | valid_accuracy: 0.68912 |  0:00:11s\n",
      "epoch 63 | loss: 0.72038 | train_accuracy: 0.67747 | valid_accuracy: 0.67143 |  0:00:12s\n",
      "epoch 64 | loss: 0.72786 | train_accuracy: 0.68146 | valid_accuracy: 0.67687 |  0:00:12s\n",
      "epoch 65 | loss: 0.72608 | train_accuracy: 0.69252 | valid_accuracy: 0.68912 |  0:00:12s\n",
      "epoch 66 | loss: 0.71857 | train_accuracy: 0.68673 | valid_accuracy: 0.68095 |  0:00:12s\n",
      "epoch 67 | loss: 0.72095 | train_accuracy: 0.6966  | valid_accuracy: 0.69626 |  0:00:12s\n",
      "epoch 68 | loss: 0.71959 | train_accuracy: 0.69311 | valid_accuracy: 0.70204 |  0:00:13s\n",
      "epoch 69 | loss: 0.72416 | train_accuracy: 0.68325 | valid_accuracy: 0.67211 |  0:00:13s\n",
      "epoch 70 | loss: 0.71707 | train_accuracy: 0.70306 | valid_accuracy: 0.6932  |  0:00:13s\n",
      "epoch 71 | loss: 0.71922 | train_accuracy: 0.69294 | valid_accuracy: 0.68707 |  0:00:13s\n",
      "epoch 72 | loss: 0.70971 | train_accuracy: 0.69524 | valid_accuracy: 0.6915  |  0:00:13s\n",
      "epoch 73 | loss: 0.70563 | train_accuracy: 0.68946 | valid_accuracy: 0.68639 |  0:00:14s\n",
      "epoch 74 | loss: 0.71549 | train_accuracy: 0.69974 | valid_accuracy: 0.6898  |  0:00:14s\n",
      "epoch 75 | loss: 0.70932 | train_accuracy: 0.69753 | valid_accuracy: 0.69456 |  0:00:14s\n",
      "epoch 76 | loss: 0.72017 | train_accuracy: 0.70026 | valid_accuracy: 0.70102 |  0:00:14s\n",
      "epoch 77 | loss: 0.70967 | train_accuracy: 0.6983  | valid_accuracy: 0.70238 |  0:00:14s\n",
      "epoch 78 | loss: 0.70136 | train_accuracy: 0.69558 | valid_accuracy: 0.70204 |  0:00:14s\n",
      "epoch 79 | loss: 0.70365 | train_accuracy: 0.70162 | valid_accuracy: 0.70408 |  0:00:15s\n",
      "epoch 80 | loss: 0.70326 | train_accuracy: 0.70272 | valid_accuracy: 0.7068  |  0:00:15s\n",
      "epoch 81 | loss: 0.70169 | train_accuracy: 0.69277 | valid_accuracy: 0.68776 |  0:00:15s\n",
      "epoch 82 | loss: 0.70199 | train_accuracy: 0.68869 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 83 | loss: 0.69747 | train_accuracy: 0.70816 | valid_accuracy: 0.70986 |  0:00:15s\n",
      "epoch 84 | loss: 0.69479 | train_accuracy: 0.71114 | valid_accuracy: 0.71395 |  0:00:16s\n",
      "epoch 85 | loss: 0.68969 | train_accuracy: 0.7119  | valid_accuracy: 0.69762 |  0:00:16s\n",
      "epoch 86 | loss: 0.68884 | train_accuracy: 0.696   | valid_accuracy: 0.69694 |  0:00:16s\n",
      "epoch 87 | loss: 0.68618 | train_accuracy: 0.71454 | valid_accuracy: 0.70544 |  0:00:16s\n",
      "epoch 88 | loss: 0.6922  | train_accuracy: 0.71207 | valid_accuracy: 0.70884 |  0:00:16s\n",
      "epoch 89 | loss: 0.68681 | train_accuracy: 0.70315 | valid_accuracy: 0.69558 |  0:00:17s\n",
      "epoch 90 | loss: 0.69063 | train_accuracy: 0.70952 | valid_accuracy: 0.71259 |  0:00:17s\n",
      "epoch 91 | loss: 0.68621 | train_accuracy: 0.71114 | valid_accuracy: 0.70748 |  0:00:17s\n",
      "epoch 92 | loss: 0.6875  | train_accuracy: 0.69677 | valid_accuracy: 0.69558 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.68078 | train_accuracy: 0.72304 | valid_accuracy: 0.72211 |  0:00:17s\n",
      "epoch 94 | loss: 0.68012 | train_accuracy: 0.71514 | valid_accuracy: 0.70884 |  0:00:17s\n",
      "epoch 95 | loss: 0.68192 | train_accuracy: 0.71488 | valid_accuracy: 0.71327 |  0:00:18s\n",
      "epoch 96 | loss: 0.68897 | train_accuracy: 0.71454 | valid_accuracy: 0.70986 |  0:00:18s\n",
      "epoch 97 | loss: 0.67915 | train_accuracy: 0.71828 | valid_accuracy: 0.71122 |  0:00:18s\n",
      "epoch 98 | loss: 0.68941 | train_accuracy: 0.70731 | valid_accuracy: 0.7017  |  0:00:18s\n",
      "epoch 99 | loss: 0.68701 | train_accuracy: 0.71454 | valid_accuracy: 0.70476 |  0:00:18s\n",
      "epoch 100| loss: 0.68634 | train_accuracy: 0.69813 | valid_accuracy: 0.69286 |  0:00:19s\n",
      "epoch 101| loss: 0.68082 | train_accuracy: 0.71624 | valid_accuracy: 0.71088 |  0:00:19s\n",
      "epoch 102| loss: 0.67408 | train_accuracy: 0.7165  | valid_accuracy: 0.71463 |  0:00:19s\n",
      "epoch 103| loss: 0.68004 | train_accuracy: 0.71003 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 104| loss: 0.66945 | train_accuracy: 0.72789 | valid_accuracy: 0.71565 |  0:00:19s\n",
      "epoch 105| loss: 0.66905 | train_accuracy: 0.71233 | valid_accuracy: 0.70646 |  0:00:20s\n",
      "epoch 106| loss: 0.67431 | train_accuracy: 0.72083 | valid_accuracy: 0.72211 |  0:00:20s\n",
      "epoch 107| loss: 0.67978 | train_accuracy: 0.72194 | valid_accuracy: 0.71497 |  0:00:20s\n",
      "epoch 108| loss: 0.68099 | train_accuracy: 0.72049 | valid_accuracy: 0.71156 |  0:00:20s\n",
      "epoch 109| loss: 0.68415 | train_accuracy: 0.71888 | valid_accuracy: 0.7     |  0:00:20s\n",
      "epoch 110| loss: 0.67041 | train_accuracy: 0.7165  | valid_accuracy: 0.71497 |  0:00:21s\n",
      "epoch 111| loss: 0.67438 | train_accuracy: 0.71964 | valid_accuracy: 0.71701 |  0:00:21s\n",
      "epoch 112| loss: 0.67135 | train_accuracy: 0.71293 | valid_accuracy: 0.70748 |  0:00:21s\n",
      "epoch 113| loss: 0.66776 | train_accuracy: 0.72236 | valid_accuracy: 0.71837 |  0:00:21s\n",
      "epoch 114| loss: 0.66602 | train_accuracy: 0.72747 | valid_accuracy: 0.72245 |  0:00:21s\n",
      "epoch 115| loss: 0.66807 | train_accuracy: 0.72696 | valid_accuracy: 0.71803 |  0:00:21s\n",
      "epoch 116| loss: 0.66038 | train_accuracy: 0.72449 | valid_accuracy: 0.71667 |  0:00:22s\n",
      "epoch 117| loss: 0.67084 | train_accuracy: 0.7244  | valid_accuracy: 0.72041 |  0:00:22s\n",
      "epoch 118| loss: 0.66217 | train_accuracy: 0.71701 | valid_accuracy: 0.70714 |  0:00:22s\n",
      "epoch 119| loss: 0.66586 | train_accuracy: 0.72968 | valid_accuracy: 0.7119  |  0:00:22s\n",
      "epoch 120| loss: 0.66097 | train_accuracy: 0.71947 | valid_accuracy: 0.70306 |  0:00:22s\n",
      "epoch 121| loss: 0.65619 | train_accuracy: 0.73121 | valid_accuracy: 0.72041 |  0:00:23s\n",
      "epoch 122| loss: 0.66338 | train_accuracy: 0.73053 | valid_accuracy: 0.71803 |  0:00:23s\n",
      "epoch 123| loss: 0.66309 | train_accuracy: 0.73019 | valid_accuracy: 0.71905 |  0:00:23s\n",
      "epoch 124| loss: 0.65771 | train_accuracy: 0.72925 | valid_accuracy: 0.71803 |  0:00:23s\n",
      "epoch 125| loss: 0.66347 | train_accuracy: 0.7233  | valid_accuracy: 0.70714 |  0:00:23s\n",
      "epoch 126| loss: 0.65346 | train_accuracy: 0.73129 | valid_accuracy: 0.72415 |  0:00:24s\n",
      "epoch 127| loss: 0.65424 | train_accuracy: 0.72721 | valid_accuracy: 0.71633 |  0:00:24s\n",
      "epoch 128| loss: 0.66343 | train_accuracy: 0.73053 | valid_accuracy: 0.71531 |  0:00:24s\n",
      "epoch 129| loss: 0.65346 | train_accuracy: 0.72959 | valid_accuracy: 0.71735 |  0:00:24s\n",
      "epoch 130| loss: 0.6554  | train_accuracy: 0.72653 | valid_accuracy: 0.71497 |  0:00:24s\n",
      "epoch 131| loss: 0.65597 | train_accuracy: 0.72236 | valid_accuracy: 0.71429 |  0:00:24s\n",
      "epoch 132| loss: 0.66041 | train_accuracy: 0.72211 | valid_accuracy: 0.71054 |  0:00:25s\n",
      "epoch 133| loss: 0.65684 | train_accuracy: 0.73554 | valid_accuracy: 0.7102  |  0:00:25s\n",
      "epoch 134| loss: 0.64938 | train_accuracy: 0.72577 | valid_accuracy: 0.72075 |  0:00:25s\n",
      "epoch 135| loss: 0.65365 | train_accuracy: 0.73393 | valid_accuracy: 0.72279 |  0:00:25s\n",
      "epoch 136| loss: 0.64767 | train_accuracy: 0.7256  | valid_accuracy: 0.71259 |  0:00:25s\n",
      "epoch 137| loss: 0.64523 | train_accuracy: 0.72891 | valid_accuracy: 0.71531 |  0:00:26s\n",
      "epoch 138| loss: 0.64796 | train_accuracy: 0.73393 | valid_accuracy: 0.72381 |  0:00:26s\n",
      "epoch 139| loss: 0.65445 | train_accuracy: 0.72721 | valid_accuracy: 0.72347 |  0:00:26s\n",
      "epoch 140| loss: 0.65324 | train_accuracy: 0.73971 | valid_accuracy: 0.73265 |  0:00:26s\n",
      "epoch 141| loss: 0.64706 | train_accuracy: 0.7307  | valid_accuracy: 0.72109 |  0:00:26s\n",
      "epoch 142| loss: 0.63835 | train_accuracy: 0.73427 | valid_accuracy: 0.71565 |  0:00:27s\n",
      "epoch 143| loss: 0.63982 | train_accuracy: 0.73793 | valid_accuracy: 0.72857 |  0:00:27s\n",
      "epoch 144| loss: 0.6413  | train_accuracy: 0.73316 | valid_accuracy: 0.71871 |  0:00:27s\n",
      "epoch 145| loss: 0.6445  | train_accuracy: 0.73019 | valid_accuracy: 0.71361 |  0:00:27s\n",
      "epoch 146| loss: 0.64439 | train_accuracy: 0.74167 | valid_accuracy: 0.72551 |  0:00:27s\n",
      "epoch 147| loss: 0.63424 | train_accuracy: 0.73818 | valid_accuracy: 0.72483 |  0:00:27s\n",
      "epoch 148| loss: 0.64016 | train_accuracy: 0.73912 | valid_accuracy: 0.72245 |  0:00:28s\n",
      "epoch 149| loss: 0.65022 | train_accuracy: 0.73954 | valid_accuracy: 0.72551 |  0:00:28s\n",
      "epoch 150| loss: 0.64469 | train_accuracy: 0.73793 | valid_accuracy: 0.72857 |  0:00:28s\n",
      "epoch 151| loss: 0.63436 | train_accuracy: 0.74124 | valid_accuracy: 0.72177 |  0:00:28s\n",
      "epoch 152| loss: 0.63666 | train_accuracy: 0.73512 | valid_accuracy: 0.72177 |  0:00:28s\n",
      "epoch 153| loss: 0.64458 | train_accuracy: 0.73988 | valid_accuracy: 0.73367 |  0:00:29s\n",
      "epoch 154| loss: 0.63943 | train_accuracy: 0.74133 | valid_accuracy: 0.72551 |  0:00:29s\n",
      "epoch 155| loss: 0.64789 | train_accuracy: 0.7381  | valid_accuracy: 0.72245 |  0:00:29s\n",
      "epoch 156| loss: 0.6376  | train_accuracy: 0.74022 | valid_accuracy: 0.72891 |  0:00:29s\n",
      "epoch 157| loss: 0.6354  | train_accuracy: 0.74388 | valid_accuracy: 0.72653 |  0:00:29s\n",
      "epoch 158| loss: 0.63739 | train_accuracy: 0.74039 | valid_accuracy: 0.72415 |  0:00:30s\n",
      "epoch 159| loss: 0.63723 | train_accuracy: 0.74175 | valid_accuracy: 0.72483 |  0:00:30s\n",
      "epoch 160| loss: 0.64493 | train_accuracy: 0.74345 | valid_accuracy: 0.72653 |  0:00:30s\n",
      "epoch 161| loss: 0.63718 | train_accuracy: 0.73724 | valid_accuracy: 0.71905 |  0:00:30s\n",
      "epoch 162| loss: 0.62869 | train_accuracy: 0.74668 | valid_accuracy: 0.72449 |  0:00:30s\n",
      "epoch 163| loss: 0.63816 | train_accuracy: 0.74966 | valid_accuracy: 0.73231 |  0:00:30s\n",
      "epoch 164| loss: 0.62857 | train_accuracy: 0.7415  | valid_accuracy: 0.73061 |  0:00:31s\n",
      "epoch 165| loss: 0.63612 | train_accuracy: 0.73512 | valid_accuracy: 0.72245 |  0:00:31s\n",
      "epoch 166| loss: 0.64081 | train_accuracy: 0.73316 | valid_accuracy: 0.72449 |  0:00:31s\n",
      "epoch 167| loss: 0.63465 | train_accuracy: 0.73818 | valid_accuracy: 0.72653 |  0:00:31s\n",
      "epoch 168| loss: 0.62932 | train_accuracy: 0.74974 | valid_accuracy: 0.73095 |  0:00:31s\n",
      "epoch 169| loss: 0.63351 | train_accuracy: 0.74617 | valid_accuracy: 0.72891 |  0:00:32s\n",
      "epoch 170| loss: 0.6205  | train_accuracy: 0.75247 | valid_accuracy: 0.74354 |  0:00:32s\n",
      "epoch 171| loss: 0.63418 | train_accuracy: 0.74651 | valid_accuracy: 0.73265 |  0:00:32s\n",
      "epoch 172| loss: 0.62937 | train_accuracy: 0.74728 | valid_accuracy: 0.72857 |  0:00:32s\n",
      "epoch 173| loss: 0.62729 | train_accuracy: 0.74371 | valid_accuracy: 0.72449 |  0:00:32s\n",
      "epoch 174| loss: 0.6289  | train_accuracy: 0.74575 | valid_accuracy: 0.73061 |  0:00:33s\n",
      "epoch 175| loss: 0.62315 | train_accuracy: 0.74991 | valid_accuracy: 0.73741 |  0:00:33s\n",
      "epoch 176| loss: 0.62228 | train_accuracy: 0.74881 | valid_accuracy: 0.73333 |  0:00:33s\n",
      "epoch 177| loss: 0.62855 | train_accuracy: 0.74311 | valid_accuracy: 0.72619 |  0:00:33s\n",
      "epoch 178| loss: 0.63543 | train_accuracy: 0.73963 | valid_accuracy: 0.72347 |  0:00:33s\n",
      "epoch 179| loss: 0.62853 | train_accuracy: 0.74821 | valid_accuracy: 0.72585 |  0:00:33s\n",
      "epoch 180| loss: 0.63553 | train_accuracy: 0.74634 | valid_accuracy: 0.72517 |  0:00:34s\n",
      "epoch 181| loss: 0.63491 | train_accuracy: 0.74107 | valid_accuracy: 0.73469 |  0:00:34s\n",
      "epoch 182| loss: 0.62785 | train_accuracy: 0.74558 | valid_accuracy: 0.72925 |  0:00:34s\n",
      "epoch 183| loss: 0.62346 | train_accuracy: 0.74762 | valid_accuracy: 0.73776 |  0:00:34s\n",
      "epoch 184| loss: 0.62068 | train_accuracy: 0.74685 | valid_accuracy: 0.72789 |  0:00:34s\n",
      "epoch 185| loss: 0.62543 | train_accuracy: 0.74549 | valid_accuracy: 0.73776 |  0:00:35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186| loss: 0.62638 | train_accuracy: 0.74719 | valid_accuracy: 0.73299 |  0:00:35s\n",
      "epoch 187| loss: 0.62088 | train_accuracy: 0.7517  | valid_accuracy: 0.73435 |  0:00:35s\n",
      "epoch 188| loss: 0.62562 | train_accuracy: 0.74906 | valid_accuracy: 0.73537 |  0:00:35s\n",
      "epoch 189| loss: 0.62289 | train_accuracy: 0.75119 | valid_accuracy: 0.73401 |  0:00:35s\n",
      "epoch 190| loss: 0.6216  | train_accuracy: 0.75111 | valid_accuracy: 0.73197 |  0:00:36s\n",
      "epoch 191| loss: 0.62559 | train_accuracy: 0.74677 | valid_accuracy: 0.73469 |  0:00:36s\n",
      "epoch 192| loss: 0.62074 | train_accuracy: 0.74949 | valid_accuracy: 0.73844 |  0:00:36s\n",
      "epoch 193| loss: 0.62546 | train_accuracy: 0.74549 | valid_accuracy: 0.72653 |  0:00:36s\n",
      "epoch 194| loss: 0.62692 | train_accuracy: 0.73486 | valid_accuracy: 0.71327 |  0:00:36s\n",
      "epoch 195| loss: 0.62129 | train_accuracy: 0.74745 | valid_accuracy: 0.73299 |  0:00:37s\n",
      "\n",
      "Early stopping occurred at epoch 195 with best_epoch = 170 and best_valid_accuracy = 0.74354\n",
      "170\n",
      "170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.28344 | train_accuracy: 0.25731 | valid_accuracy: 0.25442 |  0:00:00s\n",
      "epoch 1  | loss: 1.0555  | train_accuracy: 0.2966  | valid_accuracy: 0.30136 |  0:00:00s\n",
      "epoch 2  | loss: 0.99378 | train_accuracy: 0.29821 | valid_accuracy: 0.3034  |  0:00:00s\n",
      "epoch 3  | loss: 0.95021 | train_accuracy: 0.27628 | valid_accuracy: 0.27687 |  0:00:00s\n",
      "epoch 4  | loss: 0.94029 | train_accuracy: 0.27245 | valid_accuracy: 0.27381 |  0:00:00s\n",
      "epoch 5  | loss: 0.91958 | train_accuracy: 0.29558 | valid_accuracy: 0.29694 |  0:00:01s\n",
      "epoch 6  | loss: 0.90863 | train_accuracy: 0.29456 | valid_accuracy: 0.29898 |  0:00:01s\n",
      "epoch 7  | loss: 0.89326 | train_accuracy: 0.35255 | valid_accuracy: 0.36224 |  0:00:01s\n",
      "epoch 8  | loss: 0.88018 | train_accuracy: 0.34592 | valid_accuracy: 0.3551  |  0:00:01s\n",
      "epoch 9  | loss: 0.87404 | train_accuracy: 0.35349 | valid_accuracy: 0.35544 |  0:00:01s\n",
      "epoch 10 | loss: 0.86842 | train_accuracy: 0.40289 | valid_accuracy: 0.42381 |  0:00:02s\n",
      "epoch 11 | loss: 0.87167 | train_accuracy: 0.38104 | valid_accuracy: 0.3898  |  0:00:02s\n",
      "epoch 12 | loss: 0.85678 | train_accuracy: 0.46837 | valid_accuracy: 0.48061 |  0:00:02s\n",
      "epoch 13 | loss: 0.85446 | train_accuracy: 0.43878 | valid_accuracy: 0.44966 |  0:00:02s\n",
      "epoch 14 | loss: 0.85102 | train_accuracy: 0.47704 | valid_accuracy: 0.48129 |  0:00:02s\n",
      "epoch 15 | loss: 0.83863 | train_accuracy: 0.4875  | valid_accuracy: 0.4983  |  0:00:03s\n",
      "epoch 16 | loss: 0.83605 | train_accuracy: 0.496   | valid_accuracy: 0.5034  |  0:00:03s\n",
      "epoch 17 | loss: 0.82723 | train_accuracy: 0.54864 | valid_accuracy: 0.54864 |  0:00:03s\n",
      "epoch 18 | loss: 0.83122 | train_accuracy: 0.54396 | valid_accuracy: 0.55034 |  0:00:03s\n",
      "epoch 19 | loss: 0.82895 | train_accuracy: 0.5381  | valid_accuracy: 0.53844 |  0:00:03s\n",
      "epoch 20 | loss: 0.82194 | train_accuracy: 0.56726 | valid_accuracy: 0.57211 |  0:00:03s\n",
      "epoch 21 | loss: 0.8195  | train_accuracy: 0.58724 | valid_accuracy: 0.59796 |  0:00:04s\n",
      "epoch 22 | loss: 0.81843 | train_accuracy: 0.59014 | valid_accuracy: 0.5983  |  0:00:04s\n",
      "epoch 23 | loss: 0.81136 | train_accuracy: 0.61165 | valid_accuracy: 0.6119  |  0:00:04s\n",
      "epoch 24 | loss: 0.81029 | train_accuracy: 0.59677 | valid_accuracy: 0.59864 |  0:00:04s\n",
      "epoch 25 | loss: 0.80781 | train_accuracy: 0.6085  | valid_accuracy: 0.60748 |  0:00:04s\n",
      "epoch 26 | loss: 0.80706 | train_accuracy: 0.62381 | valid_accuracy: 0.62279 |  0:00:05s\n",
      "epoch 27 | loss: 0.80865 | train_accuracy: 0.59983 | valid_accuracy: 0.60068 |  0:00:05s\n",
      "epoch 28 | loss: 0.80062 | train_accuracy: 0.64235 | valid_accuracy: 0.6449  |  0:00:05s\n",
      "epoch 29 | loss: 0.80479 | train_accuracy: 0.63937 | valid_accuracy: 0.63741 |  0:00:05s\n",
      "epoch 30 | loss: 0.789   | train_accuracy: 0.6426  | valid_accuracy: 0.64014 |  0:00:05s\n",
      "epoch 31 | loss: 0.79219 | train_accuracy: 0.63291 | valid_accuracy: 0.62347 |  0:00:06s\n",
      "epoch 32 | loss: 0.79161 | train_accuracy: 0.64405 | valid_accuracy: 0.63673 |  0:00:06s\n",
      "epoch 33 | loss: 0.77597 | train_accuracy: 0.64269 | valid_accuracy: 0.63503 |  0:00:06s\n",
      "epoch 34 | loss: 0.78105 | train_accuracy: 0.64991 | valid_accuracy: 0.65068 |  0:00:06s\n",
      "epoch 35 | loss: 0.77133 | train_accuracy: 0.65646 | valid_accuracy: 0.65    |  0:00:06s\n",
      "epoch 36 | loss: 0.77627 | train_accuracy: 0.66794 | valid_accuracy: 0.66156 |  0:00:06s\n",
      "epoch 37 | loss: 0.7689  | train_accuracy: 0.6557  | valid_accuracy: 0.65476 |  0:00:07s\n",
      "epoch 38 | loss: 0.78428 | train_accuracy: 0.65451 | valid_accuracy: 0.65544 |  0:00:07s\n",
      "epoch 39 | loss: 0.77902 | train_accuracy: 0.65476 | valid_accuracy: 0.64864 |  0:00:07s\n",
      "epoch 40 | loss: 0.7655  | train_accuracy: 0.66862 | valid_accuracy: 0.66871 |  0:00:07s\n",
      "epoch 41 | loss: 0.75966 | train_accuracy: 0.65714 | valid_accuracy: 0.66122 |  0:00:07s\n",
      "epoch 42 | loss: 0.75613 | train_accuracy: 0.66531 | valid_accuracy: 0.66939 |  0:00:08s\n",
      "epoch 43 | loss: 0.75343 | train_accuracy: 0.67279 | valid_accuracy: 0.67279 |  0:00:08s\n",
      "epoch 44 | loss: 0.75875 | train_accuracy: 0.67483 | valid_accuracy: 0.67245 |  0:00:08s\n",
      "epoch 45 | loss: 0.75591 | train_accuracy: 0.65825 | valid_accuracy: 0.65442 |  0:00:08s\n",
      "epoch 46 | loss: 0.74869 | train_accuracy: 0.67262 | valid_accuracy: 0.66122 |  0:00:08s\n",
      "epoch 47 | loss: 0.75456 | train_accuracy: 0.66046 | valid_accuracy: 0.65544 |  0:00:09s\n",
      "epoch 48 | loss: 0.76183 | train_accuracy: 0.65196 | valid_accuracy: 0.65442 |  0:00:09s\n",
      "epoch 49 | loss: 0.76972 | train_accuracy: 0.67917 | valid_accuracy: 0.67755 |  0:00:09s\n",
      "epoch 50 | loss: 0.76062 | train_accuracy: 0.65842 | valid_accuracy: 0.6551  |  0:00:09s\n",
      "epoch 51 | loss: 0.75657 | train_accuracy: 0.68639 | valid_accuracy: 0.67653 |  0:00:09s\n",
      "epoch 52 | loss: 0.75575 | train_accuracy: 0.66709 | valid_accuracy: 0.65816 |  0:00:10s\n",
      "epoch 53 | loss: 0.7544  | train_accuracy: 0.67951 | valid_accuracy: 0.67347 |  0:00:10s\n",
      "epoch 54 | loss: 0.75017 | train_accuracy: 0.6858  | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 55 | loss: 0.7435  | train_accuracy: 0.67976 | valid_accuracy: 0.67517 |  0:00:10s\n",
      "epoch 56 | loss: 0.73739 | train_accuracy: 0.68027 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 57 | loss: 0.74458 | train_accuracy: 0.6784  | valid_accuracy: 0.67551 |  0:00:10s\n",
      "epoch 58 | loss: 0.74699 | train_accuracy: 0.68291 | valid_accuracy: 0.67007 |  0:00:11s\n",
      "epoch 59 | loss: 0.73908 | train_accuracy: 0.67049 | valid_accuracy: 0.66565 |  0:00:11s\n",
      "epoch 60 | loss: 0.74277 | train_accuracy: 0.69413 | valid_accuracy: 0.67721 |  0:00:11s\n",
      "epoch 61 | loss: 0.73652 | train_accuracy: 0.67398 | valid_accuracy: 0.67381 |  0:00:11s\n",
      "epoch 62 | loss: 0.73385 | train_accuracy: 0.68503 | valid_accuracy: 0.68061 |  0:00:11s\n",
      "epoch 63 | loss: 0.72943 | train_accuracy: 0.67721 | valid_accuracy: 0.66871 |  0:00:12s\n",
      "epoch 64 | loss: 0.73156 | train_accuracy: 0.6898  | valid_accuracy: 0.68129 |  0:00:12s\n",
      "epoch 65 | loss: 0.73634 | train_accuracy: 0.69422 | valid_accuracy: 0.68265 |  0:00:12s\n",
      "epoch 66 | loss: 0.72859 | train_accuracy: 0.67355 | valid_accuracy: 0.67211 |  0:00:12s\n",
      "epoch 67 | loss: 0.72857 | train_accuracy: 0.6926  | valid_accuracy: 0.67993 |  0:00:12s\n",
      "epoch 68 | loss: 0.72512 | train_accuracy: 0.69966 | valid_accuracy: 0.6932  |  0:00:12s\n",
      "epoch 69 | loss: 0.72377 | train_accuracy: 0.69779 | valid_accuracy: 0.69116 |  0:00:13s\n",
      "epoch 70 | loss: 0.73493 | train_accuracy: 0.68435 | valid_accuracy: 0.67857 |  0:00:13s\n",
      "epoch 71 | loss: 0.72793 | train_accuracy: 0.68444 | valid_accuracy: 0.68163 |  0:00:13s\n",
      "epoch 72 | loss: 0.7175  | train_accuracy: 0.68852 | valid_accuracy: 0.67041 |  0:00:13s\n",
      "epoch 73 | loss: 0.73234 | train_accuracy: 0.68206 | valid_accuracy: 0.67789 |  0:00:13s\n",
      "epoch 74 | loss: 0.72045 | train_accuracy: 0.68784 | valid_accuracy: 0.68367 |  0:00:14s\n",
      "epoch 75 | loss: 0.71812 | train_accuracy: 0.69107 | valid_accuracy: 0.67279 |  0:00:14s\n",
      "epoch 76 | loss: 0.71484 | train_accuracy: 0.70374 | valid_accuracy: 0.6949  |  0:00:14s\n",
      "epoch 77 | loss: 0.71572 | train_accuracy: 0.69354 | valid_accuracy: 0.68027 |  0:00:14s\n",
      "epoch 78 | loss: 0.70608 | train_accuracy: 0.70349 | valid_accuracy: 0.68503 |  0:00:14s\n",
      "epoch 79 | loss: 0.71677 | train_accuracy: 0.69609 | valid_accuracy: 0.68844 |  0:00:15s\n",
      "epoch 80 | loss: 0.71708 | train_accuracy: 0.69473 | valid_accuracy: 0.68265 |  0:00:15s\n",
      "epoch 81 | loss: 0.71073 | train_accuracy: 0.70655 | valid_accuracy: 0.68844 |  0:00:15s\n",
      "epoch 82 | loss: 0.70554 | train_accuracy: 0.7     | valid_accuracy: 0.68605 |  0:00:15s\n",
      "epoch 83 | loss: 0.70513 | train_accuracy: 0.70519 | valid_accuracy: 0.6898  |  0:00:15s\n",
      "epoch 84 | loss: 0.69853 | train_accuracy: 0.70502 | valid_accuracy: 0.69898 |  0:00:16s\n",
      "epoch 85 | loss: 0.71029 | train_accuracy: 0.7074  | valid_accuracy: 0.69354 |  0:00:16s\n",
      "epoch 86 | loss: 0.70884 | train_accuracy: 0.69881 | valid_accuracy: 0.67857 |  0:00:16s\n",
      "epoch 87 | loss: 0.7196  | train_accuracy: 0.70434 | valid_accuracy: 0.68878 |  0:00:16s\n",
      "epoch 88 | loss: 0.71192 | train_accuracy: 0.68903 | valid_accuracy: 0.67755 |  0:00:16s\n",
      "epoch 89 | loss: 0.70199 | train_accuracy: 0.7034  | valid_accuracy: 0.69558 |  0:00:16s\n",
      "epoch 90 | loss: 0.70353 | train_accuracy: 0.71199 | valid_accuracy: 0.69796 |  0:00:17s\n",
      "epoch 91 | loss: 0.70238 | train_accuracy: 0.69541 | valid_accuracy: 0.68367 |  0:00:17s\n",
      "epoch 92 | loss: 0.70604 | train_accuracy: 0.7034  | valid_accuracy: 0.69592 |  0:00:17s\n",
      "epoch 93 | loss: 0.69629 | train_accuracy: 0.69558 | valid_accuracy: 0.68844 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 | loss: 0.69872 | train_accuracy: 0.70162 | valid_accuracy: 0.69116 |  0:00:17s\n",
      "epoch 95 | loss: 0.70695 | train_accuracy: 0.7148  | valid_accuracy: 0.70578 |  0:00:18s\n",
      "epoch 96 | loss: 0.69965 | train_accuracy: 0.70077 | valid_accuracy: 0.69354 |  0:00:18s\n",
      "epoch 97 | loss: 0.69163 | train_accuracy: 0.71216 | valid_accuracy: 0.70034 |  0:00:18s\n",
      "epoch 98 | loss: 0.69712 | train_accuracy: 0.6966  | valid_accuracy: 0.68095 |  0:00:18s\n",
      "epoch 99 | loss: 0.70317 | train_accuracy: 0.69243 | valid_accuracy: 0.68469 |  0:00:18s\n",
      "epoch 100| loss: 0.70748 | train_accuracy: 0.70995 | valid_accuracy: 0.6983  |  0:00:19s\n",
      "epoch 101| loss: 0.7033  | train_accuracy: 0.69906 | valid_accuracy: 0.6932  |  0:00:19s\n",
      "epoch 102| loss: 0.70562 | train_accuracy: 0.70689 | valid_accuracy: 0.70578 |  0:00:19s\n",
      "epoch 103| loss: 0.69433 | train_accuracy: 0.7159  | valid_accuracy: 0.70068 |  0:00:19s\n",
      "epoch 104| loss: 0.69272 | train_accuracy: 0.71573 | valid_accuracy: 0.69524 |  0:00:19s\n",
      "epoch 105| loss: 0.68665 | train_accuracy: 0.71267 | valid_accuracy: 0.70204 |  0:00:19s\n",
      "epoch 106| loss: 0.69516 | train_accuracy: 0.70026 | valid_accuracy: 0.68639 |  0:00:20s\n",
      "epoch 107| loss: 0.69001 | train_accuracy: 0.71633 | valid_accuracy: 0.69932 |  0:00:20s\n",
      "epoch 108| loss: 0.69257 | train_accuracy: 0.70782 | valid_accuracy: 0.70238 |  0:00:20s\n",
      "epoch 109| loss: 0.68964 | train_accuracy: 0.71318 | valid_accuracy: 0.6932  |  0:00:20s\n",
      "epoch 110| loss: 0.68861 | train_accuracy: 0.71675 | valid_accuracy: 0.70374 |  0:00:20s\n",
      "epoch 111| loss: 0.68961 | train_accuracy: 0.7034  | valid_accuracy: 0.69048 |  0:00:21s\n",
      "epoch 112| loss: 0.68145 | train_accuracy: 0.70952 | valid_accuracy: 0.69694 |  0:00:21s\n",
      "epoch 113| loss: 0.6793  | train_accuracy: 0.70714 | valid_accuracy: 0.6932  |  0:00:21s\n",
      "epoch 114| loss: 0.68191 | train_accuracy: 0.71429 | valid_accuracy: 0.69728 |  0:00:21s\n",
      "epoch 115| loss: 0.68685 | train_accuracy: 0.7074  | valid_accuracy: 0.70374 |  0:00:21s\n",
      "epoch 116| loss: 0.68252 | train_accuracy: 0.72058 | valid_accuracy: 0.7017  |  0:00:22s\n",
      "epoch 117| loss: 0.6793  | train_accuracy: 0.71607 | valid_accuracy: 0.69796 |  0:00:22s\n",
      "epoch 118| loss: 0.69298 | train_accuracy: 0.71139 | valid_accuracy: 0.69218 |  0:00:22s\n",
      "epoch 119| loss: 0.69031 | train_accuracy: 0.70986 | valid_accuracy: 0.69184 |  0:00:22s\n",
      "epoch 120| loss: 0.68713 | train_accuracy: 0.70918 | valid_accuracy: 0.69082 |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 120 with best_epoch = 95 and best_valid_accuracy = 0.70578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "95\n",
      "epoch 0  | loss: 1.23843 | train_accuracy: 0.27959 | valid_accuracy: 0.27007 |  0:00:00s\n",
      "epoch 1  | loss: 0.95868 | train_accuracy: 0.35306 | valid_accuracy: 0.35204 |  0:00:00s\n",
      "epoch 2  | loss: 0.9011  | train_accuracy: 0.17602 | valid_accuracy: 0.17517 |  0:00:00s\n",
      "epoch 3  | loss: 0.87617 | train_accuracy: 0.22917 | valid_accuracy: 0.23265 |  0:00:00s\n",
      "epoch 4  | loss: 0.86693 | train_accuracy: 0.2534  | valid_accuracy: 0.27143 |  0:00:00s\n",
      "epoch 5  | loss: 0.8525  | train_accuracy: 0.20578 | valid_accuracy: 0.21837 |  0:00:01s\n",
      "epoch 6  | loss: 0.83299 | train_accuracy: 0.22738 | valid_accuracy: 0.23707 |  0:00:01s\n",
      "epoch 7  | loss: 0.83451 | train_accuracy: 0.23189 | valid_accuracy: 0.24252 |  0:00:01s\n",
      "epoch 8  | loss: 0.82015 | train_accuracy: 0.2801  | valid_accuracy: 0.29218 |  0:00:01s\n",
      "epoch 9  | loss: 0.82068 | train_accuracy: 0.33291 | valid_accuracy: 0.35068 |  0:00:01s\n",
      "epoch 10 | loss: 0.82116 | train_accuracy: 0.43971 | valid_accuracy: 0.4449  |  0:00:02s\n",
      "epoch 11 | loss: 0.80958 | train_accuracy: 0.46735 | valid_accuracy: 0.46905 |  0:00:02s\n",
      "epoch 12 | loss: 0.80859 | train_accuracy: 0.41624 | valid_accuracy: 0.41633 |  0:00:02s\n",
      "epoch 13 | loss: 0.80973 | train_accuracy: 0.47713 | valid_accuracy: 0.47279 |  0:00:02s\n",
      "epoch 14 | loss: 0.80341 | train_accuracy: 0.50026 | valid_accuracy: 0.4949  |  0:00:02s\n",
      "epoch 15 | loss: 0.79741 | train_accuracy: 0.49762 | valid_accuracy: 0.49116 |  0:00:03s\n",
      "epoch 16 | loss: 0.79015 | train_accuracy: 0.51207 | valid_accuracy: 0.52755 |  0:00:03s\n",
      "epoch 17 | loss: 0.79117 | train_accuracy: 0.4892  | valid_accuracy: 0.48333 |  0:00:03s\n",
      "epoch 18 | loss: 0.79491 | train_accuracy: 0.54048 | valid_accuracy: 0.52993 |  0:00:03s\n",
      "epoch 19 | loss: 0.78443 | train_accuracy: 0.52304 | valid_accuracy: 0.51871 |  0:00:03s\n",
      "epoch 20 | loss: 0.77592 | train_accuracy: 0.53537 | valid_accuracy: 0.52551 |  0:00:04s\n",
      "epoch 21 | loss: 0.77378 | train_accuracy: 0.49566 | valid_accuracy: 0.47245 |  0:00:04s\n",
      "epoch 22 | loss: 0.78094 | train_accuracy: 0.57509 | valid_accuracy: 0.57381 |  0:00:04s\n",
      "epoch 23 | loss: 0.77291 | train_accuracy: 0.59566 | valid_accuracy: 0.58503 |  0:00:04s\n",
      "epoch 24 | loss: 0.76491 | train_accuracy: 0.58571 | valid_accuracy: 0.58333 |  0:00:04s\n",
      "epoch 25 | loss: 0.76759 | train_accuracy: 0.60306 | valid_accuracy: 0.59762 |  0:00:04s\n",
      "epoch 26 | loss: 0.77382 | train_accuracy: 0.59626 | valid_accuracy: 0.58299 |  0:00:05s\n",
      "epoch 27 | loss: 0.7736  | train_accuracy: 0.60995 | valid_accuracy: 0.5966  |  0:00:05s\n",
      "epoch 28 | loss: 0.78297 | train_accuracy: 0.61539 | valid_accuracy: 0.60612 |  0:00:05s\n",
      "epoch 29 | loss: 0.7818  | train_accuracy: 0.60077 | valid_accuracy: 0.58776 |  0:00:05s\n",
      "epoch 30 | loss: 0.78791 | train_accuracy: 0.64439 | valid_accuracy: 0.63401 |  0:00:05s\n",
      "epoch 31 | loss: 0.77661 | train_accuracy: 0.6199  | valid_accuracy: 0.60612 |  0:00:06s\n",
      "epoch 32 | loss: 0.76663 | train_accuracy: 0.63495 | valid_accuracy: 0.6119  |  0:00:06s\n",
      "epoch 33 | loss: 0.76017 | train_accuracy: 0.63478 | valid_accuracy: 0.62585 |  0:00:06s\n",
      "epoch 34 | loss: 0.76953 | train_accuracy: 0.64566 | valid_accuracy: 0.63027 |  0:00:06s\n",
      "epoch 35 | loss: 0.75536 | train_accuracy: 0.65502 | valid_accuracy: 0.63946 |  0:00:06s\n",
      "epoch 36 | loss: 0.75849 | train_accuracy: 0.63741 | valid_accuracy: 0.61565 |  0:00:07s\n",
      "epoch 37 | loss: 0.75865 | train_accuracy: 0.65162 | valid_accuracy: 0.64932 |  0:00:07s\n",
      "epoch 38 | loss: 0.7504  | train_accuracy: 0.65638 | valid_accuracy: 0.64932 |  0:00:07s\n",
      "epoch 39 | loss: 0.75501 | train_accuracy: 0.66293 | valid_accuracy: 0.65816 |  0:00:07s\n",
      "epoch 40 | loss: 0.74997 | train_accuracy: 0.66088 | valid_accuracy: 0.64694 |  0:00:07s\n",
      "epoch 41 | loss: 0.74585 | train_accuracy: 0.67645 | valid_accuracy: 0.67007 |  0:00:07s\n",
      "epoch 42 | loss: 0.74318 | train_accuracy: 0.66361 | valid_accuracy: 0.65476 |  0:00:08s\n",
      "epoch 43 | loss: 0.74491 | train_accuracy: 0.6727  | valid_accuracy: 0.66259 |  0:00:08s\n",
      "epoch 44 | loss: 0.74478 | train_accuracy: 0.67619 | valid_accuracy: 0.67075 |  0:00:08s\n",
      "epoch 45 | loss: 0.73788 | train_accuracy: 0.67185 | valid_accuracy: 0.66054 |  0:00:08s\n",
      "epoch 46 | loss: 0.74217 | train_accuracy: 0.67389 | valid_accuracy: 0.65442 |  0:00:08s\n",
      "epoch 47 | loss: 0.74727 | train_accuracy: 0.65867 | valid_accuracy: 0.6432  |  0:00:09s\n",
      "epoch 48 | loss: 0.74451 | train_accuracy: 0.67092 | valid_accuracy: 0.66735 |  0:00:09s\n",
      "epoch 49 | loss: 0.74121 | train_accuracy: 0.66709 | valid_accuracy: 0.65238 |  0:00:09s\n",
      "epoch 50 | loss: 0.7428  | train_accuracy: 0.66786 | valid_accuracy: 0.66122 |  0:00:09s\n",
      "epoch 51 | loss: 0.73745 | train_accuracy: 0.67406 | valid_accuracy: 0.66871 |  0:00:09s\n",
      "epoch 52 | loss: 0.72958 | train_accuracy: 0.67874 | valid_accuracy: 0.66701 |  0:00:10s\n",
      "epoch 53 | loss: 0.73337 | train_accuracy: 0.68282 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 54 | loss: 0.72882 | train_accuracy: 0.68571 | valid_accuracy: 0.67619 |  0:00:10s\n",
      "epoch 55 | loss: 0.72717 | train_accuracy: 0.67823 | valid_accuracy: 0.66327 |  0:00:10s\n",
      "epoch 56 | loss: 0.72971 | train_accuracy: 0.6665  | valid_accuracy: 0.6534  |  0:00:10s\n",
      "epoch 57 | loss: 0.73418 | train_accuracy: 0.67721 | valid_accuracy: 0.67075 |  0:00:10s\n",
      "epoch 58 | loss: 0.74179 | train_accuracy: 0.671   | valid_accuracy: 0.65    |  0:00:11s\n",
      "epoch 59 | loss: 0.74644 | train_accuracy: 0.68095 | valid_accuracy: 0.67687 |  0:00:11s\n",
      "epoch 60 | loss: 0.72335 | train_accuracy: 0.66837 | valid_accuracy: 0.65408 |  0:00:11s\n",
      "epoch 61 | loss: 0.72954 | train_accuracy: 0.67483 | valid_accuracy: 0.6619  |  0:00:11s\n",
      "epoch 62 | loss: 0.72484 | train_accuracy: 0.67543 | valid_accuracy: 0.65748 |  0:00:11s\n",
      "epoch 63 | loss: 0.72528 | train_accuracy: 0.67696 | valid_accuracy: 0.67075 |  0:00:12s\n",
      "epoch 64 | loss: 0.71794 | train_accuracy: 0.68903 | valid_accuracy: 0.67755 |  0:00:12s\n",
      "epoch 65 | loss: 0.7163  | train_accuracy: 0.68452 | valid_accuracy: 0.67381 |  0:00:12s\n",
      "epoch 66 | loss: 0.72016 | train_accuracy: 0.68759 | valid_accuracy: 0.67721 |  0:00:12s\n",
      "epoch 67 | loss: 0.72108 | train_accuracy: 0.67355 | valid_accuracy: 0.66259 |  0:00:12s\n",
      "epoch 68 | loss: 0.71944 | train_accuracy: 0.68495 | valid_accuracy: 0.68299 |  0:00:13s\n",
      "epoch 69 | loss: 0.71806 | train_accuracy: 0.68741 | valid_accuracy: 0.67143 |  0:00:13s\n",
      "epoch 70 | loss: 0.71089 | train_accuracy: 0.6943  | valid_accuracy: 0.68265 |  0:00:13s\n",
      "epoch 71 | loss: 0.7068  | train_accuracy: 0.69473 | valid_accuracy: 0.68163 |  0:00:13s\n",
      "epoch 72 | loss: 0.70857 | train_accuracy: 0.69447 | valid_accuracy: 0.68844 |  0:00:13s\n",
      "epoch 73 | loss: 0.70269 | train_accuracy: 0.69396 | valid_accuracy: 0.68367 |  0:00:14s\n",
      "epoch 74 | loss: 0.70525 | train_accuracy: 0.69277 | valid_accuracy: 0.67993 |  0:00:14s\n",
      "epoch 75 | loss: 0.69824 | train_accuracy: 0.68869 | valid_accuracy: 0.68231 |  0:00:14s\n",
      "epoch 76 | loss: 0.70771 | train_accuracy: 0.69311 | valid_accuracy: 0.68435 |  0:00:14s\n",
      "epoch 77 | loss: 0.69107 | train_accuracy: 0.6943  | valid_accuracy: 0.68333 |  0:00:14s\n",
      "epoch 78 | loss: 0.70361 | train_accuracy: 0.68138 | valid_accuracy: 0.66088 |  0:00:14s\n",
      "epoch 79 | loss: 0.70295 | train_accuracy: 0.69447 | valid_accuracy: 0.69558 |  0:00:15s\n",
      "epoch 80 | loss: 0.69369 | train_accuracy: 0.68895 | valid_accuracy: 0.68333 |  0:00:15s\n",
      "epoch 81 | loss: 0.69363 | train_accuracy: 0.6994  | valid_accuracy: 0.68639 |  0:00:15s\n",
      "epoch 82 | loss: 0.69326 | train_accuracy: 0.69558 | valid_accuracy: 0.69388 |  0:00:15s\n",
      "epoch 83 | loss: 0.69362 | train_accuracy: 0.69966 | valid_accuracy: 0.68537 |  0:00:15s\n",
      "epoch 84 | loss: 0.69131 | train_accuracy: 0.69413 | valid_accuracy: 0.67687 |  0:00:16s\n",
      "epoch 85 | loss: 0.70995 | train_accuracy: 0.69201 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 86 | loss: 0.69776 | train_accuracy: 0.69583 | valid_accuracy: 0.68537 |  0:00:16s\n",
      "epoch 87 | loss: 0.69752 | train_accuracy: 0.69864 | valid_accuracy: 0.68571 |  0:00:16s\n",
      "epoch 88 | loss: 0.69651 | train_accuracy: 0.69864 | valid_accuracy: 0.68878 |  0:00:16s\n",
      "epoch 89 | loss: 0.69823 | train_accuracy: 0.69804 | valid_accuracy: 0.67551 |  0:00:17s\n",
      "epoch 90 | loss: 0.69182 | train_accuracy: 0.70077 | valid_accuracy: 0.68367 |  0:00:17s\n",
      "epoch 91 | loss: 0.69018 | train_accuracy: 0.68546 | valid_accuracy: 0.66973 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 | loss: 0.69575 | train_accuracy: 0.69745 | valid_accuracy: 0.68878 |  0:00:17s\n",
      "epoch 93 | loss: 0.69473 | train_accuracy: 0.7     | valid_accuracy: 0.69184 |  0:00:17s\n",
      "epoch 94 | loss: 0.68595 | train_accuracy: 0.69736 | valid_accuracy: 0.68027 |  0:00:17s\n",
      "epoch 95 | loss: 0.68846 | train_accuracy: 0.69966 | valid_accuracy: 0.68435 |  0:00:18s\n",
      "epoch 96 | loss: 0.68652 | train_accuracy: 0.70204 | valid_accuracy: 0.6949  |  0:00:18s\n",
      "epoch 97 | loss: 0.68509 | train_accuracy: 0.696   | valid_accuracy: 0.68673 |  0:00:18s\n",
      "epoch 98 | loss: 0.68219 | train_accuracy: 0.69872 | valid_accuracy: 0.68707 |  0:00:18s\n",
      "epoch 99 | loss: 0.68601 | train_accuracy: 0.70136 | valid_accuracy: 0.68537 |  0:00:18s\n",
      "epoch 100| loss: 0.68166 | train_accuracy: 0.69481 | valid_accuracy: 0.68061 |  0:00:19s\n",
      "epoch 101| loss: 0.68821 | train_accuracy: 0.71063 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 102| loss: 0.69301 | train_accuracy: 0.70221 | valid_accuracy: 0.67959 |  0:00:19s\n",
      "epoch 103| loss: 0.68292 | train_accuracy: 0.70782 | valid_accuracy: 0.68946 |  0:00:19s\n",
      "epoch 104| loss: 0.68322 | train_accuracy: 0.70357 | valid_accuracy: 0.6932  |  0:00:19s\n",
      "epoch 105| loss: 0.67751 | train_accuracy: 0.70349 | valid_accuracy: 0.68673 |  0:00:20s\n",
      "epoch 106| loss: 0.69268 | train_accuracy: 0.69626 | valid_accuracy: 0.68265 |  0:00:20s\n",
      "epoch 107| loss: 0.6876  | train_accuracy: 0.70391 | valid_accuracy: 0.68946 |  0:00:20s\n",
      "epoch 108| loss: 0.67868 | train_accuracy: 0.70901 | valid_accuracy: 0.69762 |  0:00:20s\n",
      "epoch 109| loss: 0.68674 | train_accuracy: 0.69592 | valid_accuracy: 0.68469 |  0:00:20s\n",
      "epoch 110| loss: 0.67786 | train_accuracy: 0.69711 | valid_accuracy: 0.69388 |  0:00:20s\n",
      "epoch 111| loss: 0.68496 | train_accuracy: 0.69864 | valid_accuracy: 0.68333 |  0:00:21s\n",
      "epoch 112| loss: 0.68078 | train_accuracy: 0.70357 | valid_accuracy: 0.6966  |  0:00:21s\n",
      "epoch 113| loss: 0.67861 | train_accuracy: 0.69745 | valid_accuracy: 0.68776 |  0:00:21s\n",
      "epoch 114| loss: 0.67788 | train_accuracy: 0.70485 | valid_accuracy: 0.69762 |  0:00:21s\n",
      "epoch 115| loss: 0.67429 | train_accuracy: 0.70238 | valid_accuracy: 0.6881  |  0:00:21s\n",
      "epoch 116| loss: 0.67716 | train_accuracy: 0.70995 | valid_accuracy: 0.70102 |  0:00:22s\n",
      "epoch 117| loss: 0.67711 | train_accuracy: 0.70859 | valid_accuracy: 0.69524 |  0:00:22s\n",
      "epoch 118| loss: 0.67718 | train_accuracy: 0.70672 | valid_accuracy: 0.68844 |  0:00:22s\n",
      "epoch 119| loss: 0.6648  | train_accuracy: 0.71327 | valid_accuracy: 0.69728 |  0:00:22s\n",
      "epoch 120| loss: 0.67069 | train_accuracy: 0.71216 | valid_accuracy: 0.70136 |  0:00:22s\n",
      "epoch 121| loss: 0.66414 | train_accuracy: 0.7125  | valid_accuracy: 0.70442 |  0:00:23s\n",
      "epoch 122| loss: 0.67499 | train_accuracy: 0.71259 | valid_accuracy: 0.7051  |  0:00:23s\n",
      "epoch 123| loss: 0.66541 | train_accuracy: 0.71743 | valid_accuracy: 0.7051  |  0:00:23s\n",
      "epoch 124| loss: 0.66675 | train_accuracy: 0.71029 | valid_accuracy: 0.69286 |  0:00:23s\n",
      "epoch 125| loss: 0.67357 | train_accuracy: 0.70859 | valid_accuracy: 0.68503 |  0:00:23s\n",
      "epoch 126| loss: 0.67501 | train_accuracy: 0.71139 | valid_accuracy: 0.69388 |  0:00:24s\n",
      "epoch 127| loss: 0.66869 | train_accuracy: 0.70697 | valid_accuracy: 0.67993 |  0:00:24s\n",
      "epoch 128| loss: 0.67312 | train_accuracy: 0.70655 | valid_accuracy: 0.69728 |  0:00:24s\n",
      "epoch 129| loss: 0.67873 | train_accuracy: 0.70782 | valid_accuracy: 0.69558 |  0:00:24s\n",
      "epoch 130| loss: 0.66275 | train_accuracy: 0.71471 | valid_accuracy: 0.70102 |  0:00:24s\n",
      "epoch 131| loss: 0.66325 | train_accuracy: 0.71046 | valid_accuracy: 0.68673 |  0:00:24s\n",
      "epoch 132| loss: 0.66735 | train_accuracy: 0.71582 | valid_accuracy: 0.70544 |  0:00:25s\n",
      "epoch 133| loss: 0.66614 | train_accuracy: 0.71599 | valid_accuracy: 0.69864 |  0:00:25s\n",
      "epoch 134| loss: 0.66802 | train_accuracy: 0.71658 | valid_accuracy: 0.7051  |  0:00:25s\n",
      "epoch 135| loss: 0.66506 | train_accuracy: 0.71752 | valid_accuracy: 0.70442 |  0:00:25s\n",
      "epoch 136| loss: 0.66247 | train_accuracy: 0.71854 | valid_accuracy: 0.70476 |  0:00:25s\n",
      "epoch 137| loss: 0.66334 | train_accuracy: 0.71454 | valid_accuracy: 0.69286 |  0:00:26s\n",
      "epoch 138| loss: 0.66251 | train_accuracy: 0.71437 | valid_accuracy: 0.70068 |  0:00:26s\n",
      "epoch 139| loss: 0.66727 | train_accuracy: 0.71548 | valid_accuracy: 0.6966  |  0:00:26s\n",
      "epoch 140| loss: 0.66288 | train_accuracy: 0.71497 | valid_accuracy: 0.7     |  0:00:26s\n",
      "epoch 141| loss: 0.65962 | train_accuracy: 0.71063 | valid_accuracy: 0.68878 |  0:00:26s\n",
      "epoch 142| loss: 0.66579 | train_accuracy: 0.71718 | valid_accuracy: 0.69456 |  0:00:27s\n",
      "epoch 143| loss: 0.66048 | train_accuracy: 0.7176  | valid_accuracy: 0.70748 |  0:00:27s\n",
      "epoch 144| loss: 0.65752 | train_accuracy: 0.71548 | valid_accuracy: 0.7     |  0:00:27s\n",
      "epoch 145| loss: 0.65871 | train_accuracy: 0.7165  | valid_accuracy: 0.70068 |  0:00:27s\n",
      "epoch 146| loss: 0.65512 | train_accuracy: 0.72066 | valid_accuracy: 0.69762 |  0:00:27s\n",
      "epoch 147| loss: 0.66548 | train_accuracy: 0.71828 | valid_accuracy: 0.70068 |  0:00:27s\n",
      "epoch 148| loss: 0.66215 | train_accuracy: 0.71879 | valid_accuracy: 0.70816 |  0:00:28s\n",
      "epoch 149| loss: 0.65734 | train_accuracy: 0.72134 | valid_accuracy: 0.7068  |  0:00:28s\n",
      "epoch 150| loss: 0.6586  | train_accuracy: 0.7176  | valid_accuracy: 0.69932 |  0:00:28s\n",
      "epoch 151| loss: 0.65308 | train_accuracy: 0.71922 | valid_accuracy: 0.70408 |  0:00:28s\n",
      "epoch 152| loss: 0.65936 | train_accuracy: 0.71862 | valid_accuracy: 0.7051  |  0:00:28s\n",
      "epoch 153| loss: 0.65748 | train_accuracy: 0.72194 | valid_accuracy: 0.7051  |  0:00:29s\n",
      "epoch 154| loss: 0.6599  | train_accuracy: 0.7148  | valid_accuracy: 0.71122 |  0:00:29s\n",
      "epoch 155| loss: 0.65307 | train_accuracy: 0.71854 | valid_accuracy: 0.70476 |  0:00:29s\n",
      "epoch 156| loss: 0.65061 | train_accuracy: 0.72313 | valid_accuracy: 0.7068  |  0:00:29s\n",
      "epoch 157| loss: 0.65958 | train_accuracy: 0.72049 | valid_accuracy: 0.70884 |  0:00:29s\n",
      "epoch 158| loss: 0.65602 | train_accuracy: 0.71913 | valid_accuracy: 0.7068  |  0:00:30s\n",
      "epoch 159| loss: 0.66021 | train_accuracy: 0.72789 | valid_accuracy: 0.70816 |  0:00:30s\n",
      "epoch 160| loss: 0.65434 | train_accuracy: 0.71361 | valid_accuracy: 0.70476 |  0:00:30s\n",
      "epoch 161| loss: 0.64958 | train_accuracy: 0.72594 | valid_accuracy: 0.71224 |  0:00:30s\n",
      "epoch 162| loss: 0.65051 | train_accuracy: 0.72236 | valid_accuracy: 0.70782 |  0:00:30s\n",
      "epoch 163| loss: 0.65473 | train_accuracy: 0.72245 | valid_accuracy: 0.70442 |  0:00:30s\n",
      "epoch 164| loss: 0.64427 | train_accuracy: 0.72823 | valid_accuracy: 0.70884 |  0:00:31s\n",
      "epoch 165| loss: 0.64964 | train_accuracy: 0.72219 | valid_accuracy: 0.70476 |  0:00:31s\n",
      "epoch 166| loss: 0.64467 | train_accuracy: 0.72704 | valid_accuracy: 0.70816 |  0:00:31s\n",
      "epoch 167| loss: 0.66109 | train_accuracy: 0.72296 | valid_accuracy: 0.70646 |  0:00:31s\n",
      "epoch 168| loss: 0.65343 | train_accuracy: 0.72679 | valid_accuracy: 0.70714 |  0:00:31s\n",
      "epoch 169| loss: 0.64647 | train_accuracy: 0.73053 | valid_accuracy: 0.71497 |  0:00:32s\n",
      "epoch 170| loss: 0.65052 | train_accuracy: 0.72202 | valid_accuracy: 0.71361 |  0:00:32s\n",
      "epoch 171| loss: 0.65151 | train_accuracy: 0.71879 | valid_accuracy: 0.69728 |  0:00:32s\n",
      "epoch 172| loss: 0.65234 | train_accuracy: 0.73019 | valid_accuracy: 0.71293 |  0:00:32s\n",
      "epoch 173| loss: 0.65015 | train_accuracy: 0.72543 | valid_accuracy: 0.71395 |  0:00:32s\n",
      "epoch 174| loss: 0.65382 | train_accuracy: 0.72713 | valid_accuracy: 0.71122 |  0:00:33s\n",
      "epoch 175| loss: 0.63998 | train_accuracy: 0.72594 | valid_accuracy: 0.70782 |  0:00:33s\n",
      "epoch 176| loss: 0.64879 | train_accuracy: 0.72959 | valid_accuracy: 0.7068  |  0:00:33s\n",
      "epoch 177| loss: 0.64406 | train_accuracy: 0.73112 | valid_accuracy: 0.71395 |  0:00:33s\n",
      "epoch 178| loss: 0.64445 | train_accuracy: 0.72568 | valid_accuracy: 0.71224 |  0:00:33s\n",
      "epoch 179| loss: 0.64245 | train_accuracy: 0.73376 | valid_accuracy: 0.71224 |  0:00:34s\n",
      "epoch 180| loss: 0.64139 | train_accuracy: 0.73129 | valid_accuracy: 0.71293 |  0:00:34s\n",
      "epoch 181| loss: 0.64238 | train_accuracy: 0.72738 | valid_accuracy: 0.7085  |  0:00:34s\n",
      "epoch 182| loss: 0.64895 | train_accuracy: 0.72798 | valid_accuracy: 0.71327 |  0:00:34s\n",
      "epoch 183| loss: 0.65132 | train_accuracy: 0.73163 | valid_accuracy: 0.70952 |  0:00:34s\n",
      "epoch 184| loss: 0.64951 | train_accuracy: 0.72934 | valid_accuracy: 0.71599 |  0:00:34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185| loss: 0.65068 | train_accuracy: 0.72534 | valid_accuracy: 0.70816 |  0:00:35s\n",
      "epoch 186| loss: 0.64193 | train_accuracy: 0.72415 | valid_accuracy: 0.70782 |  0:00:35s\n",
      "epoch 187| loss: 0.64076 | train_accuracy: 0.72551 | valid_accuracy: 0.71293 |  0:00:35s\n",
      "epoch 188| loss: 0.64743 | train_accuracy: 0.72934 | valid_accuracy: 0.71905 |  0:00:35s\n",
      "epoch 189| loss: 0.635   | train_accuracy: 0.73189 | valid_accuracy: 0.71905 |  0:00:35s\n",
      "epoch 190| loss: 0.6436  | train_accuracy: 0.72543 | valid_accuracy: 0.70612 |  0:00:36s\n",
      "epoch 191| loss: 0.64317 | train_accuracy: 0.73495 | valid_accuracy: 0.71769 |  0:00:36s\n",
      "epoch 192| loss: 0.6409  | train_accuracy: 0.73707 | valid_accuracy: 0.7102  |  0:00:36s\n",
      "epoch 193| loss: 0.6406  | train_accuracy: 0.73418 | valid_accuracy: 0.71531 |  0:00:36s\n",
      "epoch 194| loss: 0.63919 | train_accuracy: 0.73197 | valid_accuracy: 0.72109 |  0:00:36s\n",
      "epoch 195| loss: 0.64378 | train_accuracy: 0.72815 | valid_accuracy: 0.71156 |  0:00:36s\n",
      "epoch 196| loss: 0.64795 | train_accuracy: 0.72968 | valid_accuracy: 0.71633 |  0:00:37s\n",
      "epoch 197| loss: 0.64372 | train_accuracy: 0.73129 | valid_accuracy: 0.71667 |  0:00:37s\n",
      "epoch 198| loss: 0.64472 | train_accuracy: 0.73257 | valid_accuracy: 0.72313 |  0:00:37s\n",
      "epoch 199| loss: 0.6408  | train_accuracy: 0.7307  | valid_accuracy: 0.71599 |  0:00:37s\n",
      "epoch 200| loss: 0.64346 | train_accuracy: 0.73537 | valid_accuracy: 0.71497 |  0:00:37s\n",
      "epoch 201| loss: 0.63198 | train_accuracy: 0.73614 | valid_accuracy: 0.71599 |  0:00:38s\n",
      "epoch 202| loss: 0.63592 | train_accuracy: 0.73308 | valid_accuracy: 0.71054 |  0:00:38s\n",
      "epoch 203| loss: 0.6375  | train_accuracy: 0.73248 | valid_accuracy: 0.71735 |  0:00:38s\n",
      "epoch 204| loss: 0.63119 | train_accuracy: 0.73724 | valid_accuracy: 0.71259 |  0:00:38s\n",
      "epoch 205| loss: 0.6381  | train_accuracy: 0.7335  | valid_accuracy: 0.71224 |  0:00:38s\n",
      "epoch 206| loss: 0.63797 | train_accuracy: 0.7335  | valid_accuracy: 0.72211 |  0:00:39s\n",
      "epoch 207| loss: 0.6359  | train_accuracy: 0.73503 | valid_accuracy: 0.71463 |  0:00:39s\n",
      "epoch 208| loss: 0.63985 | train_accuracy: 0.7307  | valid_accuracy: 0.71259 |  0:00:39s\n",
      "epoch 209| loss: 0.63685 | train_accuracy: 0.73707 | valid_accuracy: 0.71701 |  0:00:39s\n",
      "epoch 210| loss: 0.63246 | train_accuracy: 0.73019 | valid_accuracy: 0.70408 |  0:00:39s\n",
      "epoch 211| loss: 0.62954 | train_accuracy: 0.73376 | valid_accuracy: 0.71667 |  0:00:40s\n",
      "epoch 212| loss: 0.63986 | train_accuracy: 0.73104 | valid_accuracy: 0.71701 |  0:00:40s\n",
      "epoch 213| loss: 0.64163 | train_accuracy: 0.73265 | valid_accuracy: 0.70646 |  0:00:40s\n",
      "epoch 214| loss: 0.64028 | train_accuracy: 0.73546 | valid_accuracy: 0.71497 |  0:00:40s\n",
      "epoch 215| loss: 0.63867 | train_accuracy: 0.73588 | valid_accuracy: 0.71122 |  0:00:40s\n",
      "epoch 216| loss: 0.64357 | train_accuracy: 0.73869 | valid_accuracy: 0.71837 |  0:00:40s\n",
      "epoch 217| loss: 0.63352 | train_accuracy: 0.73835 | valid_accuracy: 0.71701 |  0:00:41s\n",
      "epoch 218| loss: 0.63669 | train_accuracy: 0.73095 | valid_accuracy: 0.71837 |  0:00:41s\n",
      "epoch 219| loss: 0.64203 | train_accuracy: 0.73138 | valid_accuracy: 0.71939 |  0:00:41s\n",
      "epoch 220| loss: 0.62518 | train_accuracy: 0.73469 | valid_accuracy: 0.71701 |  0:00:41s\n",
      "epoch 221| loss: 0.63838 | train_accuracy: 0.73231 | valid_accuracy: 0.71565 |  0:00:41s\n",
      "epoch 222| loss: 0.63824 | train_accuracy: 0.73359 | valid_accuracy: 0.7085  |  0:00:42s\n",
      "epoch 223| loss: 0.63023 | train_accuracy: 0.73946 | valid_accuracy: 0.71361 |  0:00:42s\n",
      "\n",
      "Early stopping occurred at epoch 223 with best_epoch = 198 and best_valid_accuracy = 0.72313\n",
      "220\n",
      "198\n",
      "Fold 1: Train Accuracy=0.7166, Valid Accuracy=0.6966, Epoch = 151\n",
      "Fold 2: Train Accuracy=0.7539, Valid Accuracy=0.7333, Epoch = 286\n",
      "Fold 3: Train Accuracy=0.7525, Valid Accuracy=0.7435, Epoch = 170\n",
      "Fold 4: Train Accuracy=0.7071, Valid Accuracy=0.6932, Epoch = 113\n",
      "Fold 5: Train Accuracy=0.7347, Valid Accuracy=0.7170, Epoch = 220\n",
      "Mean Train Accuracy=0.7330, Mean Valid Accuracy=0.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "비지도를 하지 않고 지도 학습만 수행 하는 경우\n",
    "(준지도 학습과 지도 학습의 성능 차이를 비교하기 위함)\n",
    "'''\n",
    "import torch\n",
    "import pytorch_tabnet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 데이터를 나누기 위한 K 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "best_train_accuracies = []\n",
    "best_valid_accuracies = []\n",
    "\n",
    "epoch_idx = []\n",
    "\n",
    "dict_train = {}\n",
    "dict_val = {}\n",
    "\n",
    "keys = 0\n",
    "\n",
    "# K-fold 교차 검증 반복\n",
    "for train_idx, val_idx in kf.split(x_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_idx], x_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # 모델 초기화\n",
    "    clf2 = TabNetClassifier(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=3e-2),\n",
    "        scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                         \"gamma\":0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type='sparsemax' # \"sparsemax\"\n",
    "    )\n",
    "\n",
    "    # fit the model \n",
    "    clf2.fit(\n",
    "        X_train_fold , y_train_fold,\n",
    "        eval_set=[(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=1000 , patience=25\n",
    "    )    \n",
    "    \n",
    "    \n",
    "    # 가장 작은 loss 를 기준으로 train accuracy, valid accuracy 값 저장\n",
    "    best_idx =clf2.history['loss'].index(min(clf2.history['loss']))\n",
    "    best_train_accuracy = clf2.history['train_accuracy'][best_idx]\n",
    "    best_valid_accuracy = clf2.history['valid_accuracy'][best_idx]\n",
    "    best_train_accuracies.append(best_train_accuracy)\n",
    "    best_valid_accuracies.append(best_valid_accuracy)\n",
    "    \n",
    "    # 폴드별 train accuracy와 valid accuracy 기록\n",
    "    train_accuracies.append(clf2.history['train_accuracy'][best_idx])\n",
    "    valid_accuracies.append(clf2.history['valid_accuracy'][best_idx])\n",
    "    \n",
    "    \n",
    "    # fold 별 train, valid accuracy 평균으로 plot 을 위함\n",
    "    dict_train[keys] = clf2.history['train_accuracy']\n",
    "    dict_val[keys] = clf2.history['valid_accuracy']\n",
    "    keys +=1\n",
    "    \n",
    "    print(clf2.history['loss'].index(min(clf2.history['loss'])))\n",
    "    print(clf2.history['valid_accuracy'].index(max(clf2.history['valid_accuracy'])))\n",
    "    \n",
    "    epoch_idx.append(best_idx)\n",
    "    \n",
    "# 폴드별 best train accuracy와 valid accuracy 출력\n",
    "for i, (train_acc, valid_acc) in enumerate(zip(best_train_accuracies, best_valid_accuracies)):\n",
    "    print(f\"Fold {i+1}: Train Accuracy={train_acc:.4f}, Valid Accuracy={valid_acc:.4f}, Epoch = {epoch_idx[i]}\")\n",
    "\n",
    "# Train accuracy와 valid accuracy의 평균 계산\n",
    "mean_train_accuracy = np.mean(best_train_accuracies)\n",
    "mean_valid_accuracy = np.mean(best_valid_accuracies)\n",
    "\n",
    "print(f\"Mean Train Accuracy={mean_train_accuracy:.4f}, Mean Valid Accuracy={mean_valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0dd516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./tabnet_model_test_2.zip\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_2\"\n",
    "saved_filepath = clf2.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "K-Fold 는 알아서 train val 을 나눠준다. \n",
    "따라서, 우리는 test랑 k-fold 에서 나눠준 validation set이랑 비교하면 된다.\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = clf2.predict(x_test)\n",
    "test_acc = accuracy_score(preds, y_test)\n",
    "\n",
    "preds_valid = clf2.predict(X_val_fold)\n",
    "valid_acc = accuracy_score(preds_valid, y_val_fold)\n",
    "\n",
    "print(\"Accuracy score on validation set:\", valid_acc)\n",
    "print(\"Accuracy score on test set: \",test_acc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a49f1194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2372, 9)\n",
      "(2372,)\n",
      "(5880, 9)\n",
      "(1470, 9)\n",
      "(5880,)\n",
      "(1470,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape) # test 셋\n",
    "print(y_test.shape)\n",
    "print(X_train_fold.shape) # smote 이후 train 셋\n",
    "print(X_val_fold.shape)   # smote 이후 valid 셋 \n",
    "print(y_train_fold.shape)\n",
    "print(y_val_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334e094",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning (Collison unsupervised (weight) -> ECS supervised )\n",
    "# 준지도 학습의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91daa4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.30235 | train_accuracy: 0.41199 | valid_accuracy: 0.39524 |  0:00:00s\n",
      "epoch 1  | loss: 1.01943 | train_accuracy: 0.39898 | valid_accuracy: 0.38231 |  0:00:00s\n",
      "epoch 2  | loss: 0.95734 | train_accuracy: 0.38767 | valid_accuracy: 0.37381 |  0:00:00s\n",
      "epoch 3  | loss: 0.92054 | train_accuracy: 0.41701 | valid_accuracy: 0.40952 |  0:00:00s\n",
      "epoch 4  | loss: 0.88325 | train_accuracy: 0.37466 | valid_accuracy: 0.36905 |  0:00:00s\n",
      "epoch 5  | loss: 0.86975 | train_accuracy: 0.39677 | valid_accuracy: 0.38707 |  0:00:01s\n",
      "epoch 6  | loss: 0.85663 | train_accuracy: 0.40374 | valid_accuracy: 0.40374 |  0:00:01s\n",
      "epoch 7  | loss: 0.83982 | train_accuracy: 0.37219 | valid_accuracy: 0.36973 |  0:00:01s\n",
      "epoch 8  | loss: 0.82817 | train_accuracy: 0.41998 | valid_accuracy: 0.42143 |  0:00:01s\n",
      "epoch 9  | loss: 0.82395 | train_accuracy: 0.46641 | valid_accuracy: 0.46054 |  0:00:01s\n",
      "epoch 10 | loss: 0.81273 | train_accuracy: 0.45527 | valid_accuracy: 0.46088 |  0:00:02s\n",
      "epoch 11 | loss: 0.80962 | train_accuracy: 0.45434 | valid_accuracy: 0.4534  |  0:00:02s\n",
      "epoch 12 | loss: 0.80971 | train_accuracy: 0.51437 | valid_accuracy: 0.51531 |  0:00:02s\n",
      "epoch 13 | loss: 0.80933 | train_accuracy: 0.52985 | valid_accuracy: 0.52653 |  0:00:02s\n",
      "epoch 14 | loss: 0.80828 | train_accuracy: 0.52934 | valid_accuracy: 0.52687 |  0:00:02s\n",
      "epoch 15 | loss: 0.80723 | train_accuracy: 0.57474 | valid_accuracy: 0.5602  |  0:00:03s\n",
      "epoch 16 | loss: 0.79721 | train_accuracy: 0.60017 | valid_accuracy: 0.58095 |  0:00:03s\n",
      "epoch 17 | loss: 0.78894 | train_accuracy: 0.57849 | valid_accuracy: 0.57347 |  0:00:03s\n",
      "epoch 18 | loss: 0.7882  | train_accuracy: 0.61803 | valid_accuracy: 0.61224 |  0:00:03s\n",
      "epoch 19 | loss: 0.78343 | train_accuracy: 0.604   | valid_accuracy: 0.58707 |  0:00:03s\n",
      "epoch 20 | loss: 0.78731 | train_accuracy: 0.62381 | valid_accuracy: 0.60918 |  0:00:04s\n",
      "epoch 21 | loss: 0.7682  | train_accuracy: 0.59354 | valid_accuracy: 0.57925 |  0:00:04s\n",
      "epoch 22 | loss: 0.77208 | train_accuracy: 0.64082 | valid_accuracy: 0.62585 |  0:00:04s\n",
      "epoch 23 | loss: 0.77102 | train_accuracy: 0.58639 | valid_accuracy: 0.57993 |  0:00:04s\n",
      "epoch 24 | loss: 0.76905 | train_accuracy: 0.63912 | valid_accuracy: 0.62721 |  0:00:04s\n",
      "epoch 25 | loss: 0.759   | train_accuracy: 0.64983 | valid_accuracy: 0.63469 |  0:00:04s\n",
      "epoch 26 | loss: 0.75496 | train_accuracy: 0.64388 | valid_accuracy: 0.63197 |  0:00:05s\n",
      "epoch 27 | loss: 0.75703 | train_accuracy: 0.65978 | valid_accuracy: 0.64966 |  0:00:05s\n",
      "epoch 28 | loss: 0.75212 | train_accuracy: 0.66301 | valid_accuracy: 0.65272 |  0:00:05s\n",
      "epoch 29 | loss: 0.75182 | train_accuracy: 0.65417 | valid_accuracy: 0.63197 |  0:00:05s\n",
      "epoch 30 | loss: 0.7503  | train_accuracy: 0.66224 | valid_accuracy: 0.64864 |  0:00:06s\n",
      "epoch 31 | loss: 0.74934 | train_accuracy: 0.66386 | valid_accuracy: 0.65884 |  0:00:06s\n",
      "epoch 32 | loss: 0.74139 | train_accuracy: 0.64694 | valid_accuracy: 0.62823 |  0:00:06s\n",
      "epoch 33 | loss: 0.75616 | train_accuracy: 0.65264 | valid_accuracy: 0.6449  |  0:00:06s\n",
      "epoch 34 | loss: 0.75506 | train_accuracy: 0.67372 | valid_accuracy: 0.65544 |  0:00:06s\n",
      "epoch 35 | loss: 0.7499  | train_accuracy: 0.66556 | valid_accuracy: 0.6432  |  0:00:06s\n",
      "epoch 36 | loss: 0.73752 | train_accuracy: 0.68087 | valid_accuracy: 0.66565 |  0:00:07s\n",
      "epoch 37 | loss: 0.74185 | train_accuracy: 0.6807  | valid_accuracy: 0.66735 |  0:00:07s\n",
      "epoch 38 | loss: 0.73185 | train_accuracy: 0.68946 | valid_accuracy: 0.67075 |  0:00:07s\n",
      "epoch 39 | loss: 0.7286  | train_accuracy: 0.67304 | valid_accuracy: 0.65782 |  0:00:07s\n",
      "epoch 40 | loss: 0.72891 | train_accuracy: 0.67474 | valid_accuracy: 0.65918 |  0:00:07s\n",
      "epoch 41 | loss: 0.73148 | train_accuracy: 0.68393 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 42 | loss: 0.72753 | train_accuracy: 0.68844 | valid_accuracy: 0.66633 |  0:00:08s\n",
      "epoch 43 | loss: 0.72437 | train_accuracy: 0.66505 | valid_accuracy: 0.64898 |  0:00:08s\n",
      "epoch 44 | loss: 0.71886 | train_accuracy: 0.68214 | valid_accuracy: 0.66497 |  0:00:08s\n",
      "epoch 45 | loss: 0.72501 | train_accuracy: 0.68333 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 46 | loss: 0.72123 | train_accuracy: 0.69175 | valid_accuracy: 0.66701 |  0:00:09s\n",
      "epoch 47 | loss: 0.7149  | train_accuracy: 0.69167 | valid_accuracy: 0.67313 |  0:00:09s\n",
      "epoch 48 | loss: 0.72006 | train_accuracy: 0.69464 | valid_accuracy: 0.68197 |  0:00:09s\n",
      "epoch 49 | loss: 0.72014 | train_accuracy: 0.68997 | valid_accuracy: 0.66293 |  0:00:09s\n",
      "epoch 50 | loss: 0.71148 | train_accuracy: 0.70357 | valid_accuracy: 0.67925 |  0:00:09s\n",
      "epoch 51 | loss: 0.70739 | train_accuracy: 0.69558 | valid_accuracy: 0.66871 |  0:00:10s\n",
      "epoch 52 | loss: 0.71689 | train_accuracy: 0.68631 | valid_accuracy: 0.66701 |  0:00:10s\n",
      "epoch 53 | loss: 0.71959 | train_accuracy: 0.69915 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 54 | loss: 0.71249 | train_accuracy: 0.68308 | valid_accuracy: 0.66701 |  0:00:10s\n",
      "epoch 55 | loss: 0.71701 | train_accuracy: 0.696   | valid_accuracy: 0.68163 |  0:00:10s\n",
      "epoch 56 | loss: 0.70783 | train_accuracy: 0.70612 | valid_accuracy: 0.67823 |  0:00:10s\n",
      "epoch 57 | loss: 0.70435 | train_accuracy: 0.69464 | valid_accuracy: 0.67177 |  0:00:11s\n",
      "epoch 58 | loss: 0.70305 | train_accuracy: 0.70468 | valid_accuracy: 0.68061 |  0:00:11s\n",
      "epoch 59 | loss: 0.69993 | train_accuracy: 0.70663 | valid_accuracy: 0.68605 |  0:00:11s\n",
      "epoch 60 | loss: 0.70298 | train_accuracy: 0.70034 | valid_accuracy: 0.68571 |  0:00:11s\n",
      "epoch 61 | loss: 0.69473 | train_accuracy: 0.68912 | valid_accuracy: 0.66531 |  0:00:11s\n",
      "epoch 62 | loss: 0.70061 | train_accuracy: 0.70281 | valid_accuracy: 0.68129 |  0:00:12s\n",
      "epoch 63 | loss: 0.71046 | train_accuracy: 0.70893 | valid_accuracy: 0.67517 |  0:00:12s\n",
      "epoch 64 | loss: 0.69661 | train_accuracy: 0.7119  | valid_accuracy: 0.68333 |  0:00:12s\n",
      "epoch 65 | loss: 0.68939 | train_accuracy: 0.71692 | valid_accuracy: 0.6898  |  0:00:12s\n",
      "epoch 66 | loss: 0.6889  | train_accuracy: 0.70876 | valid_accuracy: 0.67143 |  0:00:12s\n",
      "epoch 67 | loss: 0.68523 | train_accuracy: 0.71378 | valid_accuracy: 0.68741 |  0:00:13s\n",
      "epoch 68 | loss: 0.69006 | train_accuracy: 0.70221 | valid_accuracy: 0.68639 |  0:00:13s\n",
      "epoch 69 | loss: 0.6927  | train_accuracy: 0.71531 | valid_accuracy: 0.68605 |  0:00:13s\n",
      "epoch 70 | loss: 0.68558 | train_accuracy: 0.70391 | valid_accuracy: 0.68095 |  0:00:13s\n",
      "epoch 71 | loss: 0.69365 | train_accuracy: 0.70221 | valid_accuracy: 0.67041 |  0:00:13s\n",
      "epoch 72 | loss: 0.6938  | train_accuracy: 0.71684 | valid_accuracy: 0.6949  |  0:00:14s\n",
      "epoch 73 | loss: 0.68677 | train_accuracy: 0.70995 | valid_accuracy: 0.67925 |  0:00:14s\n",
      "epoch 74 | loss: 0.68675 | train_accuracy: 0.72143 | valid_accuracy: 0.68605 |  0:00:14s\n",
      "epoch 75 | loss: 0.68299 | train_accuracy: 0.70867 | valid_accuracy: 0.68503 |  0:00:14s\n",
      "epoch 76 | loss: 0.68253 | train_accuracy: 0.71216 | valid_accuracy: 0.68367 |  0:00:14s\n",
      "epoch 77 | loss: 0.67785 | train_accuracy: 0.70833 | valid_accuracy: 0.69116 |  0:00:15s\n",
      "epoch 78 | loss: 0.67014 | train_accuracy: 0.71845 | valid_accuracy: 0.6932  |  0:00:15s\n",
      "epoch 79 | loss: 0.67502 | train_accuracy: 0.71658 | valid_accuracy: 0.68503 |  0:00:15s\n",
      "epoch 80 | loss: 0.67547 | train_accuracy: 0.72483 | valid_accuracy: 0.68741 |  0:00:15s\n",
      "epoch 81 | loss: 0.66949 | train_accuracy: 0.71709 | valid_accuracy: 0.69184 |  0:00:15s\n",
      "epoch 82 | loss: 0.68575 | train_accuracy: 0.68427 | valid_accuracy: 0.65816 |  0:00:16s\n",
      "epoch 83 | loss: 0.67127 | train_accuracy: 0.71233 | valid_accuracy: 0.68776 |  0:00:16s\n",
      "epoch 84 | loss: 0.67244 | train_accuracy: 0.7284  | valid_accuracy: 0.70952 |  0:00:16s\n",
      "epoch 85 | loss: 0.67719 | train_accuracy: 0.72236 | valid_accuracy: 0.68912 |  0:00:16s\n",
      "epoch 86 | loss: 0.6688  | train_accuracy: 0.69592 | valid_accuracy: 0.66259 |  0:00:16s\n",
      "epoch 87 | loss: 0.66185 | train_accuracy: 0.71752 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 88 | loss: 0.66444 | train_accuracy: 0.71939 | valid_accuracy: 0.68741 |  0:00:17s\n",
      "epoch 89 | loss: 0.67338 | train_accuracy: 0.71939 | valid_accuracy: 0.70034 |  0:00:17s\n",
      "epoch 90 | loss: 0.66432 | train_accuracy: 0.7256  | valid_accuracy: 0.69184 |  0:00:17s\n",
      "epoch 91 | loss: 0.66766 | train_accuracy: 0.71964 | valid_accuracy: 0.69864 |  0:00:17s\n",
      "epoch 92 | loss: 0.66985 | train_accuracy: 0.72585 | valid_accuracy: 0.7     |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.66617 | train_accuracy: 0.72109 | valid_accuracy: 0.69456 |  0:00:18s\n",
      "epoch 94 | loss: 0.66696 | train_accuracy: 0.72866 | valid_accuracy: 0.69558 |  0:00:18s\n",
      "epoch 95 | loss: 0.66071 | train_accuracy: 0.73061 | valid_accuracy: 0.70136 |  0:00:18s\n",
      "epoch 96 | loss: 0.6625  | train_accuracy: 0.71896 | valid_accuracy: 0.68401 |  0:00:18s\n",
      "epoch 97 | loss: 0.66062 | train_accuracy: 0.72151 | valid_accuracy: 0.68912 |  0:00:18s\n",
      "epoch 98 | loss: 0.66856 | train_accuracy: 0.71412 | valid_accuracy: 0.68129 |  0:00:19s\n",
      "epoch 99 | loss: 0.66348 | train_accuracy: 0.72262 | valid_accuracy: 0.6949  |  0:00:19s\n",
      "epoch 100| loss: 0.65586 | train_accuracy: 0.72347 | valid_accuracy: 0.6932  |  0:00:19s\n",
      "epoch 101| loss: 0.65773 | train_accuracy: 0.72917 | valid_accuracy: 0.69898 |  0:00:19s\n",
      "epoch 102| loss: 0.64304 | train_accuracy: 0.72109 | valid_accuracy: 0.69558 |  0:00:19s\n",
      "epoch 103| loss: 0.65465 | train_accuracy: 0.73818 | valid_accuracy: 0.7085  |  0:00:20s\n",
      "epoch 104| loss: 0.64497 | train_accuracy: 0.73401 | valid_accuracy: 0.70068 |  0:00:20s\n",
      "epoch 105| loss: 0.65244 | train_accuracy: 0.73427 | valid_accuracy: 0.70136 |  0:00:20s\n",
      "epoch 106| loss: 0.64866 | train_accuracy: 0.72951 | valid_accuracy: 0.69932 |  0:00:20s\n",
      "epoch 107| loss: 0.64929 | train_accuracy: 0.73597 | valid_accuracy: 0.70782 |  0:00:20s\n",
      "epoch 108| loss: 0.65358 | train_accuracy: 0.73588 | valid_accuracy: 0.70612 |  0:00:20s\n",
      "epoch 109| loss: 0.64928 | train_accuracy: 0.73138 | valid_accuracy: 0.69966 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 109 with best_epoch = 84 and best_valid_accuracy = 0.70952\n",
      "102\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.28608 | train_accuracy: 0.38036 | valid_accuracy: 0.38469 |  0:00:00s\n",
      "epoch 1  | loss: 1.01908 | train_accuracy: 0.33359 | valid_accuracy: 0.33776 |  0:00:00s\n",
      "epoch 2  | loss: 0.94268 | train_accuracy: 0.47857 | valid_accuracy: 0.47211 |  0:00:00s\n",
      "epoch 3  | loss: 0.9116  | train_accuracy: 0.50451 | valid_accuracy: 0.52177 |  0:00:00s\n",
      "epoch 4  | loss: 0.88636 | train_accuracy: 0.47296 | valid_accuracy: 0.48367 |  0:00:00s\n",
      "epoch 5  | loss: 0.86857 | train_accuracy: 0.47423 | valid_accuracy: 0.48231 |  0:00:01s\n",
      "epoch 6  | loss: 0.85935 | train_accuracy: 0.49201 | valid_accuracy: 0.49082 |  0:00:01s\n",
      "epoch 7  | loss: 0.84788 | train_accuracy: 0.52041 | valid_accuracy: 0.52313 |  0:00:01s\n",
      "epoch 8  | loss: 0.83902 | train_accuracy: 0.55162 | valid_accuracy: 0.56497 |  0:00:01s\n",
      "epoch 9  | loss: 0.83598 | train_accuracy: 0.56633 | valid_accuracy: 0.57585 |  0:00:01s\n",
      "epoch 10 | loss: 0.83289 | train_accuracy: 0.52534 | valid_accuracy: 0.52483 |  0:00:02s\n",
      "epoch 11 | loss: 0.83143 | train_accuracy: 0.56633 | valid_accuracy: 0.56463 |  0:00:02s\n",
      "epoch 12 | loss: 0.83292 | train_accuracy: 0.5494  | valid_accuracy: 0.55748 |  0:00:02s\n",
      "epoch 13 | loss: 0.81737 | train_accuracy: 0.58231 | valid_accuracy: 0.59184 |  0:00:02s\n",
      "epoch 14 | loss: 0.80867 | train_accuracy: 0.56497 | valid_accuracy: 0.56122 |  0:00:02s\n",
      "epoch 15 | loss: 0.80284 | train_accuracy: 0.58129 | valid_accuracy: 0.58401 |  0:00:03s\n",
      "epoch 16 | loss: 0.79286 | train_accuracy: 0.57168 | valid_accuracy: 0.57041 |  0:00:03s\n",
      "epoch 17 | loss: 0.79315 | train_accuracy: 0.59269 | valid_accuracy: 0.59184 |  0:00:03s\n",
      "epoch 18 | loss: 0.79255 | train_accuracy: 0.60213 | valid_accuracy: 0.60816 |  0:00:03s\n",
      "epoch 19 | loss: 0.7934  | train_accuracy: 0.62483 | valid_accuracy: 0.61156 |  0:00:03s\n",
      "epoch 20 | loss: 0.77745 | train_accuracy: 0.61361 | valid_accuracy: 0.62347 |  0:00:04s\n",
      "epoch 21 | loss: 0.78302 | train_accuracy: 0.62951 | valid_accuracy: 0.62517 |  0:00:04s\n",
      "epoch 22 | loss: 0.78189 | train_accuracy: 0.63699 | valid_accuracy: 0.64048 |  0:00:04s\n",
      "epoch 23 | loss: 0.77404 | train_accuracy: 0.63478 | valid_accuracy: 0.6415  |  0:00:04s\n",
      "epoch 24 | loss: 0.76545 | train_accuracy: 0.65408 | valid_accuracy: 0.6449  |  0:00:04s\n",
      "epoch 25 | loss: 0.76478 | train_accuracy: 0.65238 | valid_accuracy: 0.6551  |  0:00:05s\n",
      "epoch 26 | loss: 0.76172 | train_accuracy: 0.65204 | valid_accuracy: 0.64422 |  0:00:05s\n",
      "epoch 27 | loss: 0.75984 | train_accuracy: 0.66522 | valid_accuracy: 0.65612 |  0:00:05s\n",
      "epoch 28 | loss: 0.75742 | train_accuracy: 0.66054 | valid_accuracy: 0.65272 |  0:00:05s\n",
      "epoch 29 | loss: 0.74547 | train_accuracy: 0.65638 | valid_accuracy: 0.66054 |  0:00:05s\n",
      "epoch 30 | loss: 0.74678 | train_accuracy: 0.65927 | valid_accuracy: 0.6483  |  0:00:06s\n",
      "epoch 31 | loss: 0.75878 | train_accuracy: 0.65663 | valid_accuracy: 0.65816 |  0:00:06s\n",
      "epoch 32 | loss: 0.75739 | train_accuracy: 0.66182 | valid_accuracy: 0.65748 |  0:00:06s\n",
      "epoch 33 | loss: 0.75476 | train_accuracy: 0.66718 | valid_accuracy: 0.66361 |  0:00:06s\n",
      "epoch 34 | loss: 0.73709 | train_accuracy: 0.67491 | valid_accuracy: 0.66701 |  0:00:06s\n",
      "epoch 35 | loss: 0.73789 | train_accuracy: 0.67058 | valid_accuracy: 0.66871 |  0:00:06s\n",
      "epoch 36 | loss: 0.7378  | train_accuracy: 0.66828 | valid_accuracy: 0.67007 |  0:00:07s\n",
      "epoch 37 | loss: 0.73737 | train_accuracy: 0.67857 | valid_accuracy: 0.67959 |  0:00:07s\n",
      "epoch 38 | loss: 0.73192 | train_accuracy: 0.6773  | valid_accuracy: 0.67483 |  0:00:07s\n",
      "epoch 39 | loss: 0.72488 | train_accuracy: 0.68104 | valid_accuracy: 0.67279 |  0:00:07s\n",
      "epoch 40 | loss: 0.72787 | train_accuracy: 0.6926  | valid_accuracy: 0.68401 |  0:00:07s\n",
      "epoch 41 | loss: 0.7221  | train_accuracy: 0.67602 | valid_accuracy: 0.66667 |  0:00:08s\n",
      "epoch 42 | loss: 0.72968 | train_accuracy: 0.67985 | valid_accuracy: 0.67279 |  0:00:08s\n",
      "epoch 43 | loss: 0.7295  | train_accuracy: 0.68206 | valid_accuracy: 0.67279 |  0:00:08s\n",
      "epoch 44 | loss: 0.71978 | train_accuracy: 0.68682 | valid_accuracy: 0.69286 |  0:00:08s\n",
      "epoch 45 | loss: 0.71421 | train_accuracy: 0.7006  | valid_accuracy: 0.68741 |  0:00:08s\n",
      "epoch 46 | loss: 0.70909 | train_accuracy: 0.69048 | valid_accuracy: 0.68605 |  0:00:09s\n",
      "epoch 47 | loss: 0.7078  | train_accuracy: 0.68435 | valid_accuracy: 0.67449 |  0:00:09s\n",
      "epoch 48 | loss: 0.71702 | train_accuracy: 0.68095 | valid_accuracy: 0.67891 |  0:00:09s\n",
      "epoch 49 | loss: 0.72081 | train_accuracy: 0.67866 | valid_accuracy: 0.67313 |  0:00:09s\n",
      "epoch 50 | loss: 0.70577 | train_accuracy: 0.66241 | valid_accuracy: 0.66395 |  0:00:09s\n",
      "epoch 51 | loss: 0.71193 | train_accuracy: 0.69286 | valid_accuracy: 0.68946 |  0:00:10s\n",
      "epoch 52 | loss: 0.69799 | train_accuracy: 0.69728 | valid_accuracy: 0.68061 |  0:00:10s\n",
      "epoch 53 | loss: 0.70103 | train_accuracy: 0.68639 | valid_accuracy: 0.68537 |  0:00:10s\n",
      "epoch 54 | loss: 0.70567 | train_accuracy: 0.67083 | valid_accuracy: 0.65748 |  0:00:10s\n",
      "epoch 55 | loss: 0.70468 | train_accuracy: 0.69643 | valid_accuracy: 0.68435 |  0:00:10s\n",
      "epoch 56 | loss: 0.69506 | train_accuracy: 0.70833 | valid_accuracy: 0.69456 |  0:00:11s\n",
      "epoch 57 | loss: 0.70159 | train_accuracy: 0.69337 | valid_accuracy: 0.68333 |  0:00:11s\n",
      "epoch 58 | loss: 0.69281 | train_accuracy: 0.69787 | valid_accuracy: 0.68776 |  0:00:11s\n",
      "epoch 59 | loss: 0.69685 | train_accuracy: 0.6915  | valid_accuracy: 0.68129 |  0:00:11s\n",
      "epoch 60 | loss: 0.69499 | train_accuracy: 0.70833 | valid_accuracy: 0.69252 |  0:00:11s\n",
      "epoch 61 | loss: 0.68481 | train_accuracy: 0.70893 | valid_accuracy: 0.71054 |  0:00:12s\n",
      "epoch 62 | loss: 0.68678 | train_accuracy: 0.70034 | valid_accuracy: 0.68435 |  0:00:12s\n",
      "epoch 63 | loss: 0.69007 | train_accuracy: 0.70391 | valid_accuracy: 0.69252 |  0:00:12s\n",
      "epoch 64 | loss: 0.68613 | train_accuracy: 0.69762 | valid_accuracy: 0.68741 |  0:00:12s\n",
      "epoch 65 | loss: 0.68896 | train_accuracy: 0.69022 | valid_accuracy: 0.69116 |  0:00:12s\n",
      "epoch 66 | loss: 0.68631 | train_accuracy: 0.70791 | valid_accuracy: 0.69864 |  0:00:13s\n",
      "epoch 67 | loss: 0.6875  | train_accuracy: 0.70893 | valid_accuracy: 0.68946 |  0:00:13s\n",
      "epoch 68 | loss: 0.68603 | train_accuracy: 0.68444 | valid_accuracy: 0.67959 |  0:00:13s\n",
      "epoch 69 | loss: 0.69201 | train_accuracy: 0.68869 | valid_accuracy: 0.67551 |  0:00:13s\n",
      "epoch 70 | loss: 0.68093 | train_accuracy: 0.70757 | valid_accuracy: 0.69694 |  0:00:13s\n",
      "epoch 71 | loss: 0.66822 | train_accuracy: 0.70544 | valid_accuracy: 0.69456 |  0:00:13s\n",
      "epoch 72 | loss: 0.67523 | train_accuracy: 0.71548 | valid_accuracy: 0.70578 |  0:00:14s\n",
      "epoch 73 | loss: 0.6841  | train_accuracy: 0.69932 | valid_accuracy: 0.69286 |  0:00:14s\n",
      "epoch 74 | loss: 0.67468 | train_accuracy: 0.69422 | valid_accuracy: 0.68946 |  0:00:14s\n",
      "epoch 75 | loss: 0.67102 | train_accuracy: 0.71769 | valid_accuracy: 0.7085  |  0:00:14s\n",
      "epoch 76 | loss: 0.66803 | train_accuracy: 0.71607 | valid_accuracy: 0.70646 |  0:00:14s\n",
      "epoch 77 | loss: 0.66454 | train_accuracy: 0.7125  | valid_accuracy: 0.70034 |  0:00:15s\n",
      "epoch 78 | loss: 0.66347 | train_accuracy: 0.71122 | valid_accuracy: 0.69456 |  0:00:15s\n",
      "epoch 79 | loss: 0.65336 | train_accuracy: 0.72364 | valid_accuracy: 0.70374 |  0:00:15s\n",
      "epoch 80 | loss: 0.6533  | train_accuracy: 0.69124 | valid_accuracy: 0.68027 |  0:00:15s\n",
      "epoch 81 | loss: 0.6663  | train_accuracy: 0.72985 | valid_accuracy: 0.70918 |  0:00:15s\n",
      "epoch 82 | loss: 0.64666 | train_accuracy: 0.72619 | valid_accuracy: 0.71973 |  0:00:16s\n",
      "epoch 83 | loss: 0.65882 | train_accuracy: 0.72398 | valid_accuracy: 0.71122 |  0:00:16s\n",
      "epoch 84 | loss: 0.65347 | train_accuracy: 0.72993 | valid_accuracy: 0.71531 |  0:00:16s\n",
      "epoch 85 | loss: 0.65455 | train_accuracy: 0.67806 | valid_accuracy: 0.66259 |  0:00:16s\n",
      "epoch 86 | loss: 0.65399 | train_accuracy: 0.73257 | valid_accuracy: 0.72551 |  0:00:16s\n",
      "epoch 87 | loss: 0.66473 | train_accuracy: 0.70816 | valid_accuracy: 0.6949  |  0:00:17s\n",
      "epoch 88 | loss: 0.6579  | train_accuracy: 0.74167 | valid_accuracy: 0.73605 |  0:00:17s\n",
      "epoch 89 | loss: 0.64527 | train_accuracy: 0.7284  | valid_accuracy: 0.70816 |  0:00:17s\n",
      "epoch 90 | loss: 0.66096 | train_accuracy: 0.72832 | valid_accuracy: 0.72041 |  0:00:17s\n",
      "epoch 91 | loss: 0.64319 | train_accuracy: 0.70315 | valid_accuracy: 0.68776 |  0:00:17s\n",
      "epoch 92 | loss: 0.63927 | train_accuracy: 0.73571 | valid_accuracy: 0.72585 |  0:00:18s\n",
      "epoch 93 | loss: 0.63643 | train_accuracy: 0.74456 | valid_accuracy: 0.73027 |  0:00:18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 | loss: 0.64135 | train_accuracy: 0.71675 | valid_accuracy: 0.70884 |  0:00:18s\n",
      "epoch 95 | loss: 0.64307 | train_accuracy: 0.71871 | valid_accuracy: 0.70748 |  0:00:18s\n",
      "epoch 96 | loss: 0.63803 | train_accuracy: 0.7165  | valid_accuracy: 0.7051  |  0:00:18s\n",
      "epoch 97 | loss: 0.64405 | train_accuracy: 0.71565 | valid_accuracy: 0.69864 |  0:00:19s\n",
      "epoch 98 | loss: 0.6299  | train_accuracy: 0.74456 | valid_accuracy: 0.72449 |  0:00:19s\n",
      "epoch 99 | loss: 0.64021 | train_accuracy: 0.72577 | valid_accuracy: 0.71565 |  0:00:19s\n",
      "epoch 100| loss: 0.63664 | train_accuracy: 0.73206 | valid_accuracy: 0.71224 |  0:00:19s\n",
      "epoch 101| loss: 0.62818 | train_accuracy: 0.71794 | valid_accuracy: 0.69796 |  0:00:19s\n",
      "epoch 102| loss: 0.62066 | train_accuracy: 0.74422 | valid_accuracy: 0.72619 |  0:00:20s\n",
      "epoch 103| loss: 0.62399 | train_accuracy: 0.74209 | valid_accuracy: 0.72381 |  0:00:20s\n",
      "epoch 104| loss: 0.62431 | train_accuracy: 0.74048 | valid_accuracy: 0.72993 |  0:00:20s\n",
      "epoch 105| loss: 0.62729 | train_accuracy: 0.74838 | valid_accuracy: 0.73061 |  0:00:20s\n",
      "epoch 106| loss: 0.61374 | train_accuracy: 0.72194 | valid_accuracy: 0.71463 |  0:00:20s\n",
      "epoch 107| loss: 0.62726 | train_accuracy: 0.73869 | valid_accuracy: 0.72347 |  0:00:20s\n",
      "epoch 108| loss: 0.61869 | train_accuracy: 0.74294 | valid_accuracy: 0.72483 |  0:00:21s\n",
      "epoch 109| loss: 0.61235 | train_accuracy: 0.72764 | valid_accuracy: 0.71905 |  0:00:21s\n",
      "epoch 110| loss: 0.62006 | train_accuracy: 0.74753 | valid_accuracy: 0.72653 |  0:00:21s\n",
      "epoch 111| loss: 0.6178  | train_accuracy: 0.7318  | valid_accuracy: 0.71224 |  0:00:21s\n",
      "epoch 112| loss: 0.6129  | train_accuracy: 0.7517  | valid_accuracy: 0.73197 |  0:00:21s\n",
      "epoch 113| loss: 0.61266 | train_accuracy: 0.74252 | valid_accuracy: 0.72109 |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 113 with best_epoch = 88 and best_valid_accuracy = 0.73605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "88\n",
      "epoch 0  | loss: 1.30751 | train_accuracy: 0.45859 | valid_accuracy: 0.48401 |  0:00:00s\n",
      "epoch 1  | loss: 1.00134 | train_accuracy: 0.35867 | valid_accuracy: 0.34422 |  0:00:00s\n",
      "epoch 2  | loss: 0.94572 | train_accuracy: 0.40034 | valid_accuracy: 0.39184 |  0:00:00s\n",
      "epoch 3  | loss: 0.91532 | train_accuracy: 0.41913 | valid_accuracy: 0.41803 |  0:00:00s\n",
      "epoch 4  | loss: 0.89893 | train_accuracy: 0.40187 | valid_accuracy: 0.40816 |  0:00:00s\n",
      "epoch 5  | loss: 0.88841 | train_accuracy: 0.35077 | valid_accuracy: 0.35102 |  0:00:01s\n",
      "epoch 6  | loss: 0.88487 | train_accuracy: 0.34651 | valid_accuracy: 0.33333 |  0:00:01s\n",
      "epoch 7  | loss: 0.8724  | train_accuracy: 0.48333 | valid_accuracy: 0.48367 |  0:00:01s\n",
      "epoch 8  | loss: 0.8513  | train_accuracy: 0.5074  | valid_accuracy: 0.51667 |  0:00:01s\n",
      "epoch 9  | loss: 0.85684 | train_accuracy: 0.4858  | valid_accuracy: 0.49422 |  0:00:01s\n",
      "epoch 10 | loss: 0.84074 | train_accuracy: 0.53206 | valid_accuracy: 0.54014 |  0:00:02s\n",
      "epoch 11 | loss: 0.83256 | train_accuracy: 0.52389 | valid_accuracy: 0.52857 |  0:00:02s\n",
      "epoch 12 | loss: 0.82259 | train_accuracy: 0.52619 | valid_accuracy: 0.53231 |  0:00:02s\n",
      "epoch 13 | loss: 0.81924 | train_accuracy: 0.54592 | valid_accuracy: 0.54898 |  0:00:02s\n",
      "epoch 14 | loss: 0.80887 | train_accuracy: 0.54762 | valid_accuracy: 0.5551  |  0:00:02s\n",
      "epoch 15 | loss: 0.80755 | train_accuracy: 0.55646 | valid_accuracy: 0.56224 |  0:00:03s\n",
      "epoch 16 | loss: 0.79311 | train_accuracy: 0.56284 | valid_accuracy: 0.56429 |  0:00:03s\n",
      "epoch 17 | loss: 0.79472 | train_accuracy: 0.55221 | valid_accuracy: 0.56088 |  0:00:03s\n",
      "epoch 18 | loss: 0.79473 | train_accuracy: 0.59209 | valid_accuracy: 0.60238 |  0:00:03s\n",
      "epoch 19 | loss: 0.80879 | train_accuracy: 0.59677 | valid_accuracy: 0.60442 |  0:00:03s\n",
      "epoch 20 | loss: 0.8169  | train_accuracy: 0.61259 | valid_accuracy: 0.61599 |  0:00:04s\n",
      "epoch 21 | loss: 0.80699 | train_accuracy: 0.63316 | valid_accuracy: 0.63639 |  0:00:04s\n",
      "epoch 22 | loss: 0.78895 | train_accuracy: 0.61701 | valid_accuracy: 0.62007 |  0:00:04s\n",
      "epoch 23 | loss: 0.78974 | train_accuracy: 0.63104 | valid_accuracy: 0.64456 |  0:00:04s\n",
      "epoch 24 | loss: 0.77983 | train_accuracy: 0.62134 | valid_accuracy: 0.62857 |  0:00:04s\n",
      "epoch 25 | loss: 0.77226 | train_accuracy: 0.6199  | valid_accuracy: 0.61497 |  0:00:05s\n",
      "epoch 26 | loss: 0.77495 | train_accuracy: 0.55204 | valid_accuracy: 0.55136 |  0:00:05s\n",
      "epoch 27 | loss: 0.77181 | train_accuracy: 0.62721 | valid_accuracy: 0.63265 |  0:00:05s\n",
      "epoch 28 | loss: 0.76112 | train_accuracy: 0.61871 | valid_accuracy: 0.61837 |  0:00:05s\n",
      "epoch 29 | loss: 0.76044 | train_accuracy: 0.64566 | valid_accuracy: 0.64694 |  0:00:05s\n",
      "epoch 30 | loss: 0.75823 | train_accuracy: 0.6477  | valid_accuracy: 0.65136 |  0:00:06s\n",
      "epoch 31 | loss: 0.75158 | train_accuracy: 0.64923 | valid_accuracy: 0.65544 |  0:00:06s\n",
      "epoch 32 | loss: 0.74663 | train_accuracy: 0.65034 | valid_accuracy: 0.6602  |  0:00:06s\n",
      "epoch 33 | loss: 0.7513  | train_accuracy: 0.65255 | valid_accuracy: 0.65612 |  0:00:06s\n",
      "epoch 34 | loss: 0.75807 | train_accuracy: 0.65204 | valid_accuracy: 0.64626 |  0:00:06s\n",
      "epoch 35 | loss: 0.74304 | train_accuracy: 0.66548 | valid_accuracy: 0.67279 |  0:00:06s\n",
      "epoch 36 | loss: 0.74034 | train_accuracy: 0.67083 | valid_accuracy: 0.67585 |  0:00:07s\n",
      "epoch 37 | loss: 0.73781 | train_accuracy: 0.67423 | valid_accuracy: 0.67925 |  0:00:07s\n",
      "epoch 38 | loss: 0.74852 | train_accuracy: 0.65561 | valid_accuracy: 0.66497 |  0:00:07s\n",
      "epoch 39 | loss: 0.75843 | train_accuracy: 0.65816 | valid_accuracy: 0.66769 |  0:00:07s\n",
      "epoch 40 | loss: 0.74277 | train_accuracy: 0.67007 | valid_accuracy: 0.67245 |  0:00:07s\n",
      "epoch 41 | loss: 0.7378  | train_accuracy: 0.67355 | valid_accuracy: 0.68469 |  0:00:08s\n",
      "epoch 42 | loss: 0.73669 | train_accuracy: 0.63537 | valid_accuracy: 0.62891 |  0:00:08s\n",
      "epoch 43 | loss: 0.74581 | train_accuracy: 0.67874 | valid_accuracy: 0.67925 |  0:00:08s\n",
      "epoch 44 | loss: 0.73606 | train_accuracy: 0.67772 | valid_accuracy: 0.68197 |  0:00:08s\n",
      "epoch 45 | loss: 0.73251 | train_accuracy: 0.67517 | valid_accuracy: 0.67585 |  0:00:08s\n",
      "epoch 46 | loss: 0.7371  | train_accuracy: 0.68384 | valid_accuracy: 0.69014 |  0:00:09s\n",
      "epoch 47 | loss: 0.72665 | train_accuracy: 0.67253 | valid_accuracy: 0.67381 |  0:00:09s\n",
      "epoch 48 | loss: 0.72789 | train_accuracy: 0.67151 | valid_accuracy: 0.68503 |  0:00:09s\n",
      "epoch 49 | loss: 0.72157 | train_accuracy: 0.6807  | valid_accuracy: 0.67789 |  0:00:09s\n",
      "epoch 50 | loss: 0.71836 | train_accuracy: 0.68316 | valid_accuracy: 0.69932 |  0:00:09s\n",
      "epoch 51 | loss: 0.7185  | train_accuracy: 0.68929 | valid_accuracy: 0.6949  |  0:00:10s\n",
      "epoch 52 | loss: 0.71566 | train_accuracy: 0.69311 | valid_accuracy: 0.69762 |  0:00:10s\n",
      "epoch 53 | loss: 0.72137 | train_accuracy: 0.68997 | valid_accuracy: 0.69388 |  0:00:10s\n",
      "epoch 54 | loss: 0.71486 | train_accuracy: 0.68682 | valid_accuracy: 0.69694 |  0:00:10s\n",
      "epoch 55 | loss: 0.71734 | train_accuracy: 0.64932 | valid_accuracy: 0.64626 |  0:00:10s\n",
      "epoch 56 | loss: 0.70852 | train_accuracy: 0.69056 | valid_accuracy: 0.6966  |  0:00:10s\n",
      "epoch 57 | loss: 0.71073 | train_accuracy: 0.69524 | valid_accuracy: 0.70238 |  0:00:11s\n",
      "epoch 58 | loss: 0.70369 | train_accuracy: 0.68733 | valid_accuracy: 0.69694 |  0:00:11s\n",
      "epoch 59 | loss: 0.70684 | train_accuracy: 0.6892  | valid_accuracy: 0.6949  |  0:00:11s\n",
      "epoch 60 | loss: 0.71153 | train_accuracy: 0.69124 | valid_accuracy: 0.70272 |  0:00:11s\n",
      "epoch 61 | loss: 0.72022 | train_accuracy: 0.67049 | valid_accuracy: 0.67381 |  0:00:11s\n",
      "epoch 62 | loss: 0.71841 | train_accuracy: 0.69116 | valid_accuracy: 0.6966  |  0:00:12s\n",
      "epoch 63 | loss: 0.71331 | train_accuracy: 0.69719 | valid_accuracy: 0.70034 |  0:00:12s\n",
      "epoch 64 | loss: 0.71377 | train_accuracy: 0.68648 | valid_accuracy: 0.68027 |  0:00:12s\n",
      "epoch 65 | loss: 0.70824 | train_accuracy: 0.69677 | valid_accuracy: 0.6932  |  0:00:12s\n",
      "epoch 66 | loss: 0.70351 | train_accuracy: 0.65774 | valid_accuracy: 0.65136 |  0:00:12s\n",
      "epoch 67 | loss: 0.72015 | train_accuracy: 0.69362 | valid_accuracy: 0.70034 |  0:00:13s\n",
      "epoch 68 | loss: 0.70373 | train_accuracy: 0.70357 | valid_accuracy: 0.70646 |  0:00:13s\n",
      "epoch 69 | loss: 0.7147  | train_accuracy: 0.704   | valid_accuracy: 0.71224 |  0:00:13s\n",
      "epoch 70 | loss: 0.70417 | train_accuracy: 0.70204 | valid_accuracy: 0.7085  |  0:00:13s\n",
      "epoch 71 | loss: 0.70037 | train_accuracy: 0.70238 | valid_accuracy: 0.7068  |  0:00:13s\n",
      "epoch 72 | loss: 0.69123 | train_accuracy: 0.70867 | valid_accuracy: 0.72211 |  0:00:14s\n",
      "epoch 73 | loss: 0.69015 | train_accuracy: 0.68988 | valid_accuracy: 0.68367 |  0:00:14s\n",
      "epoch 74 | loss: 0.69242 | train_accuracy: 0.69099 | valid_accuracy: 0.70102 |  0:00:14s\n",
      "epoch 75 | loss: 0.693   | train_accuracy: 0.70425 | valid_accuracy: 0.71088 |  0:00:14s\n",
      "epoch 76 | loss: 0.69058 | train_accuracy: 0.70672 | valid_accuracy: 0.71054 |  0:00:14s\n",
      "epoch 77 | loss: 0.69709 | train_accuracy: 0.69736 | valid_accuracy: 0.6983  |  0:00:15s\n",
      "epoch 78 | loss: 0.68318 | train_accuracy: 0.70655 | valid_accuracy: 0.71429 |  0:00:15s\n",
      "epoch 79 | loss: 0.69213 | train_accuracy: 0.70136 | valid_accuracy: 0.71088 |  0:00:15s\n",
      "epoch 80 | loss: 0.68846 | train_accuracy: 0.70893 | valid_accuracy: 0.71633 |  0:00:15s\n",
      "epoch 81 | loss: 0.68065 | train_accuracy: 0.71973 | valid_accuracy: 0.72755 |  0:00:15s\n",
      "epoch 82 | loss: 0.68523 | train_accuracy: 0.7119  | valid_accuracy: 0.71088 |  0:00:16s\n",
      "epoch 83 | loss: 0.68025 | train_accuracy: 0.71888 | valid_accuracy: 0.72177 |  0:00:16s\n",
      "epoch 84 | loss: 0.67175 | train_accuracy: 0.71803 | valid_accuracy: 0.71599 |  0:00:16s\n",
      "epoch 85 | loss: 0.67398 | train_accuracy: 0.7307  | valid_accuracy: 0.72415 |  0:00:16s\n",
      "epoch 86 | loss: 0.67227 | train_accuracy: 0.71318 | valid_accuracy: 0.72075 |  0:00:16s\n",
      "epoch 87 | loss: 0.67434 | train_accuracy: 0.71412 | valid_accuracy: 0.71259 |  0:00:16s\n",
      "epoch 88 | loss: 0.68761 | train_accuracy: 0.72058 | valid_accuracy: 0.71735 |  0:00:17s\n",
      "epoch 89 | loss: 0.67448 | train_accuracy: 0.70952 | valid_accuracy: 0.71531 |  0:00:17s\n",
      "epoch 90 | loss: 0.67627 | train_accuracy: 0.71803 | valid_accuracy: 0.72211 |  0:00:17s\n",
      "epoch 91 | loss: 0.67543 | train_accuracy: 0.71879 | valid_accuracy: 0.71973 |  0:00:17s\n",
      "epoch 92 | loss: 0.66881 | train_accuracy: 0.72611 | valid_accuracy: 0.72415 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.66575 | train_accuracy: 0.725   | valid_accuracy: 0.72993 |  0:00:18s\n",
      "epoch 94 | loss: 0.67873 | train_accuracy: 0.72287 | valid_accuracy: 0.72075 |  0:00:18s\n",
      "epoch 95 | loss: 0.67133 | train_accuracy: 0.7193  | valid_accuracy: 0.72483 |  0:00:18s\n",
      "epoch 96 | loss: 0.67214 | train_accuracy: 0.71888 | valid_accuracy: 0.71463 |  0:00:18s\n",
      "epoch 97 | loss: 0.66516 | train_accuracy: 0.72304 | valid_accuracy: 0.72347 |  0:00:18s\n",
      "epoch 98 | loss: 0.67377 | train_accuracy: 0.70833 | valid_accuracy: 0.70374 |  0:00:19s\n",
      "epoch 99 | loss: 0.67217 | train_accuracy: 0.7034  | valid_accuracy: 0.69762 |  0:00:19s\n",
      "epoch 100| loss: 0.66375 | train_accuracy: 0.72534 | valid_accuracy: 0.72619 |  0:00:19s\n",
      "epoch 101| loss: 0.66306 | train_accuracy: 0.72262 | valid_accuracy: 0.72619 |  0:00:19s\n",
      "epoch 102| loss: 0.66663 | train_accuracy: 0.72347 | valid_accuracy: 0.72177 |  0:00:19s\n",
      "epoch 103| loss: 0.66142 | train_accuracy: 0.73257 | valid_accuracy: 0.73741 |  0:00:20s\n",
      "epoch 104| loss: 0.65889 | train_accuracy: 0.73376 | valid_accuracy: 0.73912 |  0:00:20s\n",
      "epoch 105| loss: 0.65409 | train_accuracy: 0.72806 | valid_accuracy: 0.72959 |  0:00:20s\n",
      "epoch 106| loss: 0.65519 | train_accuracy: 0.72789 | valid_accuracy: 0.72789 |  0:00:20s\n",
      "epoch 107| loss: 0.65759 | train_accuracy: 0.71905 | valid_accuracy: 0.71361 |  0:00:20s\n",
      "epoch 108| loss: 0.65758 | train_accuracy: 0.73112 | valid_accuracy: 0.73435 |  0:00:21s\n",
      "epoch 109| loss: 0.65672 | train_accuracy: 0.72577 | valid_accuracy: 0.72143 |  0:00:21s\n",
      "epoch 110| loss: 0.64383 | train_accuracy: 0.72815 | valid_accuracy: 0.72823 |  0:00:21s\n",
      "epoch 111| loss: 0.65667 | train_accuracy: 0.73418 | valid_accuracy: 0.72891 |  0:00:21s\n",
      "epoch 112| loss: 0.65075 | train_accuracy: 0.72993 | valid_accuracy: 0.72619 |  0:00:21s\n",
      "epoch 113| loss: 0.64768 | train_accuracy: 0.72755 | valid_accuracy: 0.73639 |  0:00:22s\n",
      "epoch 114| loss: 0.64996 | train_accuracy: 0.73512 | valid_accuracy: 0.73265 |  0:00:22s\n",
      "epoch 115| loss: 0.64999 | train_accuracy: 0.72976 | valid_accuracy: 0.7381  |  0:00:22s\n",
      "epoch 116| loss: 0.64477 | train_accuracy: 0.70842 | valid_accuracy: 0.70952 |  0:00:22s\n",
      "epoch 117| loss: 0.64402 | train_accuracy: 0.73087 | valid_accuracy: 0.73027 |  0:00:22s\n",
      "epoch 118| loss: 0.63339 | train_accuracy: 0.72823 | valid_accuracy: 0.72177 |  0:00:22s\n",
      "epoch 119| loss: 0.64638 | train_accuracy: 0.73682 | valid_accuracy: 0.73673 |  0:00:23s\n",
      "epoch 120| loss: 0.64341 | train_accuracy: 0.70833 | valid_accuracy: 0.69694 |  0:00:23s\n",
      "epoch 121| loss: 0.64362 | train_accuracy: 0.73622 | valid_accuracy: 0.73435 |  0:00:23s\n",
      "epoch 122| loss: 0.6422  | train_accuracy: 0.73546 | valid_accuracy: 0.73265 |  0:00:23s\n",
      "epoch 123| loss: 0.64134 | train_accuracy: 0.74133 | valid_accuracy: 0.74082 |  0:00:23s\n",
      "epoch 124| loss: 0.63973 | train_accuracy: 0.73512 | valid_accuracy: 0.72687 |  0:00:24s\n",
      "epoch 125| loss: 0.6448  | train_accuracy: 0.72866 | valid_accuracy: 0.72177 |  0:00:24s\n",
      "epoch 126| loss: 0.63356 | train_accuracy: 0.73886 | valid_accuracy: 0.73129 |  0:00:24s\n",
      "epoch 127| loss: 0.64142 | train_accuracy: 0.73818 | valid_accuracy: 0.72823 |  0:00:24s\n",
      "epoch 128| loss: 0.64363 | train_accuracy: 0.73707 | valid_accuracy: 0.73367 |  0:00:24s\n",
      "epoch 129| loss: 0.63565 | train_accuracy: 0.7466  | valid_accuracy: 0.74456 |  0:00:25s\n",
      "epoch 130| loss: 0.63053 | train_accuracy: 0.73767 | valid_accuracy: 0.72585 |  0:00:25s\n",
      "epoch 131| loss: 0.62422 | train_accuracy: 0.74626 | valid_accuracy: 0.74558 |  0:00:25s\n",
      "epoch 132| loss: 0.63111 | train_accuracy: 0.74371 | valid_accuracy: 0.74252 |  0:00:25s\n",
      "epoch 133| loss: 0.63828 | train_accuracy: 0.72151 | valid_accuracy: 0.71803 |  0:00:25s\n",
      "epoch 134| loss: 0.63829 | train_accuracy: 0.74855 | valid_accuracy: 0.74762 |  0:00:26s\n",
      "epoch 135| loss: 0.63752 | train_accuracy: 0.73546 | valid_accuracy: 0.72993 |  0:00:26s\n",
      "epoch 136| loss: 0.63606 | train_accuracy: 0.74855 | valid_accuracy: 0.74762 |  0:00:26s\n",
      "epoch 137| loss: 0.63807 | train_accuracy: 0.7432  | valid_accuracy: 0.74456 |  0:00:26s\n",
      "epoch 138| loss: 0.63351 | train_accuracy: 0.74541 | valid_accuracy: 0.74082 |  0:00:26s\n",
      "epoch 139| loss: 0.64622 | train_accuracy: 0.72279 | valid_accuracy: 0.71701 |  0:00:26s\n",
      "epoch 140| loss: 0.63955 | train_accuracy: 0.74447 | valid_accuracy: 0.74558 |  0:00:27s\n",
      "epoch 141| loss: 0.62611 | train_accuracy: 0.7335  | valid_accuracy: 0.73061 |  0:00:27s\n",
      "epoch 142| loss: 0.62347 | train_accuracy: 0.74592 | valid_accuracy: 0.74082 |  0:00:27s\n",
      "epoch 143| loss: 0.62908 | train_accuracy: 0.74957 | valid_accuracy: 0.74388 |  0:00:27s\n",
      "epoch 144| loss: 0.62336 | train_accuracy: 0.73614 | valid_accuracy: 0.73129 |  0:00:27s\n",
      "epoch 145| loss: 0.61977 | train_accuracy: 0.71046 | valid_accuracy: 0.71088 |  0:00:28s\n",
      "epoch 146| loss: 0.62371 | train_accuracy: 0.73248 | valid_accuracy: 0.73333 |  0:00:28s\n",
      "epoch 147| loss: 0.62865 | train_accuracy: 0.75187 | valid_accuracy: 0.74932 |  0:00:28s\n",
      "epoch 148| loss: 0.62305 | train_accuracy: 0.75136 | valid_accuracy: 0.75374 |  0:00:28s\n",
      "epoch 149| loss: 0.63055 | train_accuracy: 0.74983 | valid_accuracy: 0.74592 |  0:00:28s\n",
      "epoch 150| loss: 0.62559 | train_accuracy: 0.74762 | valid_accuracy: 0.74728 |  0:00:29s\n",
      "epoch 151| loss: 0.61815 | train_accuracy: 0.75255 | valid_accuracy: 0.7398  |  0:00:29s\n",
      "epoch 152| loss: 0.61504 | train_accuracy: 0.75    | valid_accuracy: 0.74116 |  0:00:29s\n",
      "epoch 153| loss: 0.60855 | train_accuracy: 0.75213 | valid_accuracy: 0.74252 |  0:00:29s\n",
      "epoch 154| loss: 0.61614 | train_accuracy: 0.74711 | valid_accuracy: 0.74184 |  0:00:29s\n",
      "epoch 155| loss: 0.62211 | train_accuracy: 0.74201 | valid_accuracy: 0.73776 |  0:00:30s\n",
      "epoch 156| loss: 0.62488 | train_accuracy: 0.73869 | valid_accuracy: 0.7449  |  0:00:30s\n",
      "epoch 157| loss: 0.63157 | train_accuracy: 0.74592 | valid_accuracy: 0.7398  |  0:00:30s\n",
      "epoch 158| loss: 0.62204 | train_accuracy: 0.73759 | valid_accuracy: 0.72721 |  0:00:30s\n",
      "epoch 159| loss: 0.61406 | train_accuracy: 0.75153 | valid_accuracy: 0.75238 |  0:00:30s\n",
      "epoch 160| loss: 0.61748 | train_accuracy: 0.75595 | valid_accuracy: 0.75068 |  0:00:31s\n",
      "epoch 161| loss: 0.61499 | train_accuracy: 0.74906 | valid_accuracy: 0.74354 |  0:00:31s\n",
      "epoch 162| loss: 0.60561 | train_accuracy: 0.75527 | valid_accuracy: 0.75238 |  0:00:31s\n",
      "epoch 163| loss: 0.61128 | train_accuracy: 0.75612 | valid_accuracy: 0.75442 |  0:00:31s\n",
      "epoch 164| loss: 0.61215 | train_accuracy: 0.75748 | valid_accuracy: 0.74558 |  0:00:31s\n",
      "epoch 165| loss: 0.62639 | train_accuracy: 0.75221 | valid_accuracy: 0.74422 |  0:00:32s\n",
      "epoch 166| loss: 0.61303 | train_accuracy: 0.75757 | valid_accuracy: 0.75408 |  0:00:32s\n",
      "epoch 167| loss: 0.61371 | train_accuracy: 0.75774 | valid_accuracy: 0.75102 |  0:00:32s\n",
      "epoch 168| loss: 0.61384 | train_accuracy: 0.7523  | valid_accuracy: 0.74626 |  0:00:32s\n",
      "epoch 169| loss: 0.60593 | train_accuracy: 0.75408 | valid_accuracy: 0.74456 |  0:00:32s\n",
      "epoch 170| loss: 0.60456 | train_accuracy: 0.75612 | valid_accuracy: 0.75442 |  0:00:32s\n",
      "epoch 171| loss: 0.61016 | train_accuracy: 0.75493 | valid_accuracy: 0.75136 |  0:00:33s\n",
      "epoch 172| loss: 0.60738 | train_accuracy: 0.74847 | valid_accuracy: 0.74592 |  0:00:33s\n",
      "epoch 173| loss: 0.61345 | train_accuracy: 0.75757 | valid_accuracy: 0.75238 |  0:00:33s\n",
      "epoch 174| loss: 0.60296 | train_accuracy: 0.75085 | valid_accuracy: 0.74422 |  0:00:33s\n",
      "epoch 175| loss: 0.60269 | train_accuracy: 0.76012 | valid_accuracy: 0.75408 |  0:00:33s\n",
      "epoch 176| loss: 0.60635 | train_accuracy: 0.7574  | valid_accuracy: 0.75102 |  0:00:34s\n",
      "epoch 177| loss: 0.60358 | train_accuracy: 0.76105 | valid_accuracy: 0.75102 |  0:00:34s\n",
      "epoch 178| loss: 0.61951 | train_accuracy: 0.74371 | valid_accuracy: 0.74014 |  0:00:34s\n",
      "epoch 179| loss: 0.59922 | train_accuracy: 0.76352 | valid_accuracy: 0.75782 |  0:00:34s\n",
      "epoch 180| loss: 0.6126  | train_accuracy: 0.75383 | valid_accuracy: 0.75034 |  0:00:34s\n",
      "epoch 181| loss: 0.60702 | train_accuracy: 0.75034 | valid_accuracy: 0.74728 |  0:00:35s\n",
      "epoch 182| loss: 0.59973 | train_accuracy: 0.74728 | valid_accuracy: 0.74728 |  0:00:35s\n",
      "epoch 183| loss: 0.60854 | train_accuracy: 0.75969 | valid_accuracy: 0.74966 |  0:00:35s\n",
      "epoch 184| loss: 0.60438 | train_accuracy: 0.75663 | valid_accuracy: 0.75884 |  0:00:35s\n",
      "epoch 185| loss: 0.60836 | train_accuracy: 0.76131 | valid_accuracy: 0.75272 |  0:00:35s\n",
      "epoch 186| loss: 0.59501 | train_accuracy: 0.7619  | valid_accuracy: 0.75816 |  0:00:36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187| loss: 0.60263 | train_accuracy: 0.75859 | valid_accuracy: 0.76224 |  0:00:36s\n",
      "epoch 188| loss: 0.6055  | train_accuracy: 0.75587 | valid_accuracy: 0.75544 |  0:00:36s\n",
      "epoch 189| loss: 0.60529 | train_accuracy: 0.75434 | valid_accuracy: 0.75068 |  0:00:36s\n",
      "epoch 190| loss: 0.59795 | train_accuracy: 0.76165 | valid_accuracy: 0.75442 |  0:00:36s\n",
      "epoch 191| loss: 0.59973 | train_accuracy: 0.75706 | valid_accuracy: 0.75    |  0:00:36s\n",
      "epoch 192| loss: 0.60306 | train_accuracy: 0.75587 | valid_accuracy: 0.75272 |  0:00:37s\n",
      "epoch 193| loss: 0.60878 | train_accuracy: 0.76224 | valid_accuracy: 0.75408 |  0:00:37s\n",
      "epoch 194| loss: 0.61183 | train_accuracy: 0.75451 | valid_accuracy: 0.75238 |  0:00:37s\n",
      "epoch 195| loss: 0.61531 | train_accuracy: 0.75646 | valid_accuracy: 0.7551  |  0:00:37s\n",
      "epoch 196| loss: 0.60739 | train_accuracy: 0.76301 | valid_accuracy: 0.75612 |  0:00:38s\n",
      "epoch 197| loss: 0.60468 | train_accuracy: 0.76063 | valid_accuracy: 0.75612 |  0:00:38s\n",
      "epoch 198| loss: 0.59904 | train_accuracy: 0.76361 | valid_accuracy: 0.7534  |  0:00:38s\n",
      "epoch 199| loss: 0.60618 | train_accuracy: 0.76624 | valid_accuracy: 0.7619  |  0:00:38s\n",
      "epoch 200| loss: 0.59875 | train_accuracy: 0.75638 | valid_accuracy: 0.75136 |  0:00:38s\n",
      "epoch 201| loss: 0.59793 | train_accuracy: 0.76293 | valid_accuracy: 0.75782 |  0:00:38s\n",
      "epoch 202| loss: 0.59446 | train_accuracy: 0.76216 | valid_accuracy: 0.76259 |  0:00:39s\n",
      "epoch 203| loss: 0.58933 | train_accuracy: 0.76709 | valid_accuracy: 0.7602  |  0:00:39s\n",
      "epoch 204| loss: 0.59869 | train_accuracy: 0.76412 | valid_accuracy: 0.7602  |  0:00:39s\n",
      "epoch 205| loss: 0.58861 | train_accuracy: 0.76335 | valid_accuracy: 0.76701 |  0:00:39s\n",
      "epoch 206| loss: 0.6003  | train_accuracy: 0.76701 | valid_accuracy: 0.76497 |  0:00:39s\n",
      "epoch 207| loss: 0.59614 | train_accuracy: 0.76012 | valid_accuracy: 0.76259 |  0:00:40s\n",
      "epoch 208| loss: 0.5981  | train_accuracy: 0.76284 | valid_accuracy: 0.76395 |  0:00:40s\n",
      "epoch 209| loss: 0.59544 | train_accuracy: 0.76114 | valid_accuracy: 0.75442 |  0:00:40s\n",
      "epoch 210| loss: 0.582   | train_accuracy: 0.7648  | valid_accuracy: 0.76122 |  0:00:40s\n",
      "epoch 211| loss: 0.60132 | train_accuracy: 0.76182 | valid_accuracy: 0.7534  |  0:00:40s\n",
      "epoch 212| loss: 0.59164 | train_accuracy: 0.76658 | valid_accuracy: 0.7585  |  0:00:41s\n",
      "epoch 213| loss: 0.59555 | train_accuracy: 0.76352 | valid_accuracy: 0.75816 |  0:00:41s\n",
      "epoch 214| loss: 0.6082  | train_accuracy: 0.76301 | valid_accuracy: 0.75986 |  0:00:41s\n",
      "epoch 215| loss: 0.59698 | train_accuracy: 0.76097 | valid_accuracy: 0.7619  |  0:00:41s\n",
      "epoch 216| loss: 0.59981 | train_accuracy: 0.76582 | valid_accuracy: 0.76429 |  0:00:41s\n",
      "epoch 217| loss: 0.58827 | train_accuracy: 0.76633 | valid_accuracy: 0.76122 |  0:00:42s\n",
      "epoch 218| loss: 0.59413 | train_accuracy: 0.7682  | valid_accuracy: 0.76531 |  0:00:42s\n",
      "epoch 219| loss: 0.5905  | train_accuracy: 0.76548 | valid_accuracy: 0.7585  |  0:00:42s\n",
      "epoch 220| loss: 0.57977 | train_accuracy: 0.76837 | valid_accuracy: 0.76463 |  0:00:42s\n",
      "epoch 221| loss: 0.58701 | train_accuracy: 0.76973 | valid_accuracy: 0.76599 |  0:00:42s\n",
      "epoch 222| loss: 0.59305 | train_accuracy: 0.76675 | valid_accuracy: 0.75986 |  0:00:42s\n",
      "epoch 223| loss: 0.594   | train_accuracy: 0.76378 | valid_accuracy: 0.75748 |  0:00:43s\n",
      "epoch 224| loss: 0.5866  | train_accuracy: 0.76207 | valid_accuracy: 0.75578 |  0:00:43s\n",
      "epoch 225| loss: 0.58962 | train_accuracy: 0.76709 | valid_accuracy: 0.76395 |  0:00:43s\n",
      "epoch 226| loss: 0.58324 | train_accuracy: 0.76973 | valid_accuracy: 0.76531 |  0:00:43s\n",
      "epoch 227| loss: 0.57942 | train_accuracy: 0.76803 | valid_accuracy: 0.76701 |  0:00:43s\n",
      "epoch 228| loss: 0.59474 | train_accuracy: 0.77092 | valid_accuracy: 0.76531 |  0:00:44s\n",
      "epoch 229| loss: 0.58782 | train_accuracy: 0.77287 | valid_accuracy: 0.76429 |  0:00:44s\n",
      "epoch 230| loss: 0.59473 | train_accuracy: 0.76896 | valid_accuracy: 0.76769 |  0:00:44s\n",
      "epoch 231| loss: 0.58595 | train_accuracy: 0.7699  | valid_accuracy: 0.76701 |  0:00:44s\n",
      "epoch 232| loss: 0.58436 | train_accuracy: 0.77245 | valid_accuracy: 0.76565 |  0:00:44s\n",
      "epoch 233| loss: 0.58822 | train_accuracy: 0.77049 | valid_accuracy: 0.76565 |  0:00:45s\n",
      "epoch 234| loss: 0.58241 | train_accuracy: 0.76879 | valid_accuracy: 0.7602  |  0:00:45s\n",
      "epoch 235| loss: 0.5909  | train_accuracy: 0.75255 | valid_accuracy: 0.7466  |  0:00:45s\n",
      "epoch 236| loss: 0.58817 | train_accuracy: 0.76879 | valid_accuracy: 0.75986 |  0:00:45s\n",
      "epoch 237| loss: 0.58905 | train_accuracy: 0.76956 | valid_accuracy: 0.76259 |  0:00:45s\n",
      "epoch 238| loss: 0.58891 | train_accuracy: 0.76922 | valid_accuracy: 0.76327 |  0:00:46s\n",
      "epoch 239| loss: 0.59251 | train_accuracy: 0.76352 | valid_accuracy: 0.76361 |  0:00:46s\n",
      "epoch 240| loss: 0.58605 | train_accuracy: 0.76709 | valid_accuracy: 0.76701 |  0:00:46s\n",
      "epoch 241| loss: 0.58943 | train_accuracy: 0.75927 | valid_accuracy: 0.75034 |  0:00:46s\n",
      "epoch 242| loss: 0.58648 | train_accuracy: 0.77177 | valid_accuracy: 0.76565 |  0:00:46s\n",
      "epoch 243| loss: 0.58635 | train_accuracy: 0.77083 | valid_accuracy: 0.76633 |  0:00:47s\n",
      "epoch 244| loss: 0.58784 | train_accuracy: 0.76837 | valid_accuracy: 0.76054 |  0:00:47s\n",
      "epoch 245| loss: 0.5855  | train_accuracy: 0.76522 | valid_accuracy: 0.76871 |  0:00:47s\n",
      "epoch 246| loss: 0.58469 | train_accuracy: 0.76964 | valid_accuracy: 0.76224 |  0:00:47s\n",
      "epoch 247| loss: 0.59147 | train_accuracy: 0.7676  | valid_accuracy: 0.76293 |  0:00:47s\n",
      "epoch 248| loss: 0.58215 | train_accuracy: 0.76837 | valid_accuracy: 0.75986 |  0:00:48s\n",
      "epoch 249| loss: 0.59303 | train_accuracy: 0.77364 | valid_accuracy: 0.76905 |  0:00:48s\n",
      "epoch 250| loss: 0.57953 | train_accuracy: 0.76964 | valid_accuracy: 0.77041 |  0:00:48s\n",
      "epoch 251| loss: 0.59167 | train_accuracy: 0.76947 | valid_accuracy: 0.7585  |  0:00:48s\n",
      "epoch 252| loss: 0.5821  | train_accuracy: 0.77185 | valid_accuracy: 0.76361 |  0:00:48s\n",
      "epoch 253| loss: 0.57788 | train_accuracy: 0.77117 | valid_accuracy: 0.76565 |  0:00:48s\n",
      "epoch 254| loss: 0.57946 | train_accuracy: 0.7676  | valid_accuracy: 0.76293 |  0:00:49s\n",
      "epoch 255| loss: 0.58092 | train_accuracy: 0.77491 | valid_accuracy: 0.76565 |  0:00:49s\n",
      "epoch 256| loss: 0.58215 | train_accuracy: 0.76913 | valid_accuracy: 0.76837 |  0:00:49s\n",
      "epoch 257| loss: 0.577   | train_accuracy: 0.77253 | valid_accuracy: 0.76667 |  0:00:49s\n",
      "epoch 258| loss: 0.57835 | train_accuracy: 0.77406 | valid_accuracy: 0.77007 |  0:00:49s\n",
      "epoch 259| loss: 0.58108 | train_accuracy: 0.77551 | valid_accuracy: 0.76939 |  0:00:50s\n",
      "epoch 260| loss: 0.57807 | train_accuracy: 0.77611 | valid_accuracy: 0.77041 |  0:00:50s\n",
      "epoch 261| loss: 0.58955 | train_accuracy: 0.77645 | valid_accuracy: 0.76667 |  0:00:50s\n",
      "epoch 262| loss: 0.58149 | train_accuracy: 0.77457 | valid_accuracy: 0.76735 |  0:00:50s\n",
      "epoch 263| loss: 0.57796 | train_accuracy: 0.77423 | valid_accuracy: 0.77177 |  0:00:50s\n",
      "epoch 264| loss: 0.57545 | train_accuracy: 0.77134 | valid_accuracy: 0.76803 |  0:00:51s\n",
      "epoch 265| loss: 0.57994 | train_accuracy: 0.76156 | valid_accuracy: 0.75612 |  0:00:51s\n",
      "epoch 266| loss: 0.57404 | train_accuracy: 0.77687 | valid_accuracy: 0.76871 |  0:00:51s\n",
      "epoch 267| loss: 0.5716  | train_accuracy: 0.77823 | valid_accuracy: 0.77007 |  0:00:51s\n",
      "epoch 268| loss: 0.57691 | train_accuracy: 0.77806 | valid_accuracy: 0.77109 |  0:00:51s\n",
      "epoch 269| loss: 0.57634 | train_accuracy: 0.76276 | valid_accuracy: 0.75816 |  0:00:52s\n",
      "epoch 270| loss: 0.58429 | train_accuracy: 0.77594 | valid_accuracy: 0.77075 |  0:00:52s\n",
      "epoch 271| loss: 0.57436 | train_accuracy: 0.77372 | valid_accuracy: 0.76599 |  0:00:52s\n",
      "epoch 272| loss: 0.57648 | train_accuracy: 0.779   | valid_accuracy: 0.77279 |  0:00:52s\n",
      "epoch 273| loss: 0.58968 | train_accuracy: 0.77321 | valid_accuracy: 0.76769 |  0:00:52s\n",
      "epoch 274| loss: 0.57825 | train_accuracy: 0.77381 | valid_accuracy: 0.76939 |  0:00:52s\n",
      "epoch 275| loss: 0.5782  | train_accuracy: 0.77823 | valid_accuracy: 0.76803 |  0:00:53s\n",
      "epoch 276| loss: 0.57851 | train_accuracy: 0.77415 | valid_accuracy: 0.76871 |  0:00:53s\n",
      "epoch 277| loss: 0.57828 | train_accuracy: 0.77321 | valid_accuracy: 0.76701 |  0:00:53s\n",
      "epoch 278| loss: 0.57756 | train_accuracy: 0.77347 | valid_accuracy: 0.77245 |  0:00:53s\n",
      "epoch 279| loss: 0.5737  | train_accuracy: 0.7733  | valid_accuracy: 0.77041 |  0:00:53s\n",
      "epoch 280| loss: 0.5726  | train_accuracy: 0.77321 | valid_accuracy: 0.77041 |  0:00:54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 281| loss: 0.57304 | train_accuracy: 0.77381 | valid_accuracy: 0.77313 |  0:00:54s\n",
      "epoch 282| loss: 0.57371 | train_accuracy: 0.77543 | valid_accuracy: 0.77381 |  0:00:54s\n",
      "epoch 283| loss: 0.58212 | train_accuracy: 0.77398 | valid_accuracy: 0.76565 |  0:00:54s\n",
      "epoch 284| loss: 0.57837 | train_accuracy: 0.77202 | valid_accuracy: 0.76395 |  0:00:54s\n",
      "epoch 285| loss: 0.57553 | train_accuracy: 0.7767  | valid_accuracy: 0.77177 |  0:00:55s\n",
      "epoch 286| loss: 0.58445 | train_accuracy: 0.77262 | valid_accuracy: 0.77075 |  0:00:55s\n",
      "epoch 287| loss: 0.57567 | train_accuracy: 0.77789 | valid_accuracy: 0.77177 |  0:00:55s\n",
      "epoch 288| loss: 0.57548 | train_accuracy: 0.76998 | valid_accuracy: 0.76633 |  0:00:55s\n",
      "epoch 289| loss: 0.57496 | train_accuracy: 0.77585 | valid_accuracy: 0.76973 |  0:00:55s\n",
      "epoch 290| loss: 0.57598 | train_accuracy: 0.77406 | valid_accuracy: 0.76361 |  0:00:56s\n",
      "epoch 291| loss: 0.56535 | train_accuracy: 0.77704 | valid_accuracy: 0.77075 |  0:00:56s\n",
      "epoch 292| loss: 0.57048 | train_accuracy: 0.77866 | valid_accuracy: 0.76905 |  0:00:56s\n",
      "epoch 293| loss: 0.56711 | train_accuracy: 0.78189 | valid_accuracy: 0.77109 |  0:00:56s\n",
      "epoch 294| loss: 0.58687 | train_accuracy: 0.76973 | valid_accuracy: 0.76599 |  0:00:56s\n",
      "epoch 295| loss: 0.57491 | train_accuracy: 0.77832 | valid_accuracy: 0.77483 |  0:00:57s\n",
      "epoch 296| loss: 0.57088 | train_accuracy: 0.77415 | valid_accuracy: 0.76769 |  0:00:57s\n",
      "epoch 297| loss: 0.57326 | train_accuracy: 0.77968 | valid_accuracy: 0.76871 |  0:00:57s\n",
      "epoch 298| loss: 0.57296 | train_accuracy: 0.77628 | valid_accuracy: 0.77109 |  0:00:57s\n",
      "epoch 299| loss: 0.57111 | train_accuracy: 0.77321 | valid_accuracy: 0.76837 |  0:00:57s\n",
      "epoch 300| loss: 0.56621 | train_accuracy: 0.77568 | valid_accuracy: 0.76701 |  0:00:58s\n",
      "epoch 301| loss: 0.57463 | train_accuracy: 0.77934 | valid_accuracy: 0.77177 |  0:00:58s\n",
      "epoch 302| loss: 0.56687 | train_accuracy: 0.78002 | valid_accuracy: 0.77143 |  0:00:58s\n",
      "epoch 303| loss: 0.57777 | train_accuracy: 0.7767  | valid_accuracy: 0.77313 |  0:00:58s\n",
      "epoch 304| loss: 0.56783 | train_accuracy: 0.77662 | valid_accuracy: 0.76837 |  0:00:58s\n",
      "epoch 305| loss: 0.57802 | train_accuracy: 0.77355 | valid_accuracy: 0.76429 |  0:00:58s\n",
      "epoch 306| loss: 0.57205 | train_accuracy: 0.78078 | valid_accuracy: 0.77211 |  0:00:59s\n",
      "epoch 307| loss: 0.5667  | train_accuracy: 0.77806 | valid_accuracy: 0.77245 |  0:00:59s\n",
      "epoch 308| loss: 0.57548 | train_accuracy: 0.77755 | valid_accuracy: 0.77143 |  0:00:59s\n",
      "epoch 309| loss: 0.5746  | train_accuracy: 0.77823 | valid_accuracy: 0.77177 |  0:00:59s\n",
      "epoch 310| loss: 0.5761  | train_accuracy: 0.77925 | valid_accuracy: 0.77279 |  0:00:59s\n",
      "epoch 311| loss: 0.57234 | train_accuracy: 0.78027 | valid_accuracy: 0.77041 |  0:01:00s\n",
      "epoch 312| loss: 0.57068 | train_accuracy: 0.78121 | valid_accuracy: 0.77007 |  0:01:00s\n",
      "epoch 313| loss: 0.57661 | train_accuracy: 0.779   | valid_accuracy: 0.76973 |  0:01:00s\n",
      "epoch 314| loss: 0.56791 | train_accuracy: 0.77806 | valid_accuracy: 0.77109 |  0:01:00s\n",
      "epoch 315| loss: 0.57029 | train_accuracy: 0.78019 | valid_accuracy: 0.76973 |  0:01:00s\n",
      "epoch 316| loss: 0.57227 | train_accuracy: 0.77721 | valid_accuracy: 0.76837 |  0:01:01s\n",
      "epoch 317| loss: 0.57082 | train_accuracy: 0.7756  | valid_accuracy: 0.77041 |  0:01:01s\n",
      "epoch 318| loss: 0.5656  | train_accuracy: 0.77917 | valid_accuracy: 0.77041 |  0:01:01s\n",
      "epoch 319| loss: 0.57439 | train_accuracy: 0.77857 | valid_accuracy: 0.76871 |  0:01:01s\n",
      "epoch 320| loss: 0.56601 | train_accuracy: 0.77934 | valid_accuracy: 0.77109 |  0:01:01s\n",
      "\n",
      "Early stopping occurred at epoch 320 with best_epoch = 295 and best_valid_accuracy = 0.77483\n",
      "291\n",
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.26995 | train_accuracy: 0.35196 | valid_accuracy: 0.35204 |  0:00:00s\n",
      "epoch 1  | loss: 1.00174 | train_accuracy: 0.34651 | valid_accuracy: 0.33333 |  0:00:00s\n",
      "epoch 2  | loss: 0.93559 | train_accuracy: 0.41335 | valid_accuracy: 0.39864 |  0:00:00s\n",
      "epoch 3  | loss: 0.89945 | train_accuracy: 0.46437 | valid_accuracy: 0.44592 |  0:00:00s\n",
      "epoch 4  | loss: 0.87652 | train_accuracy: 0.44005 | valid_accuracy: 0.43605 |  0:00:01s\n",
      "epoch 5  | loss: 0.86234 | train_accuracy: 0.44923 | valid_accuracy: 0.43912 |  0:00:01s\n",
      "epoch 6  | loss: 0.85457 | train_accuracy: 0.47262 | valid_accuracy: 0.45816 |  0:00:01s\n",
      "epoch 7  | loss: 0.84225 | train_accuracy: 0.44498 | valid_accuracy: 0.43673 |  0:00:01s\n",
      "epoch 8  | loss: 0.8358  | train_accuracy: 0.41207 | valid_accuracy: 0.39796 |  0:00:01s\n",
      "epoch 9  | loss: 0.82483 | train_accuracy: 0.4994  | valid_accuracy: 0.50238 |  0:00:01s\n",
      "epoch 10 | loss: 0.82679 | train_accuracy: 0.51284 | valid_accuracy: 0.51395 |  0:00:02s\n",
      "epoch 11 | loss: 0.81521 | train_accuracy: 0.54983 | valid_accuracy: 0.55204 |  0:00:02s\n",
      "epoch 12 | loss: 0.81377 | train_accuracy: 0.56293 | valid_accuracy: 0.55374 |  0:00:02s\n",
      "epoch 13 | loss: 0.81186 | train_accuracy: 0.58316 | valid_accuracy: 0.58776 |  0:00:02s\n",
      "epoch 14 | loss: 0.82087 | train_accuracy: 0.48665 | valid_accuracy: 0.4915  |  0:00:02s\n",
      "epoch 15 | loss: 0.81291 | train_accuracy: 0.58605 | valid_accuracy: 0.58741 |  0:00:03s\n",
      "epoch 16 | loss: 0.80888 | train_accuracy: 0.49541 | valid_accuracy: 0.4983  |  0:00:03s\n",
      "epoch 17 | loss: 0.79927 | train_accuracy: 0.55884 | valid_accuracy: 0.57007 |  0:00:03s\n",
      "epoch 18 | loss: 0.81142 | train_accuracy: 0.55587 | valid_accuracy: 0.56156 |  0:00:03s\n",
      "epoch 19 | loss: 0.81276 | train_accuracy: 0.6006  | valid_accuracy: 0.59966 |  0:00:03s\n",
      "epoch 20 | loss: 0.79511 | train_accuracy: 0.63835 | valid_accuracy: 0.63129 |  0:00:04s\n",
      "epoch 21 | loss: 0.79521 | train_accuracy: 0.62968 | valid_accuracy: 0.61939 |  0:00:04s\n",
      "epoch 22 | loss: 0.78187 | train_accuracy: 0.62602 | valid_accuracy: 0.62755 |  0:00:04s\n",
      "epoch 23 | loss: 0.78699 | train_accuracy: 0.63963 | valid_accuracy: 0.63537 |  0:00:04s\n",
      "epoch 24 | loss: 0.79015 | train_accuracy: 0.65043 | valid_accuracy: 0.64354 |  0:00:04s\n",
      "epoch 25 | loss: 0.77724 | train_accuracy: 0.65468 | valid_accuracy: 0.6517  |  0:00:05s\n",
      "epoch 26 | loss: 0.77287 | train_accuracy: 0.65587 | valid_accuracy: 0.64184 |  0:00:05s\n",
      "epoch 27 | loss: 0.76874 | train_accuracy: 0.62815 | valid_accuracy: 0.62109 |  0:00:05s\n",
      "epoch 28 | loss: 0.76174 | train_accuracy: 0.65213 | valid_accuracy: 0.64728 |  0:00:05s\n",
      "epoch 29 | loss: 0.7536  | train_accuracy: 0.66947 | valid_accuracy: 0.6585  |  0:00:05s\n",
      "epoch 30 | loss: 0.74721 | train_accuracy: 0.65196 | valid_accuracy: 0.64218 |  0:00:06s\n",
      "epoch 31 | loss: 0.75321 | train_accuracy: 0.6625  | valid_accuracy: 0.6466  |  0:00:06s\n",
      "epoch 32 | loss: 0.7629  | train_accuracy: 0.66165 | valid_accuracy: 0.6517  |  0:00:06s\n",
      "epoch 33 | loss: 0.75799 | train_accuracy: 0.66301 | valid_accuracy: 0.65544 |  0:00:06s\n",
      "epoch 34 | loss: 0.75361 | train_accuracy: 0.65612 | valid_accuracy: 0.64116 |  0:00:06s\n",
      "epoch 35 | loss: 0.74277 | train_accuracy: 0.66624 | valid_accuracy: 0.65034 |  0:00:06s\n",
      "epoch 36 | loss: 0.74803 | train_accuracy: 0.65791 | valid_accuracy: 0.64898 |  0:00:07s\n",
      "epoch 37 | loss: 0.74673 | train_accuracy: 0.66828 | valid_accuracy: 0.66054 |  0:00:07s\n",
      "epoch 38 | loss: 0.74389 | train_accuracy: 0.66369 | valid_accuracy: 0.65034 |  0:00:07s\n",
      "epoch 39 | loss: 0.7502  | train_accuracy: 0.62279 | valid_accuracy: 0.61463 |  0:00:07s\n",
      "epoch 40 | loss: 0.73888 | train_accuracy: 0.67721 | valid_accuracy: 0.65748 |  0:00:07s\n",
      "epoch 41 | loss: 0.73587 | train_accuracy: 0.68129 | valid_accuracy: 0.66259 |  0:00:08s\n",
      "epoch 42 | loss: 0.72576 | train_accuracy: 0.68418 | valid_accuracy: 0.66837 |  0:00:08s\n",
      "epoch 43 | loss: 0.72846 | train_accuracy: 0.6915  | valid_accuracy: 0.67687 |  0:00:08s\n",
      "epoch 44 | loss: 0.72939 | train_accuracy: 0.68665 | valid_accuracy: 0.66735 |  0:00:08s\n",
      "epoch 45 | loss: 0.72132 | train_accuracy: 0.68214 | valid_accuracy: 0.6551  |  0:00:08s\n",
      "epoch 46 | loss: 0.72076 | train_accuracy: 0.67483 | valid_accuracy: 0.65884 |  0:00:09s\n",
      "epoch 47 | loss: 0.71819 | train_accuracy: 0.69048 | valid_accuracy: 0.68673 |  0:00:09s\n",
      "epoch 48 | loss: 0.71768 | train_accuracy: 0.68138 | valid_accuracy: 0.66122 |  0:00:09s\n",
      "epoch 49 | loss: 0.72023 | train_accuracy: 0.69328 | valid_accuracy: 0.68061 |  0:00:09s\n",
      "epoch 50 | loss: 0.72767 | train_accuracy: 0.68878 | valid_accuracy: 0.67687 |  0:00:09s\n",
      "epoch 51 | loss: 0.71826 | train_accuracy: 0.69014 | valid_accuracy: 0.66973 |  0:00:10s\n",
      "epoch 52 | loss: 0.70845 | train_accuracy: 0.68912 | valid_accuracy: 0.66905 |  0:00:10s\n",
      "epoch 53 | loss: 0.71131 | train_accuracy: 0.69881 | valid_accuracy: 0.67925 |  0:00:10s\n",
      "epoch 54 | loss: 0.70638 | train_accuracy: 0.69456 | valid_accuracy: 0.67959 |  0:00:10s\n",
      "epoch 55 | loss: 0.71608 | train_accuracy: 0.69226 | valid_accuracy: 0.67585 |  0:00:10s\n",
      "epoch 56 | loss: 0.70631 | train_accuracy: 0.6784  | valid_accuracy: 0.6619  |  0:00:11s\n",
      "epoch 57 | loss: 0.70673 | train_accuracy: 0.69005 | valid_accuracy: 0.67619 |  0:00:11s\n",
      "epoch 58 | loss: 0.70112 | train_accuracy: 0.69651 | valid_accuracy: 0.67959 |  0:00:11s\n",
      "epoch 59 | loss: 0.69965 | train_accuracy: 0.68359 | valid_accuracy: 0.66463 |  0:00:11s\n",
      "epoch 60 | loss: 0.71079 | train_accuracy: 0.69184 | valid_accuracy: 0.67347 |  0:00:11s\n",
      "epoch 61 | loss: 0.69857 | train_accuracy: 0.69753 | valid_accuracy: 0.67517 |  0:00:12s\n",
      "epoch 62 | loss: 0.70088 | train_accuracy: 0.69762 | valid_accuracy: 0.67687 |  0:00:12s\n",
      "epoch 63 | loss: 0.69988 | train_accuracy: 0.69549 | valid_accuracy: 0.67245 |  0:00:12s\n",
      "epoch 64 | loss: 0.7064  | train_accuracy: 0.69541 | valid_accuracy: 0.67313 |  0:00:12s\n",
      "epoch 65 | loss: 0.70343 | train_accuracy: 0.66386 | valid_accuracy: 0.64252 |  0:00:12s\n",
      "epoch 66 | loss: 0.70086 | train_accuracy: 0.69974 | valid_accuracy: 0.68605 |  0:00:13s\n",
      "epoch 67 | loss: 0.69049 | train_accuracy: 0.71293 | valid_accuracy: 0.7017  |  0:00:13s\n",
      "epoch 68 | loss: 0.6889  | train_accuracy: 0.69235 | valid_accuracy: 0.67517 |  0:00:13s\n",
      "epoch 69 | loss: 0.69684 | train_accuracy: 0.70357 | valid_accuracy: 0.68741 |  0:00:13s\n",
      "epoch 70 | loss: 0.68638 | train_accuracy: 0.70527 | valid_accuracy: 0.68571 |  0:00:13s\n",
      "epoch 71 | loss: 0.68014 | train_accuracy: 0.71148 | valid_accuracy: 0.69524 |  0:00:13s\n",
      "epoch 72 | loss: 0.67858 | train_accuracy: 0.69855 | valid_accuracy: 0.67789 |  0:00:14s\n",
      "epoch 73 | loss: 0.69086 | train_accuracy: 0.71233 | valid_accuracy: 0.69592 |  0:00:14s\n",
      "epoch 74 | loss: 0.68707 | train_accuracy: 0.70612 | valid_accuracy: 0.69116 |  0:00:14s\n",
      "epoch 75 | loss: 0.68418 | train_accuracy: 0.71182 | valid_accuracy: 0.69966 |  0:00:14s\n",
      "epoch 76 | loss: 0.67858 | train_accuracy: 0.71003 | valid_accuracy: 0.69014 |  0:00:14s\n",
      "epoch 77 | loss: 0.68585 | train_accuracy: 0.70451 | valid_accuracy: 0.67925 |  0:00:15s\n",
      "epoch 78 | loss: 0.67961 | train_accuracy: 0.71148 | valid_accuracy: 0.6932  |  0:00:15s\n",
      "epoch 79 | loss: 0.67828 | train_accuracy: 0.71054 | valid_accuracy: 0.70136 |  0:00:15s\n",
      "epoch 80 | loss: 0.69411 | train_accuracy: 0.71726 | valid_accuracy: 0.69728 |  0:00:15s\n",
      "epoch 81 | loss: 0.675   | train_accuracy: 0.71369 | valid_accuracy: 0.6898  |  0:00:15s\n",
      "epoch 82 | loss: 0.68116 | train_accuracy: 0.71437 | valid_accuracy: 0.69694 |  0:00:16s\n",
      "epoch 83 | loss: 0.66806 | train_accuracy: 0.72168 | valid_accuracy: 0.70272 |  0:00:16s\n",
      "epoch 84 | loss: 0.66511 | train_accuracy: 0.71905 | valid_accuracy: 0.69354 |  0:00:16s\n",
      "epoch 85 | loss: 0.6725  | train_accuracy: 0.71378 | valid_accuracy: 0.68265 |  0:00:16s\n",
      "epoch 86 | loss: 0.67016 | train_accuracy: 0.71131 | valid_accuracy: 0.68027 |  0:00:16s\n",
      "epoch 87 | loss: 0.67806 | train_accuracy: 0.71488 | valid_accuracy: 0.68844 |  0:00:17s\n",
      "epoch 88 | loss: 0.65928 | train_accuracy: 0.71233 | valid_accuracy: 0.68844 |  0:00:17s\n",
      "epoch 89 | loss: 0.66634 | train_accuracy: 0.70544 | valid_accuracy: 0.68639 |  0:00:17s\n",
      "epoch 90 | loss: 0.66706 | train_accuracy: 0.72151 | valid_accuracy: 0.6966  |  0:00:17s\n",
      "epoch 91 | loss: 0.66958 | train_accuracy: 0.72398 | valid_accuracy: 0.7017  |  0:00:17s\n",
      "epoch 92 | loss: 0.66711 | train_accuracy: 0.71871 | valid_accuracy: 0.70306 |  0:00:18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.66197 | train_accuracy: 0.71845 | valid_accuracy: 0.69388 |  0:00:18s\n",
      "epoch 94 | loss: 0.66391 | train_accuracy: 0.721   | valid_accuracy: 0.7017  |  0:00:18s\n",
      "epoch 95 | loss: 0.66577 | train_accuracy: 0.71888 | valid_accuracy: 0.69864 |  0:00:18s\n",
      "epoch 96 | loss: 0.66221 | train_accuracy: 0.72304 | valid_accuracy: 0.69762 |  0:00:18s\n",
      "epoch 97 | loss: 0.66285 | train_accuracy: 0.72262 | valid_accuracy: 0.70578 |  0:00:19s\n",
      "epoch 98 | loss: 0.65909 | train_accuracy: 0.7142  | valid_accuracy: 0.69014 |  0:00:19s\n",
      "epoch 99 | loss: 0.65558 | train_accuracy: 0.72543 | valid_accuracy: 0.7     |  0:00:19s\n",
      "epoch 100| loss: 0.64956 | train_accuracy: 0.7108  | valid_accuracy: 0.67993 |  0:00:19s\n",
      "epoch 101| loss: 0.65532 | train_accuracy: 0.72024 | valid_accuracy: 0.6932  |  0:00:19s\n",
      "epoch 102| loss: 0.65879 | train_accuracy: 0.71956 | valid_accuracy: 0.68639 |  0:00:19s\n",
      "epoch 103| loss: 0.65182 | train_accuracy: 0.7318  | valid_accuracy: 0.70238 |  0:00:20s\n",
      "epoch 104| loss: 0.65462 | train_accuracy: 0.72245 | valid_accuracy: 0.69728 |  0:00:20s\n",
      "epoch 105| loss: 0.65402 | train_accuracy: 0.72823 | valid_accuracy: 0.70918 |  0:00:20s\n",
      "epoch 106| loss: 0.65012 | train_accuracy: 0.73078 | valid_accuracy: 0.70408 |  0:00:20s\n",
      "epoch 107| loss: 0.64726 | train_accuracy: 0.72687 | valid_accuracy: 0.70136 |  0:00:20s\n",
      "epoch 108| loss: 0.64857 | train_accuracy: 0.72747 | valid_accuracy: 0.7     |  0:00:21s\n",
      "epoch 109| loss: 0.6478  | train_accuracy: 0.72815 | valid_accuracy: 0.70102 |  0:00:21s\n",
      "epoch 110| loss: 0.64179 | train_accuracy: 0.72194 | valid_accuracy: 0.68707 |  0:00:21s\n",
      "epoch 111| loss: 0.6419  | train_accuracy: 0.73036 | valid_accuracy: 0.70306 |  0:00:21s\n",
      "epoch 112| loss: 0.63731 | train_accuracy: 0.73265 | valid_accuracy: 0.70782 |  0:00:21s\n",
      "epoch 113| loss: 0.63311 | train_accuracy: 0.72628 | valid_accuracy: 0.69524 |  0:00:22s\n",
      "epoch 114| loss: 0.63555 | train_accuracy: 0.73537 | valid_accuracy: 0.7034  |  0:00:22s\n",
      "epoch 115| loss: 0.63384 | train_accuracy: 0.73087 | valid_accuracy: 0.70782 |  0:00:22s\n",
      "epoch 116| loss: 0.63821 | train_accuracy: 0.73146 | valid_accuracy: 0.70986 |  0:00:22s\n",
      "epoch 117| loss: 0.64529 | train_accuracy: 0.73495 | valid_accuracy: 0.7102  |  0:00:22s\n",
      "epoch 118| loss: 0.65483 | train_accuracy: 0.71777 | valid_accuracy: 0.6932  |  0:00:23s\n",
      "epoch 119| loss: 0.64555 | train_accuracy: 0.73197 | valid_accuracy: 0.70612 |  0:00:23s\n",
      "epoch 120| loss: 0.63892 | train_accuracy: 0.73478 | valid_accuracy: 0.71429 |  0:00:23s\n",
      "epoch 121| loss: 0.63201 | train_accuracy: 0.73767 | valid_accuracy: 0.71463 |  0:00:23s\n",
      "epoch 122| loss: 0.63065 | train_accuracy: 0.7415  | valid_accuracy: 0.71463 |  0:00:23s\n",
      "epoch 123| loss: 0.62801 | train_accuracy: 0.73784 | valid_accuracy: 0.71122 |  0:00:23s\n",
      "epoch 124| loss: 0.62153 | train_accuracy: 0.74328 | valid_accuracy: 0.72245 |  0:00:24s\n",
      "epoch 125| loss: 0.6275  | train_accuracy: 0.73512 | valid_accuracy: 0.71122 |  0:00:24s\n",
      "epoch 126| loss: 0.61383 | train_accuracy: 0.7318  | valid_accuracy: 0.70646 |  0:00:24s\n",
      "epoch 127| loss: 0.62391 | train_accuracy: 0.73631 | valid_accuracy: 0.7119  |  0:00:24s\n",
      "epoch 128| loss: 0.62442 | train_accuracy: 0.74294 | valid_accuracy: 0.72109 |  0:00:24s\n",
      "epoch 129| loss: 0.62044 | train_accuracy: 0.73231 | valid_accuracy: 0.70578 |  0:00:25s\n",
      "epoch 130| loss: 0.61914 | train_accuracy: 0.74345 | valid_accuracy: 0.71973 |  0:00:25s\n",
      "epoch 131| loss: 0.61398 | train_accuracy: 0.74473 | valid_accuracy: 0.73129 |  0:00:25s\n",
      "epoch 132| loss: 0.62809 | train_accuracy: 0.74405 | valid_accuracy: 0.71769 |  0:00:25s\n",
      "epoch 133| loss: 0.61772 | train_accuracy: 0.74643 | valid_accuracy: 0.72551 |  0:00:25s\n",
      "epoch 134| loss: 0.61123 | train_accuracy: 0.73835 | valid_accuracy: 0.71939 |  0:00:26s\n",
      "epoch 135| loss: 0.61478 | train_accuracy: 0.74413 | valid_accuracy: 0.72857 |  0:00:26s\n",
      "epoch 136| loss: 0.61154 | train_accuracy: 0.7409  | valid_accuracy: 0.72177 |  0:00:26s\n",
      "epoch 137| loss: 0.60564 | train_accuracy: 0.74541 | valid_accuracy: 0.72483 |  0:00:26s\n",
      "epoch 138| loss: 0.62164 | train_accuracy: 0.74456 | valid_accuracy: 0.71939 |  0:00:26s\n",
      "epoch 139| loss: 0.6209  | train_accuracy: 0.74864 | valid_accuracy: 0.73095 |  0:00:27s\n",
      "epoch 140| loss: 0.61397 | train_accuracy: 0.74966 | valid_accuracy: 0.71973 |  0:00:27s\n",
      "epoch 141| loss: 0.61198 | train_accuracy: 0.74031 | valid_accuracy: 0.71463 |  0:00:27s\n",
      "epoch 142| loss: 0.61432 | train_accuracy: 0.74864 | valid_accuracy: 0.72551 |  0:00:27s\n",
      "epoch 143| loss: 0.60756 | train_accuracy: 0.74218 | valid_accuracy: 0.71973 |  0:00:27s\n",
      "epoch 144| loss: 0.61075 | train_accuracy: 0.74379 | valid_accuracy: 0.72789 |  0:00:28s\n",
      "epoch 145| loss: 0.59764 | train_accuracy: 0.74855 | valid_accuracy: 0.72653 |  0:00:28s\n",
      "epoch 146| loss: 0.61178 | train_accuracy: 0.7335  | valid_accuracy: 0.71463 |  0:00:28s\n",
      "epoch 147| loss: 0.61817 | train_accuracy: 0.74294 | valid_accuracy: 0.72177 |  0:00:28s\n",
      "epoch 148| loss: 0.61018 | train_accuracy: 0.74668 | valid_accuracy: 0.72279 |  0:00:28s\n",
      "epoch 149| loss: 0.61121 | train_accuracy: 0.75587 | valid_accuracy: 0.72959 |  0:00:29s\n",
      "epoch 150| loss: 0.60712 | train_accuracy: 0.74762 | valid_accuracy: 0.72687 |  0:00:29s\n",
      "epoch 151| loss: 0.61004 | train_accuracy: 0.75051 | valid_accuracy: 0.72993 |  0:00:29s\n",
      "epoch 152| loss: 0.60025 | train_accuracy: 0.74617 | valid_accuracy: 0.72109 |  0:00:29s\n",
      "epoch 153| loss: 0.59165 | train_accuracy: 0.75349 | valid_accuracy: 0.72415 |  0:00:29s\n",
      "epoch 154| loss: 0.59117 | train_accuracy: 0.75782 | valid_accuracy: 0.73333 |  0:00:29s\n",
      "epoch 155| loss: 0.59897 | train_accuracy: 0.75383 | valid_accuracy: 0.74048 |  0:00:30s\n",
      "epoch 156| loss: 0.59839 | train_accuracy: 0.75357 | valid_accuracy: 0.73435 |  0:00:30s\n",
      "epoch 157| loss: 0.59859 | train_accuracy: 0.75697 | valid_accuracy: 0.73673 |  0:00:30s\n",
      "epoch 158| loss: 0.60979 | train_accuracy: 0.75782 | valid_accuracy: 0.73401 |  0:00:30s\n",
      "epoch 159| loss: 0.60435 | train_accuracy: 0.74966 | valid_accuracy: 0.72789 |  0:00:30s\n",
      "epoch 160| loss: 0.59843 | train_accuracy: 0.75306 | valid_accuracy: 0.72755 |  0:00:31s\n",
      "epoch 161| loss: 0.60166 | train_accuracy: 0.75332 | valid_accuracy: 0.73265 |  0:00:31s\n",
      "epoch 162| loss: 0.59169 | train_accuracy: 0.74252 | valid_accuracy: 0.72381 |  0:00:31s\n",
      "epoch 163| loss: 0.60433 | train_accuracy: 0.7574  | valid_accuracy: 0.73231 |  0:00:31s\n",
      "epoch 164| loss: 0.59947 | train_accuracy: 0.75969 | valid_accuracy: 0.7381  |  0:00:31s\n",
      "epoch 165| loss: 0.5975  | train_accuracy: 0.75451 | valid_accuracy: 0.73231 |  0:00:32s\n",
      "epoch 166| loss: 0.5978  | train_accuracy: 0.75468 | valid_accuracy: 0.73265 |  0:00:32s\n",
      "epoch 167| loss: 0.5832  | train_accuracy: 0.76267 | valid_accuracy: 0.73776 |  0:00:32s\n",
      "epoch 168| loss: 0.59032 | train_accuracy: 0.75986 | valid_accuracy: 0.73776 |  0:00:32s\n",
      "epoch 169| loss: 0.58737 | train_accuracy: 0.76301 | valid_accuracy: 0.73878 |  0:00:32s\n",
      "epoch 170| loss: 0.58948 | train_accuracy: 0.76156 | valid_accuracy: 0.73878 |  0:00:33s\n",
      "epoch 171| loss: 0.58623 | train_accuracy: 0.76514 | valid_accuracy: 0.74218 |  0:00:33s\n",
      "epoch 172| loss: 0.58497 | train_accuracy: 0.76344 | valid_accuracy: 0.74014 |  0:00:33s\n",
      "epoch 173| loss: 0.58602 | train_accuracy: 0.76207 | valid_accuracy: 0.74116 |  0:00:33s\n",
      "epoch 174| loss: 0.58494 | train_accuracy: 0.76633 | valid_accuracy: 0.74218 |  0:00:33s\n",
      "epoch 175| loss: 0.58758 | train_accuracy: 0.7631  | valid_accuracy: 0.73946 |  0:00:34s\n",
      "epoch 176| loss: 0.58682 | train_accuracy: 0.75808 | valid_accuracy: 0.73367 |  0:00:34s\n",
      "epoch 177| loss: 0.58167 | train_accuracy: 0.76378 | valid_accuracy: 0.74592 |  0:00:34s\n",
      "epoch 178| loss: 0.58404 | train_accuracy: 0.76641 | valid_accuracy: 0.74184 |  0:00:34s\n",
      "epoch 179| loss: 0.58646 | train_accuracy: 0.75995 | valid_accuracy: 0.73537 |  0:00:34s\n",
      "epoch 180| loss: 0.5781  | train_accuracy: 0.76956 | valid_accuracy: 0.74014 |  0:00:35s\n",
      "epoch 181| loss: 0.5862  | train_accuracy: 0.76769 | valid_accuracy: 0.7449  |  0:00:35s\n",
      "epoch 182| loss: 0.57478 | train_accuracy: 0.76454 | valid_accuracy: 0.7449  |  0:00:35s\n",
      "epoch 183| loss: 0.58487 | train_accuracy: 0.76709 | valid_accuracy: 0.7432  |  0:00:35s\n",
      "epoch 184| loss: 0.5768  | train_accuracy: 0.76922 | valid_accuracy: 0.7449  |  0:00:35s\n",
      "epoch 185| loss: 0.58456 | train_accuracy: 0.76939 | valid_accuracy: 0.7398  |  0:00:35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186| loss: 0.5751  | train_accuracy: 0.77007 | valid_accuracy: 0.74456 |  0:00:36s\n",
      "epoch 187| loss: 0.57442 | train_accuracy: 0.76378 | valid_accuracy: 0.73776 |  0:00:36s\n",
      "epoch 188| loss: 0.58913 | train_accuracy: 0.76743 | valid_accuracy: 0.74252 |  0:00:36s\n",
      "epoch 189| loss: 0.58907 | train_accuracy: 0.76607 | valid_accuracy: 0.73741 |  0:00:36s\n",
      "epoch 190| loss: 0.5815  | train_accuracy: 0.7676  | valid_accuracy: 0.74694 |  0:00:36s\n",
      "epoch 191| loss: 0.58115 | train_accuracy: 0.76692 | valid_accuracy: 0.74184 |  0:00:37s\n",
      "epoch 192| loss: 0.57275 | train_accuracy: 0.77211 | valid_accuracy: 0.74524 |  0:00:37s\n",
      "epoch 193| loss: 0.57608 | train_accuracy: 0.76828 | valid_accuracy: 0.74218 |  0:00:37s\n",
      "epoch 194| loss: 0.58532 | train_accuracy: 0.77406 | valid_accuracy: 0.74932 |  0:00:37s\n",
      "epoch 195| loss: 0.58207 | train_accuracy: 0.76735 | valid_accuracy: 0.74728 |  0:00:37s\n",
      "epoch 196| loss: 0.58388 | train_accuracy: 0.76879 | valid_accuracy: 0.73605 |  0:00:38s\n",
      "epoch 197| loss: 0.57896 | train_accuracy: 0.77279 | valid_accuracy: 0.7432  |  0:00:38s\n",
      "epoch 198| loss: 0.57994 | train_accuracy: 0.76403 | valid_accuracy: 0.73129 |  0:00:38s\n",
      "epoch 199| loss: 0.57641 | train_accuracy: 0.77279 | valid_accuracy: 0.74796 |  0:00:38s\n",
      "epoch 200| loss: 0.58092 | train_accuracy: 0.77024 | valid_accuracy: 0.74116 |  0:00:38s\n",
      "epoch 201| loss: 0.57828 | train_accuracy: 0.76871 | valid_accuracy: 0.73639 |  0:00:39s\n",
      "epoch 202| loss: 0.57815 | train_accuracy: 0.77287 | valid_accuracy: 0.74796 |  0:00:39s\n",
      "epoch 203| loss: 0.58014 | train_accuracy: 0.77585 | valid_accuracy: 0.7517  |  0:00:39s\n",
      "epoch 204| loss: 0.5856  | train_accuracy: 0.7744  | valid_accuracy: 0.7449  |  0:00:39s\n",
      "epoch 205| loss: 0.57735 | train_accuracy: 0.76888 | valid_accuracy: 0.73707 |  0:00:39s\n",
      "epoch 206| loss: 0.56996 | train_accuracy: 0.77398 | valid_accuracy: 0.74388 |  0:00:40s\n",
      "epoch 207| loss: 0.57638 | train_accuracy: 0.77372 | valid_accuracy: 0.7517  |  0:00:40s\n",
      "epoch 208| loss: 0.57214 | train_accuracy: 0.77211 | valid_accuracy: 0.74184 |  0:00:40s\n",
      "epoch 209| loss: 0.57079 | train_accuracy: 0.77577 | valid_accuracy: 0.74456 |  0:00:40s\n",
      "epoch 210| loss: 0.56578 | train_accuracy: 0.77483 | valid_accuracy: 0.75068 |  0:00:40s\n",
      "epoch 211| loss: 0.5659  | train_accuracy: 0.77908 | valid_accuracy: 0.75238 |  0:00:40s\n",
      "epoch 212| loss: 0.57627 | train_accuracy: 0.76947 | valid_accuracy: 0.7432  |  0:00:41s\n",
      "epoch 213| loss: 0.57179 | train_accuracy: 0.77832 | valid_accuracy: 0.7534  |  0:00:41s\n",
      "epoch 214| loss: 0.56227 | train_accuracy: 0.76922 | valid_accuracy: 0.7415  |  0:00:41s\n",
      "epoch 215| loss: 0.57809 | train_accuracy: 0.77202 | valid_accuracy: 0.74796 |  0:00:41s\n",
      "epoch 216| loss: 0.5696  | train_accuracy: 0.77891 | valid_accuracy: 0.75034 |  0:00:41s\n",
      "epoch 217| loss: 0.57322 | train_accuracy: 0.77032 | valid_accuracy: 0.74048 |  0:00:42s\n",
      "epoch 218| loss: 0.57128 | train_accuracy: 0.77534 | valid_accuracy: 0.75068 |  0:00:42s\n",
      "epoch 219| loss: 0.57693 | train_accuracy: 0.77628 | valid_accuracy: 0.74456 |  0:00:42s\n",
      "epoch 220| loss: 0.56753 | train_accuracy: 0.77474 | valid_accuracy: 0.74456 |  0:00:42s\n",
      "epoch 221| loss: 0.5634  | train_accuracy: 0.77517 | valid_accuracy: 0.74796 |  0:00:42s\n",
      "epoch 222| loss: 0.56625 | train_accuracy: 0.76412 | valid_accuracy: 0.73299 |  0:00:43s\n",
      "epoch 223| loss: 0.57115 | train_accuracy: 0.77398 | valid_accuracy: 0.7466  |  0:00:43s\n",
      "epoch 224| loss: 0.56697 | train_accuracy: 0.77245 | valid_accuracy: 0.7449  |  0:00:43s\n",
      "epoch 225| loss: 0.57473 | train_accuracy: 0.77381 | valid_accuracy: 0.74592 |  0:00:43s\n",
      "epoch 226| loss: 0.56967 | train_accuracy: 0.77543 | valid_accuracy: 0.75    |  0:00:43s\n",
      "epoch 227| loss: 0.56672 | train_accuracy: 0.77509 | valid_accuracy: 0.74762 |  0:00:44s\n",
      "epoch 228| loss: 0.56871 | train_accuracy: 0.77798 | valid_accuracy: 0.74898 |  0:00:44s\n",
      "epoch 229| loss: 0.57531 | train_accuracy: 0.77526 | valid_accuracy: 0.74796 |  0:00:44s\n",
      "epoch 230| loss: 0.57048 | train_accuracy: 0.77747 | valid_accuracy: 0.7517  |  0:00:44s\n",
      "epoch 231| loss: 0.56387 | train_accuracy: 0.78486 | valid_accuracy: 0.75544 |  0:00:44s\n",
      "epoch 232| loss: 0.56338 | train_accuracy: 0.77713 | valid_accuracy: 0.7517  |  0:00:45s\n",
      "epoch 233| loss: 0.5689  | train_accuracy: 0.78095 | valid_accuracy: 0.75034 |  0:00:45s\n",
      "epoch 234| loss: 0.57305 | train_accuracy: 0.77568 | valid_accuracy: 0.7483  |  0:00:45s\n",
      "epoch 235| loss: 0.56757 | train_accuracy: 0.78095 | valid_accuracy: 0.74796 |  0:00:45s\n",
      "epoch 236| loss: 0.56611 | train_accuracy: 0.77917 | valid_accuracy: 0.7517  |  0:00:45s\n",
      "epoch 237| loss: 0.56275 | train_accuracy: 0.7824  | valid_accuracy: 0.75204 |  0:00:46s\n",
      "epoch 238| loss: 0.57324 | train_accuracy: 0.77764 | valid_accuracy: 0.74966 |  0:00:46s\n",
      "epoch 239| loss: 0.57286 | train_accuracy: 0.77883 | valid_accuracy: 0.75034 |  0:00:46s\n",
      "epoch 240| loss: 0.56181 | train_accuracy: 0.77951 | valid_accuracy: 0.75204 |  0:00:46s\n",
      "epoch 241| loss: 0.56989 | train_accuracy: 0.77704 | valid_accuracy: 0.74762 |  0:00:46s\n",
      "epoch 242| loss: 0.56168 | train_accuracy: 0.77534 | valid_accuracy: 0.74388 |  0:00:46s\n",
      "epoch 243| loss: 0.56444 | train_accuracy: 0.78384 | valid_accuracy: 0.75    |  0:00:47s\n",
      "epoch 244| loss: 0.56153 | train_accuracy: 0.78231 | valid_accuracy: 0.74932 |  0:00:47s\n",
      "epoch 245| loss: 0.55261 | train_accuracy: 0.77976 | valid_accuracy: 0.75    |  0:00:47s\n",
      "epoch 246| loss: 0.56198 | train_accuracy: 0.78257 | valid_accuracy: 0.75034 |  0:00:47s\n",
      "epoch 247| loss: 0.56365 | train_accuracy: 0.77993 | valid_accuracy: 0.7466  |  0:00:47s\n",
      "epoch 248| loss: 0.56256 | train_accuracy: 0.7773  | valid_accuracy: 0.74762 |  0:00:48s\n",
      "epoch 249| loss: 0.56114 | train_accuracy: 0.78019 | valid_accuracy: 0.75034 |  0:00:48s\n",
      "epoch 250| loss: 0.56534 | train_accuracy: 0.78197 | valid_accuracy: 0.74864 |  0:00:48s\n",
      "epoch 251| loss: 0.56423 | train_accuracy: 0.77423 | valid_accuracy: 0.74116 |  0:00:48s\n",
      "epoch 252| loss: 0.56959 | train_accuracy: 0.779   | valid_accuracy: 0.74626 |  0:00:48s\n",
      "epoch 253| loss: 0.55969 | train_accuracy: 0.78053 | valid_accuracy: 0.7483  |  0:00:49s\n",
      "epoch 254| loss: 0.56392 | train_accuracy: 0.78257 | valid_accuracy: 0.7517  |  0:00:49s\n",
      "epoch 255| loss: 0.55897 | train_accuracy: 0.78146 | valid_accuracy: 0.74898 |  0:00:49s\n",
      "epoch 256| loss: 0.56079 | train_accuracy: 0.77815 | valid_accuracy: 0.74796 |  0:00:49s\n",
      "\n",
      "Early stopping occurred at epoch 256 with best_epoch = 231 and best_valid_accuracy = 0.75544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "231\n",
      "epoch 0  | loss: 1.33201 | train_accuracy: 0.32577 | valid_accuracy: 0.32177 |  0:00:00s\n",
      "epoch 1  | loss: 1.04858 | train_accuracy: 0.3051  | valid_accuracy: 0.29184 |  0:00:00s\n",
      "epoch 2  | loss: 0.97887 | train_accuracy: 0.38223 | valid_accuracy: 0.37755 |  0:00:00s\n",
      "epoch 3  | loss: 0.94267 | train_accuracy: 0.40621 | valid_accuracy: 0.41361 |  0:00:00s\n",
      "epoch 4  | loss: 0.91743 | train_accuracy: 0.42347 | valid_accuracy: 0.42075 |  0:00:00s\n",
      "epoch 5  | loss: 0.89855 | train_accuracy: 0.51862 | valid_accuracy: 0.52585 |  0:00:01s\n",
      "epoch 6  | loss: 0.87291 | train_accuracy: 0.47483 | valid_accuracy: 0.48912 |  0:00:01s\n",
      "epoch 7  | loss: 0.87151 | train_accuracy: 0.43291 | valid_accuracy: 0.43333 |  0:00:01s\n",
      "epoch 8  | loss: 0.85639 | train_accuracy: 0.55315 | valid_accuracy: 0.55646 |  0:00:01s\n",
      "epoch 9  | loss: 0.84324 | train_accuracy: 0.4665  | valid_accuracy: 0.47007 |  0:00:01s\n",
      "epoch 10 | loss: 0.8402  | train_accuracy: 0.44881 | valid_accuracy: 0.45918 |  0:00:02s\n",
      "epoch 11 | loss: 0.83571 | train_accuracy: 0.54787 | valid_accuracy: 0.5483  |  0:00:02s\n",
      "epoch 12 | loss: 0.83851 | train_accuracy: 0.44685 | valid_accuracy: 0.45442 |  0:00:02s\n",
      "epoch 13 | loss: 0.8267  | train_accuracy: 0.54991 | valid_accuracy: 0.54694 |  0:00:02s\n",
      "epoch 14 | loss: 0.82008 | train_accuracy: 0.50238 | valid_accuracy: 0.4983  |  0:00:02s\n",
      "epoch 15 | loss: 0.8197  | train_accuracy: 0.59124 | valid_accuracy: 0.58299 |  0:00:03s\n",
      "epoch 16 | loss: 0.81762 | train_accuracy: 0.60408 | valid_accuracy: 0.60204 |  0:00:03s\n",
      "epoch 17 | loss: 0.80707 | train_accuracy: 0.47466 | valid_accuracy: 0.46463 |  0:00:03s\n",
      "epoch 18 | loss: 0.81078 | train_accuracy: 0.5369  | valid_accuracy: 0.52041 |  0:00:03s\n",
      "epoch 19 | loss: 0.80146 | train_accuracy: 0.55485 | valid_accuracy: 0.53707 |  0:00:03s\n",
      "epoch 20 | loss: 0.79498 | train_accuracy: 0.6398  | valid_accuracy: 0.63265 |  0:00:04s\n",
      "epoch 21 | loss: 0.79385 | train_accuracy: 0.63469 | valid_accuracy: 0.63435 |  0:00:04s\n",
      "epoch 22 | loss: 0.78299 | train_accuracy: 0.56854 | valid_accuracy: 0.56224 |  0:00:04s\n",
      "epoch 23 | loss: 0.77749 | train_accuracy: 0.66224 | valid_accuracy: 0.64286 |  0:00:04s\n",
      "epoch 24 | loss: 0.77315 | train_accuracy: 0.65663 | valid_accuracy: 0.64218 |  0:00:04s\n",
      "epoch 25 | loss: 0.77635 | train_accuracy: 0.64022 | valid_accuracy: 0.63197 |  0:00:05s\n",
      "epoch 26 | loss: 0.76487 | train_accuracy: 0.58818 | valid_accuracy: 0.57823 |  0:00:05s\n",
      "epoch 27 | loss: 0.76833 | train_accuracy: 0.6523  | valid_accuracy: 0.6466  |  0:00:05s\n",
      "epoch 28 | loss: 0.77477 | train_accuracy: 0.61446 | valid_accuracy: 0.59728 |  0:00:05s\n",
      "epoch 29 | loss: 0.78069 | train_accuracy: 0.64923 | valid_accuracy: 0.64048 |  0:00:05s\n",
      "epoch 30 | loss: 0.77453 | train_accuracy: 0.6398  | valid_accuracy: 0.62211 |  0:00:06s\n",
      "epoch 31 | loss: 0.76247 | train_accuracy: 0.65315 | valid_accuracy: 0.63571 |  0:00:06s\n",
      "epoch 32 | loss: 0.75219 | train_accuracy: 0.65757 | valid_accuracy: 0.65204 |  0:00:06s\n",
      "epoch 33 | loss: 0.75548 | train_accuracy: 0.58946 | valid_accuracy: 0.57245 |  0:00:06s\n",
      "epoch 34 | loss: 0.76534 | train_accuracy: 0.6648  | valid_accuracy: 0.65884 |  0:00:06s\n",
      "epoch 35 | loss: 0.75638 | train_accuracy: 0.66913 | valid_accuracy: 0.65714 |  0:00:06s\n",
      "epoch 36 | loss: 0.74973 | train_accuracy: 0.66139 | valid_accuracy: 0.6517  |  0:00:07s\n",
      "epoch 37 | loss: 0.75506 | train_accuracy: 0.66539 | valid_accuracy: 0.65816 |  0:00:07s\n",
      "epoch 38 | loss: 0.7443  | train_accuracy: 0.66207 | valid_accuracy: 0.65272 |  0:00:07s\n",
      "epoch 39 | loss: 0.74868 | train_accuracy: 0.67279 | valid_accuracy: 0.6602  |  0:00:07s\n",
      "epoch 40 | loss: 0.74361 | train_accuracy: 0.68044 | valid_accuracy: 0.66837 |  0:00:07s\n",
      "epoch 41 | loss: 0.73204 | train_accuracy: 0.67747 | valid_accuracy: 0.67075 |  0:00:08s\n",
      "epoch 42 | loss: 0.72797 | train_accuracy: 0.68172 | valid_accuracy: 0.67449 |  0:00:08s\n",
      "epoch 43 | loss: 0.72605 | train_accuracy: 0.67245 | valid_accuracy: 0.65884 |  0:00:08s\n",
      "epoch 44 | loss: 0.7261  | train_accuracy: 0.67747 | valid_accuracy: 0.65646 |  0:00:08s\n",
      "epoch 45 | loss: 0.71912 | train_accuracy: 0.67543 | valid_accuracy: 0.66803 |  0:00:08s\n",
      "epoch 46 | loss: 0.71932 | train_accuracy: 0.68418 | valid_accuracy: 0.67415 |  0:00:09s\n",
      "epoch 47 | loss: 0.73223 | train_accuracy: 0.67372 | valid_accuracy: 0.66395 |  0:00:09s\n",
      "epoch 48 | loss: 0.72113 | train_accuracy: 0.67041 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 49 | loss: 0.72749 | train_accuracy: 0.68418 | valid_accuracy: 0.67857 |  0:00:09s\n",
      "epoch 50 | loss: 0.71467 | train_accuracy: 0.68112 | valid_accuracy: 0.67075 |  0:00:09s\n",
      "epoch 51 | loss: 0.71245 | train_accuracy: 0.67976 | valid_accuracy: 0.67177 |  0:00:10s\n",
      "epoch 52 | loss: 0.69559 | train_accuracy: 0.68988 | valid_accuracy: 0.68435 |  0:00:10s\n",
      "epoch 53 | loss: 0.69451 | train_accuracy: 0.70451 | valid_accuracy: 0.6932  |  0:00:10s\n",
      "epoch 54 | loss: 0.70225 | train_accuracy: 0.68793 | valid_accuracy: 0.68265 |  0:00:10s\n",
      "epoch 55 | loss: 0.70705 | train_accuracy: 0.66054 | valid_accuracy: 0.64626 |  0:00:10s\n",
      "epoch 56 | loss: 0.6958  | train_accuracy: 0.69872 | valid_accuracy: 0.69456 |  0:00:11s\n",
      "epoch 57 | loss: 0.6909  | train_accuracy: 0.70128 | valid_accuracy: 0.68605 |  0:00:11s\n",
      "epoch 58 | loss: 0.69823 | train_accuracy: 0.65272 | valid_accuracy: 0.64422 |  0:00:11s\n",
      "epoch 59 | loss: 0.6967  | train_accuracy: 0.69728 | valid_accuracy: 0.68741 |  0:00:11s\n",
      "epoch 60 | loss: 0.69312 | train_accuracy: 0.704   | valid_accuracy: 0.68707 |  0:00:11s\n",
      "epoch 61 | loss: 0.68604 | train_accuracy: 0.70655 | valid_accuracy: 0.69116 |  0:00:12s\n",
      "epoch 62 | loss: 0.68158 | train_accuracy: 0.70238 | valid_accuracy: 0.69082 |  0:00:12s\n",
      "epoch 63 | loss: 0.69758 | train_accuracy: 0.70128 | valid_accuracy: 0.6966  |  0:00:12s\n",
      "epoch 64 | loss: 0.69649 | train_accuracy: 0.7006  | valid_accuracy: 0.69762 |  0:00:12s\n",
      "epoch 65 | loss: 0.68882 | train_accuracy: 0.70816 | valid_accuracy: 0.69796 |  0:00:12s\n",
      "epoch 66 | loss: 0.67225 | train_accuracy: 0.71786 | valid_accuracy: 0.70918 |  0:00:12s\n",
      "epoch 67 | loss: 0.67463 | train_accuracy: 0.65306 | valid_accuracy: 0.63707 |  0:00:13s\n",
      "epoch 68 | loss: 0.68524 | train_accuracy: 0.71063 | valid_accuracy: 0.70714 |  0:00:13s\n",
      "epoch 69 | loss: 0.68665 | train_accuracy: 0.69932 | valid_accuracy: 0.6915  |  0:00:13s\n",
      "epoch 70 | loss: 0.6727  | train_accuracy: 0.71862 | valid_accuracy: 0.71429 |  0:00:13s\n",
      "epoch 71 | loss: 0.67331 | train_accuracy: 0.71599 | valid_accuracy: 0.71327 |  0:00:13s\n",
      "epoch 72 | loss: 0.66738 | train_accuracy: 0.72662 | valid_accuracy: 0.71327 |  0:00:14s\n",
      "epoch 73 | loss: 0.66263 | train_accuracy: 0.67934 | valid_accuracy: 0.67619 |  0:00:14s\n",
      "epoch 74 | loss: 0.65764 | train_accuracy: 0.72611 | valid_accuracy: 0.71769 |  0:00:14s\n",
      "epoch 75 | loss: 0.65037 | train_accuracy: 0.72568 | valid_accuracy: 0.71293 |  0:00:14s\n",
      "epoch 76 | loss: 0.65423 | train_accuracy: 0.68248 | valid_accuracy: 0.66871 |  0:00:14s\n",
      "epoch 77 | loss: 0.65067 | train_accuracy: 0.71573 | valid_accuracy: 0.70544 |  0:00:15s\n",
      "epoch 78 | loss: 0.65923 | train_accuracy: 0.67645 | valid_accuracy: 0.66531 |  0:00:15s\n",
      "epoch 79 | loss: 0.67687 | train_accuracy: 0.71403 | valid_accuracy: 0.71054 |  0:00:15s\n",
      "epoch 80 | loss: 0.66448 | train_accuracy: 0.71403 | valid_accuracy: 0.69762 |  0:00:15s\n",
      "epoch 81 | loss: 0.65087 | train_accuracy: 0.71743 | valid_accuracy: 0.70476 |  0:00:15s\n",
      "epoch 82 | loss: 0.65752 | train_accuracy: 0.67491 | valid_accuracy: 0.67381 |  0:00:16s\n",
      "epoch 83 | loss: 0.6536  | train_accuracy: 0.72551 | valid_accuracy: 0.71769 |  0:00:16s\n",
      "epoch 84 | loss: 0.64046 | train_accuracy: 0.72483 | valid_accuracy: 0.71803 |  0:00:16s\n",
      "epoch 85 | loss: 0.65113 | train_accuracy: 0.71165 | valid_accuracy: 0.69898 |  0:00:16s\n",
      "epoch 86 | loss: 0.64786 | train_accuracy: 0.71378 | valid_accuracy: 0.71463 |  0:00:16s\n",
      "epoch 87 | loss: 0.65414 | train_accuracy: 0.73138 | valid_accuracy: 0.72279 |  0:00:16s\n",
      "epoch 88 | loss: 0.6456  | train_accuracy: 0.70833 | valid_accuracy: 0.69728 |  0:00:17s\n",
      "epoch 89 | loss: 0.64363 | train_accuracy: 0.71794 | valid_accuracy: 0.70782 |  0:00:17s\n",
      "epoch 90 | loss: 0.64145 | train_accuracy: 0.7358  | valid_accuracy: 0.72347 |  0:00:17s\n",
      "epoch 91 | loss: 0.62993 | train_accuracy: 0.72304 | valid_accuracy: 0.72415 |  0:00:17s\n",
      "epoch 92 | loss: 0.63321 | train_accuracy: 0.7369  | valid_accuracy: 0.73299 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.63878 | train_accuracy: 0.72381 | valid_accuracy: 0.71871 |  0:00:18s\n",
      "epoch 94 | loss: 0.6347  | train_accuracy: 0.70961 | valid_accuracy: 0.70306 |  0:00:18s\n",
      "epoch 95 | loss: 0.64686 | train_accuracy: 0.71641 | valid_accuracy: 0.70646 |  0:00:18s\n",
      "epoch 96 | loss: 0.63288 | train_accuracy: 0.73333 | valid_accuracy: 0.72551 |  0:00:18s\n",
      "epoch 97 | loss: 0.61995 | train_accuracy: 0.73937 | valid_accuracy: 0.72075 |  0:00:18s\n",
      "epoch 98 | loss: 0.61711 | train_accuracy: 0.73044 | valid_accuracy: 0.72551 |  0:00:19s\n",
      "epoch 99 | loss: 0.64053 | train_accuracy: 0.71718 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 100| loss: 0.61833 | train_accuracy: 0.71871 | valid_accuracy: 0.70918 |  0:00:19s\n",
      "epoch 101| loss: 0.63049 | train_accuracy: 0.72313 | valid_accuracy: 0.71156 |  0:00:19s\n",
      "epoch 102| loss: 0.63207 | train_accuracy: 0.73155 | valid_accuracy: 0.72551 |  0:00:19s\n",
      "epoch 103| loss: 0.62451 | train_accuracy: 0.74617 | valid_accuracy: 0.73435 |  0:00:20s\n",
      "epoch 104| loss: 0.61963 | train_accuracy: 0.71939 | valid_accuracy: 0.71224 |  0:00:20s\n",
      "epoch 105| loss: 0.61635 | train_accuracy: 0.69507 | valid_accuracy: 0.69422 |  0:00:20s\n",
      "epoch 106| loss: 0.62918 | train_accuracy: 0.7318  | valid_accuracy: 0.71871 |  0:00:20s\n",
      "epoch 107| loss: 0.63309 | train_accuracy: 0.71556 | valid_accuracy: 0.70408 |  0:00:20s\n",
      "epoch 108| loss: 0.62381 | train_accuracy: 0.72823 | valid_accuracy: 0.72109 |  0:00:21s\n",
      "epoch 109| loss: 0.61672 | train_accuracy: 0.72764 | valid_accuracy: 0.7085  |  0:00:21s\n",
      "epoch 110| loss: 0.61092 | train_accuracy: 0.74116 | valid_accuracy: 0.74728 |  0:00:21s\n",
      "epoch 111| loss: 0.60627 | train_accuracy: 0.74039 | valid_accuracy: 0.72789 |  0:00:21s\n",
      "epoch 112| loss: 0.61624 | train_accuracy: 0.75519 | valid_accuracy: 0.74898 |  0:00:21s\n",
      "epoch 113| loss: 0.61003 | train_accuracy: 0.74022 | valid_accuracy: 0.73129 |  0:00:22s\n",
      "epoch 114| loss: 0.60946 | train_accuracy: 0.72696 | valid_accuracy: 0.71939 |  0:00:22s\n",
      "epoch 115| loss: 0.61263 | train_accuracy: 0.74107 | valid_accuracy: 0.73571 |  0:00:22s\n",
      "epoch 116| loss: 0.62131 | train_accuracy: 0.74736 | valid_accuracy: 0.74014 |  0:00:22s\n",
      "epoch 117| loss: 0.60151 | train_accuracy: 0.73512 | valid_accuracy: 0.72721 |  0:00:22s\n",
      "epoch 118| loss: 0.61324 | train_accuracy: 0.73282 | valid_accuracy: 0.72143 |  0:00:22s\n",
      "epoch 119| loss: 0.5984  | train_accuracy: 0.74813 | valid_accuracy: 0.73912 |  0:00:23s\n",
      "epoch 120| loss: 0.60491 | train_accuracy: 0.74167 | valid_accuracy: 0.73503 |  0:00:23s\n",
      "epoch 121| loss: 0.59271 | train_accuracy: 0.74532 | valid_accuracy: 0.74388 |  0:00:23s\n",
      "epoch 122| loss: 0.60566 | train_accuracy: 0.74456 | valid_accuracy: 0.73605 |  0:00:23s\n",
      "epoch 123| loss: 0.5946  | train_accuracy: 0.74719 | valid_accuracy: 0.74728 |  0:00:23s\n",
      "epoch 124| loss: 0.60628 | train_accuracy: 0.7534  | valid_accuracy: 0.74932 |  0:00:24s\n",
      "epoch 125| loss: 0.60973 | train_accuracy: 0.73827 | valid_accuracy: 0.71735 |  0:00:24s\n",
      "epoch 126| loss: 0.60329 | train_accuracy: 0.74881 | valid_accuracy: 0.74252 |  0:00:24s\n",
      "epoch 127| loss: 0.6033  | train_accuracy: 0.75901 | valid_accuracy: 0.74694 |  0:00:24s\n",
      "epoch 128| loss: 0.60171 | train_accuracy: 0.75544 | valid_accuracy: 0.74388 |  0:00:24s\n",
      "epoch 129| loss: 0.59278 | train_accuracy: 0.72517 | valid_accuracy: 0.71293 |  0:00:25s\n",
      "epoch 130| loss: 0.60059 | train_accuracy: 0.75604 | valid_accuracy: 0.74286 |  0:00:25s\n",
      "epoch 131| loss: 0.59771 | train_accuracy: 0.75553 | valid_accuracy: 0.75374 |  0:00:25s\n",
      "epoch 132| loss: 0.59848 | train_accuracy: 0.71369 | valid_accuracy: 0.70884 |  0:00:25s\n",
      "epoch 133| loss: 0.59513 | train_accuracy: 0.74974 | valid_accuracy: 0.73673 |  0:00:25s\n",
      "epoch 134| loss: 0.60547 | train_accuracy: 0.74677 | valid_accuracy: 0.73946 |  0:00:26s\n",
      "epoch 135| loss: 0.59555 | train_accuracy: 0.74974 | valid_accuracy: 0.73776 |  0:00:26s\n",
      "epoch 136| loss: 0.5917  | train_accuracy: 0.75476 | valid_accuracy: 0.7398  |  0:00:26s\n",
      "epoch 137| loss: 0.58959 | train_accuracy: 0.73342 | valid_accuracy: 0.72789 |  0:00:26s\n",
      "epoch 138| loss: 0.58327 | train_accuracy: 0.7591  | valid_accuracy: 0.75102 |  0:00:26s\n",
      "epoch 139| loss: 0.59121 | train_accuracy: 0.75536 | valid_accuracy: 0.75034 |  0:00:27s\n",
      "epoch 140| loss: 0.59809 | train_accuracy: 0.7506  | valid_accuracy: 0.73469 |  0:00:27s\n",
      "epoch 141| loss: 0.58984 | train_accuracy: 0.75391 | valid_accuracy: 0.73878 |  0:00:27s\n",
      "epoch 142| loss: 0.59611 | train_accuracy: 0.73886 | valid_accuracy: 0.73027 |  0:00:27s\n",
      "epoch 143| loss: 0.58374 | train_accuracy: 0.75587 | valid_accuracy: 0.74524 |  0:00:27s\n",
      "epoch 144| loss: 0.58538 | train_accuracy: 0.75272 | valid_accuracy: 0.73878 |  0:00:28s\n",
      "epoch 145| loss: 0.58843 | train_accuracy: 0.75417 | valid_accuracy: 0.74728 |  0:00:28s\n",
      "epoch 146| loss: 0.58588 | train_accuracy: 0.75952 | valid_accuracy: 0.75578 |  0:00:28s\n",
      "epoch 147| loss: 0.57843 | train_accuracy: 0.75986 | valid_accuracy: 0.7517  |  0:00:28s\n",
      "epoch 148| loss: 0.58424 | train_accuracy: 0.76029 | valid_accuracy: 0.74898 |  0:00:28s\n",
      "epoch 149| loss: 0.58306 | train_accuracy: 0.75867 | valid_accuracy: 0.7551  |  0:00:28s\n",
      "epoch 150| loss: 0.57452 | train_accuracy: 0.71497 | valid_accuracy: 0.69966 |  0:00:29s\n",
      "epoch 151| loss: 0.5899  | train_accuracy: 0.74218 | valid_accuracy: 0.73095 |  0:00:29s\n",
      "epoch 152| loss: 0.58482 | train_accuracy: 0.75961 | valid_accuracy: 0.75    |  0:00:29s\n",
      "epoch 153| loss: 0.59013 | train_accuracy: 0.76105 | valid_accuracy: 0.74388 |  0:00:29s\n",
      "epoch 154| loss: 0.58129 | train_accuracy: 0.75723 | valid_accuracy: 0.7432  |  0:00:29s\n",
      "epoch 155| loss: 0.58373 | train_accuracy: 0.75629 | valid_accuracy: 0.7483  |  0:00:30s\n",
      "epoch 156| loss: 0.57516 | train_accuracy: 0.75808 | valid_accuracy: 0.74252 |  0:00:30s\n",
      "epoch 157| loss: 0.57988 | train_accuracy: 0.7585  | valid_accuracy: 0.75238 |  0:00:30s\n",
      "epoch 158| loss: 0.57993 | train_accuracy: 0.75927 | valid_accuracy: 0.74796 |  0:00:30s\n",
      "epoch 159| loss: 0.57897 | train_accuracy: 0.75689 | valid_accuracy: 0.75238 |  0:00:30s\n",
      "epoch 160| loss: 0.56868 | train_accuracy: 0.75434 | valid_accuracy: 0.74354 |  0:00:31s\n",
      "epoch 161| loss: 0.57012 | train_accuracy: 0.75468 | valid_accuracy: 0.74116 |  0:00:31s\n",
      "epoch 162| loss: 0.57802 | train_accuracy: 0.76726 | valid_accuracy: 0.75952 |  0:00:31s\n",
      "epoch 163| loss: 0.57322 | train_accuracy: 0.76811 | valid_accuracy: 0.75952 |  0:00:31s\n",
      "epoch 164| loss: 0.57736 | train_accuracy: 0.754   | valid_accuracy: 0.7432  |  0:00:31s\n",
      "epoch 165| loss: 0.58793 | train_accuracy: 0.76352 | valid_accuracy: 0.74354 |  0:00:32s\n",
      "epoch 166| loss: 0.58314 | train_accuracy: 0.75425 | valid_accuracy: 0.74116 |  0:00:32s\n",
      "epoch 167| loss: 0.59    | train_accuracy: 0.7602  | valid_accuracy: 0.74864 |  0:00:32s\n",
      "epoch 168| loss: 0.57044 | train_accuracy: 0.75765 | valid_accuracy: 0.74388 |  0:00:32s\n",
      "epoch 169| loss: 0.5739  | train_accuracy: 0.76922 | valid_accuracy: 0.7602  |  0:00:32s\n",
      "epoch 170| loss: 0.57638 | train_accuracy: 0.7466  | valid_accuracy: 0.72687 |  0:00:33s\n",
      "epoch 171| loss: 0.57945 | train_accuracy: 0.7642  | valid_accuracy: 0.75646 |  0:00:33s\n",
      "epoch 172| loss: 0.5733  | train_accuracy: 0.77236 | valid_accuracy: 0.75986 |  0:00:33s\n",
      "epoch 173| loss: 0.56805 | train_accuracy: 0.76173 | valid_accuracy: 0.74388 |  0:00:33s\n",
      "epoch 174| loss: 0.56554 | train_accuracy: 0.76378 | valid_accuracy: 0.75102 |  0:00:33s\n",
      "epoch 175| loss: 0.56451 | train_accuracy: 0.76862 | valid_accuracy: 0.75884 |  0:00:33s\n",
      "epoch 176| loss: 0.56328 | train_accuracy: 0.75825 | valid_accuracy: 0.74864 |  0:00:34s\n",
      "epoch 177| loss: 0.56552 | train_accuracy: 0.76701 | valid_accuracy: 0.75612 |  0:00:34s\n",
      "epoch 178| loss: 0.56697 | train_accuracy: 0.76335 | valid_accuracy: 0.7568  |  0:00:34s\n",
      "epoch 179| loss: 0.57143 | train_accuracy: 0.7574  | valid_accuracy: 0.74898 |  0:00:34s\n",
      "epoch 180| loss: 0.56699 | train_accuracy: 0.75731 | valid_accuracy: 0.75578 |  0:00:34s\n",
      "epoch 181| loss: 0.5632  | train_accuracy: 0.76726 | valid_accuracy: 0.75578 |  0:00:35s\n",
      "epoch 182| loss: 0.56665 | train_accuracy: 0.75952 | valid_accuracy: 0.7449  |  0:00:35s\n",
      "epoch 183| loss: 0.56523 | train_accuracy: 0.74915 | valid_accuracy: 0.73639 |  0:00:35s\n",
      "epoch 184| loss: 0.56952 | train_accuracy: 0.76122 | valid_accuracy: 0.7449  |  0:00:35s\n",
      "epoch 185| loss: 0.57498 | train_accuracy: 0.77423 | valid_accuracy: 0.76531 |  0:00:35s\n",
      "epoch 186| loss: 0.55725 | train_accuracy: 0.76259 | valid_accuracy: 0.74932 |  0:00:36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187| loss: 0.56713 | train_accuracy: 0.77202 | valid_accuracy: 0.75442 |  0:00:36s\n",
      "epoch 188| loss: 0.56068 | train_accuracy: 0.77219 | valid_accuracy: 0.75918 |  0:00:36s\n",
      "epoch 189| loss: 0.55308 | train_accuracy: 0.77551 | valid_accuracy: 0.76361 |  0:00:36s\n",
      "epoch 190| loss: 0.5612  | train_accuracy: 0.77398 | valid_accuracy: 0.75748 |  0:00:36s\n",
      "epoch 191| loss: 0.56518 | train_accuracy: 0.76454 | valid_accuracy: 0.75612 |  0:00:37s\n",
      "epoch 192| loss: 0.55768 | train_accuracy: 0.77398 | valid_accuracy: 0.76293 |  0:00:37s\n",
      "epoch 193| loss: 0.5605  | train_accuracy: 0.76454 | valid_accuracy: 0.75476 |  0:00:37s\n",
      "epoch 194| loss: 0.56105 | train_accuracy: 0.771   | valid_accuracy: 0.75578 |  0:00:37s\n",
      "epoch 195| loss: 0.57049 | train_accuracy: 0.77083 | valid_accuracy: 0.75816 |  0:00:37s\n",
      "epoch 196| loss: 0.5693  | train_accuracy: 0.77364 | valid_accuracy: 0.76599 |  0:00:38s\n",
      "epoch 197| loss: 0.56205 | train_accuracy: 0.77202 | valid_accuracy: 0.75476 |  0:00:38s\n",
      "epoch 198| loss: 0.5614  | train_accuracy: 0.77296 | valid_accuracy: 0.76701 |  0:00:38s\n",
      "epoch 199| loss: 0.55775 | train_accuracy: 0.77151 | valid_accuracy: 0.76463 |  0:00:38s\n",
      "epoch 200| loss: 0.56003 | train_accuracy: 0.77772 | valid_accuracy: 0.76531 |  0:00:38s\n",
      "epoch 201| loss: 0.55364 | train_accuracy: 0.78112 | valid_accuracy: 0.77007 |  0:00:39s\n",
      "epoch 202| loss: 0.55398 | train_accuracy: 0.76692 | valid_accuracy: 0.75612 |  0:00:39s\n",
      "epoch 203| loss: 0.56512 | train_accuracy: 0.77509 | valid_accuracy: 0.76293 |  0:00:39s\n",
      "epoch 204| loss: 0.55423 | train_accuracy: 0.77832 | valid_accuracy: 0.77551 |  0:00:39s\n",
      "epoch 205| loss: 0.56042 | train_accuracy: 0.78197 | valid_accuracy: 0.77313 |  0:00:39s\n",
      "epoch 206| loss: 0.56078 | train_accuracy: 0.76692 | valid_accuracy: 0.75612 |  0:00:39s\n",
      "epoch 207| loss: 0.55684 | train_accuracy: 0.77219 | valid_accuracy: 0.75748 |  0:00:40s\n",
      "epoch 208| loss: 0.56881 | train_accuracy: 0.77483 | valid_accuracy: 0.76156 |  0:00:40s\n",
      "epoch 209| loss: 0.55871 | train_accuracy: 0.77253 | valid_accuracy: 0.75816 |  0:00:40s\n",
      "epoch 210| loss: 0.55635 | train_accuracy: 0.77874 | valid_accuracy: 0.76531 |  0:00:40s\n",
      "epoch 211| loss: 0.54249 | train_accuracy: 0.77526 | valid_accuracy: 0.7619  |  0:00:40s\n",
      "epoch 212| loss: 0.56207 | train_accuracy: 0.78121 | valid_accuracy: 0.77245 |  0:00:41s\n",
      "epoch 213| loss: 0.55268 | train_accuracy: 0.77551 | valid_accuracy: 0.76565 |  0:00:41s\n",
      "epoch 214| loss: 0.55355 | train_accuracy: 0.77985 | valid_accuracy: 0.77517 |  0:00:41s\n",
      "epoch 215| loss: 0.5555  | train_accuracy: 0.78189 | valid_accuracy: 0.77041 |  0:00:41s\n",
      "epoch 216| loss: 0.56093 | train_accuracy: 0.77491 | valid_accuracy: 0.76565 |  0:00:41s\n",
      "epoch 217| loss: 0.55148 | train_accuracy: 0.77951 | valid_accuracy: 0.76701 |  0:00:42s\n",
      "epoch 218| loss: 0.55792 | train_accuracy: 0.77662 | valid_accuracy: 0.76565 |  0:00:42s\n",
      "epoch 219| loss: 0.55163 | train_accuracy: 0.779   | valid_accuracy: 0.76633 |  0:00:42s\n",
      "epoch 220| loss: 0.54789 | train_accuracy: 0.77823 | valid_accuracy: 0.76599 |  0:00:42s\n",
      "epoch 221| loss: 0.55932 | train_accuracy: 0.7807  | valid_accuracy: 0.76905 |  0:00:42s\n",
      "epoch 222| loss: 0.56038 | train_accuracy: 0.77755 | valid_accuracy: 0.76224 |  0:00:43s\n",
      "epoch 223| loss: 0.54487 | train_accuracy: 0.77662 | valid_accuracy: 0.76361 |  0:00:43s\n",
      "epoch 224| loss: 0.5543  | train_accuracy: 0.78206 | valid_accuracy: 0.76973 |  0:00:43s\n",
      "epoch 225| loss: 0.54719 | train_accuracy: 0.78376 | valid_accuracy: 0.76939 |  0:00:43s\n",
      "epoch 226| loss: 0.54865 | train_accuracy: 0.78223 | valid_accuracy: 0.77041 |  0:00:43s\n",
      "epoch 227| loss: 0.5418  | train_accuracy: 0.78342 | valid_accuracy: 0.76973 |  0:00:44s\n",
      "epoch 228| loss: 0.54041 | train_accuracy: 0.78197 | valid_accuracy: 0.77075 |  0:00:44s\n",
      "epoch 229| loss: 0.55226 | train_accuracy: 0.78486 | valid_accuracy: 0.77041 |  0:00:44s\n",
      "\n",
      "Early stopping occurred at epoch 229 with best_epoch = 204 and best_valid_accuracy = 0.77551\n",
      "228\n",
      "204\n",
      "Fold 1: Train Accuracy=0.7211, Valid Accuracy=0.6956, Epoch = 102\n",
      "Fold 2: Train Accuracy=0.7276, Valid Accuracy=0.7190, Epoch = 109\n",
      "Fold 3: Train Accuracy=0.7770, Valid Accuracy=0.7707, Epoch = 291\n",
      "Fold 4: Train Accuracy=0.7798, Valid Accuracy=0.7500, Epoch = 245\n",
      "Fold 5: Train Accuracy=0.7820, Valid Accuracy=0.7707, Epoch = 228\n",
      "Mean Train Accuracy=0.7575, Mean Valid Accuracy=0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_tabnet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 데이터를 나누기 위한 K 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "best_train_accuracies = []\n",
    "best_valid_accuracies = []\n",
    "\n",
    "epoch_idx = []\n",
    "\n",
    "dict_train = {}\n",
    "dict_val = {}\n",
    "\n",
    "keys = 0\n",
    "\n",
    "# K-fold 교차 검증 반복\n",
    "for train_idx, val_idx in kf.split(x_train):\n",
    "    X_train_fold, X_val_fold = x_train[train_idx], x_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # 모델 초기화\n",
    "    clf = TabNetClassifier(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=3e-2),\n",
    "        scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type='sparsemax'\n",
    "    )\n",
    "\n",
    "    # 모델 학습\n",
    "    clf.fit(\n",
    "        X_train=X_train_fold, y_train=y_train_fold,\n",
    "        eval_set=[(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=1000, patience=25,\n",
    "        from_unsupervised=unsupervised_model\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 가장 작은 loss 를 기준으로 train accuracy, valid accuracy 값 저장\n",
    "    best_idx =clf.history['loss'].index(min(clf.history['loss']))\n",
    "    best_train_accuracy = clf.history['train_accuracy'][best_idx]\n",
    "    best_valid_accuracy = clf.history['valid_accuracy'][best_idx]\n",
    "    best_train_accuracies.append(best_train_accuracy)\n",
    "    best_valid_accuracies.append(best_valid_accuracy)\n",
    "    \n",
    "    # 폴드별 train accuracy와 valid accuracy 기록\n",
    "    train_accuracies.append(clf.history['train_accuracy'][best_idx])\n",
    "    valid_accuracies.append(clf.history['valid_accuracy'][best_idx])\n",
    "    \n",
    "    \n",
    "    # fold 별 train, valid accuracy 평균으로 plot 을 위함\n",
    "    dict_train[keys] = clf.history['train_accuracy']\n",
    "    dict_val[keys] = clf.history['valid_accuracy']\n",
    "    keys +=1\n",
    "    \n",
    "    print(clf.history['loss'].index(min(clf.history['loss'])))\n",
    "    print(clf.history['valid_accuracy'].index(max(clf.history['valid_accuracy'])))\n",
    "    \n",
    "    epoch_idx.append(best_idx)\n",
    "    \n",
    "# 폴드별 best train accuracy와 valid accuracy 출력\n",
    "for i, (train_acc, valid_acc) in enumerate(zip(best_train_accuracies, best_valid_accuracies)):\n",
    "    print(f\"Fold {i+1}: Train Accuracy={train_acc:.4f}, Valid Accuracy={valid_acc:.4f}, Epoch = {epoch_idx[i]}\")\n",
    "\n",
    "# Train accuracy와 valid accuracy의 평균 계산\n",
    "mean_train_accuracy = np.mean(best_train_accuracies)\n",
    "mean_valid_accuracy = np.mean(best_valid_accuracies)\n",
    "\n",
    "print(f\"Mean Train Accuracy={mean_train_accuracy:.4f}, Mean Valid Accuracy={mean_valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e05da88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.64372 | train_accuracy: 0.37092 | valid_accuracy: 0.34218 |  0:00:00s\n",
      "epoch 1  | loss: 1.18977 | train_accuracy: 0.45595 | valid_accuracy: 0.43537 |  0:00:00s\n",
      "epoch 2  | loss: 1.08933 | train_accuracy: 0.45612 | valid_accuracy: 0.41769 |  0:00:00s\n",
      "epoch 3  | loss: 1.01931 | train_accuracy: 0.4267  | valid_accuracy: 0.3932  |  0:00:00s\n",
      "epoch 4  | loss: 0.97044 | train_accuracy: 0.37993 | valid_accuracy: 0.36803 |  0:00:00s\n",
      "epoch 5  | loss: 0.95161 | train_accuracy: 0.36616 | valid_accuracy: 0.36803 |  0:00:00s\n",
      "epoch 6  | loss: 0.94008 | train_accuracy: 0.41854 | valid_accuracy: 0.43061 |  0:00:00s\n",
      "epoch 7  | loss: 0.92132 | train_accuracy: 0.42874 | valid_accuracy: 0.44898 |  0:00:00s\n",
      "epoch 8  | loss: 0.89409 | train_accuracy: 0.44439 | valid_accuracy: 0.45442 |  0:00:00s\n",
      "epoch 9  | loss: 0.90106 | train_accuracy: 0.44796 | valid_accuracy: 0.46054 |  0:00:00s\n",
      "epoch 10 | loss: 0.88269 | train_accuracy: 0.38622 | valid_accuracy: 0.4034  |  0:00:01s\n",
      "epoch 11 | loss: 0.88464 | train_accuracy: 0.4301  | valid_accuracy: 0.44082 |  0:00:01s\n",
      "epoch 12 | loss: 0.87231 | train_accuracy: 0.40493 | valid_accuracy: 0.39728 |  0:00:01s\n",
      "epoch 13 | loss: 0.86601 | train_accuracy: 0.42347 | valid_accuracy: 0.41905 |  0:00:01s\n",
      "epoch 14 | loss: 0.86956 | train_accuracy: 0.41105 | valid_accuracy: 0.39524 |  0:00:01s\n",
      "epoch 15 | loss: 0.85597 | train_accuracy: 0.38537 | valid_accuracy: 0.37415 |  0:00:01s\n",
      "epoch 16 | loss: 0.84875 | train_accuracy: 0.37687 | valid_accuracy: 0.37279 |  0:00:01s\n",
      "epoch 17 | loss: 0.84033 | train_accuracy: 0.35255 | valid_accuracy: 0.35102 |  0:00:01s\n",
      "epoch 18 | loss: 0.82648 | train_accuracy: 0.38367 | valid_accuracy: 0.38912 |  0:00:01s\n",
      "epoch 19 | loss: 0.82858 | train_accuracy: 0.36361 | valid_accuracy: 0.37415 |  0:00:01s\n",
      "epoch 20 | loss: 0.82455 | train_accuracy: 0.37483 | valid_accuracy: 0.38435 |  0:00:01s\n",
      "epoch 21 | loss: 0.81918 | train_accuracy: 0.35731 | valid_accuracy: 0.36054 |  0:00:02s\n",
      "epoch 22 | loss: 0.81411 | train_accuracy: 0.37942 | valid_accuracy: 0.37687 |  0:00:02s\n",
      "epoch 23 | loss: 0.82784 | train_accuracy: 0.39762 | valid_accuracy: 0.38912 |  0:00:02s\n",
      "epoch 24 | loss: 0.82135 | train_accuracy: 0.44609 | valid_accuracy: 0.43946 |  0:00:02s\n",
      "epoch 25 | loss: 0.82865 | train_accuracy: 0.47194 | valid_accuracy: 0.45578 |  0:00:02s\n",
      "epoch 26 | loss: 0.8103  | train_accuracy: 0.46888 | valid_accuracy: 0.4585  |  0:00:02s\n",
      "epoch 27 | loss: 0.81768 | train_accuracy: 0.49643 | valid_accuracy: 0.47619 |  0:00:02s\n",
      "epoch 28 | loss: 0.81558 | train_accuracy: 0.49898 | valid_accuracy: 0.48231 |  0:00:02s\n",
      "epoch 29 | loss: 0.7975  | train_accuracy: 0.5119  | valid_accuracy: 0.48844 |  0:00:02s\n",
      "epoch 30 | loss: 0.80686 | train_accuracy: 0.54779 | valid_accuracy: 0.53061 |  0:00:02s\n",
      "epoch 31 | loss: 0.80144 | train_accuracy: 0.53673 | valid_accuracy: 0.51224 |  0:00:03s\n",
      "epoch 32 | loss: 0.79259 | train_accuracy: 0.54473 | valid_accuracy: 0.52721 |  0:00:03s\n",
      "epoch 33 | loss: 0.79901 | train_accuracy: 0.54286 | valid_accuracy: 0.51565 |  0:00:03s\n",
      "epoch 34 | loss: 0.78384 | train_accuracy: 0.55493 | valid_accuracy: 0.52585 |  0:00:03s\n",
      "epoch 35 | loss: 0.79284 | train_accuracy: 0.58707 | valid_accuracy: 0.56054 |  0:00:03s\n",
      "epoch 36 | loss: 0.77993 | train_accuracy: 0.5551  | valid_accuracy: 0.52041 |  0:00:03s\n",
      "epoch 37 | loss: 0.79082 | train_accuracy: 0.54439 | valid_accuracy: 0.51361 |  0:00:03s\n",
      "epoch 38 | loss: 0.77836 | train_accuracy: 0.5881  | valid_accuracy: 0.55442 |  0:00:03s\n",
      "epoch 39 | loss: 0.78786 | train_accuracy: 0.58112 | valid_accuracy: 0.5551  |  0:00:03s\n",
      "epoch 40 | loss: 0.77824 | train_accuracy: 0.5869  | valid_accuracy: 0.5517  |  0:00:03s\n",
      "epoch 41 | loss: 0.78125 | train_accuracy: 0.61939 | valid_accuracy: 0.58027 |  0:00:03s\n",
      "epoch 42 | loss: 0.77311 | train_accuracy: 0.56531 | valid_accuracy: 0.52585 |  0:00:04s\n",
      "epoch 43 | loss: 0.78015 | train_accuracy: 0.62075 | valid_accuracy: 0.58299 |  0:00:04s\n",
      "epoch 44 | loss: 0.77315 | train_accuracy: 0.60952 | valid_accuracy: 0.58503 |  0:00:04s\n",
      "epoch 45 | loss: 0.76574 | train_accuracy: 0.58078 | valid_accuracy: 0.5449  |  0:00:04s\n",
      "epoch 46 | loss: 0.78344 | train_accuracy: 0.61207 | valid_accuracy: 0.5898  |  0:00:04s\n",
      "epoch 47 | loss: 0.77895 | train_accuracy: 0.61684 | valid_accuracy: 0.58844 |  0:00:04s\n",
      "epoch 48 | loss: 0.78219 | train_accuracy: 0.59677 | valid_accuracy: 0.56871 |  0:00:04s\n",
      "epoch 49 | loss: 0.81644 | train_accuracy: 0.61837 | valid_accuracy: 0.58027 |  0:00:04s\n",
      "epoch 50 | loss: 0.80177 | train_accuracy: 0.59065 | valid_accuracy: 0.57687 |  0:00:04s\n",
      "epoch 51 | loss: 0.7865  | train_accuracy: 0.63861 | valid_accuracy: 0.61973 |  0:00:04s\n",
      "epoch 52 | loss: 0.77246 | train_accuracy: 0.63418 | valid_accuracy: 0.59456 |  0:00:04s\n",
      "epoch 53 | loss: 0.7831  | train_accuracy: 0.64983 | valid_accuracy: 0.61429 |  0:00:05s\n",
      "epoch 54 | loss: 0.76826 | train_accuracy: 0.6517  | valid_accuracy: 0.62517 |  0:00:05s\n",
      "epoch 55 | loss: 0.77337 | train_accuracy: 0.65901 | valid_accuracy: 0.62585 |  0:00:05s\n",
      "epoch 56 | loss: 0.7603  | train_accuracy: 0.6381  | valid_accuracy: 0.60612 |  0:00:05s\n",
      "epoch 57 | loss: 0.7536  | train_accuracy: 0.65102 | valid_accuracy: 0.63129 |  0:00:05s\n",
      "epoch 58 | loss: 0.75607 | train_accuracy: 0.63503 | valid_accuracy: 0.60884 |  0:00:05s\n",
      "epoch 59 | loss: 0.75324 | train_accuracy: 0.66276 | valid_accuracy: 0.6381  |  0:00:05s\n",
      "epoch 60 | loss: 0.75786 | train_accuracy: 0.65119 | valid_accuracy: 0.63333 |  0:00:05s\n",
      "epoch 61 | loss: 0.75973 | train_accuracy: 0.64405 | valid_accuracy: 0.62449 |  0:00:05s\n",
      "epoch 62 | loss: 0.75618 | train_accuracy: 0.66088 | valid_accuracy: 0.6381  |  0:00:05s\n",
      "epoch 63 | loss: 0.75649 | train_accuracy: 0.65374 | valid_accuracy: 0.62993 |  0:00:06s\n",
      "epoch 64 | loss: 0.75821 | train_accuracy: 0.65272 | valid_accuracy: 0.62517 |  0:00:06s\n",
      "epoch 65 | loss: 0.75454 | train_accuracy: 0.67058 | valid_accuracy: 0.64354 |  0:00:06s\n",
      "epoch 66 | loss: 0.754   | train_accuracy: 0.63929 | valid_accuracy: 0.61497 |  0:00:06s\n",
      "epoch 67 | loss: 0.74073 | train_accuracy: 0.67262 | valid_accuracy: 0.65102 |  0:00:06s\n",
      "epoch 68 | loss: 0.73629 | train_accuracy: 0.6733  | valid_accuracy: 0.64966 |  0:00:06s\n",
      "epoch 69 | loss: 0.74811 | train_accuracy: 0.65901 | valid_accuracy: 0.63469 |  0:00:06s\n",
      "epoch 70 | loss: 0.73451 | train_accuracy: 0.6716  | valid_accuracy: 0.63469 |  0:00:06s\n",
      "epoch 71 | loss: 0.74574 | train_accuracy: 0.65731 | valid_accuracy: 0.63469 |  0:00:06s\n",
      "epoch 72 | loss: 0.74203 | train_accuracy: 0.65748 | valid_accuracy: 0.62857 |  0:00:06s\n",
      "epoch 73 | loss: 0.72975 | train_accuracy: 0.67619 | valid_accuracy: 0.65714 |  0:00:06s\n",
      "epoch 74 | loss: 0.7383  | train_accuracy: 0.65748 | valid_accuracy: 0.62449 |  0:00:07s\n",
      "epoch 75 | loss: 0.72626 | train_accuracy: 0.68044 | valid_accuracy: 0.65238 |  0:00:07s\n",
      "epoch 76 | loss: 0.72307 | train_accuracy: 0.67449 | valid_accuracy: 0.64558 |  0:00:07s\n",
      "epoch 77 | loss: 0.73599 | train_accuracy: 0.67211 | valid_accuracy: 0.65306 |  0:00:07s\n",
      "epoch 78 | loss: 0.72195 | train_accuracy: 0.67772 | valid_accuracy: 0.64626 |  0:00:07s\n",
      "epoch 79 | loss: 0.71947 | train_accuracy: 0.67789 | valid_accuracy: 0.6483  |  0:00:07s\n",
      "epoch 80 | loss: 0.73498 | train_accuracy: 0.66565 | valid_accuracy: 0.63946 |  0:00:07s\n",
      "epoch 81 | loss: 0.72261 | train_accuracy: 0.67976 | valid_accuracy: 0.64558 |  0:00:07s\n",
      "epoch 82 | loss: 0.71728 | train_accuracy: 0.67126 | valid_accuracy: 0.63946 |  0:00:07s\n",
      "epoch 83 | loss: 0.73156 | train_accuracy: 0.68571 | valid_accuracy: 0.65986 |  0:00:07s\n",
      "epoch 84 | loss: 0.71226 | train_accuracy: 0.67194 | valid_accuracy: 0.63946 |  0:00:07s\n",
      "epoch 85 | loss: 0.72447 | train_accuracy: 0.67347 | valid_accuracy: 0.64626 |  0:00:08s\n",
      "epoch 86 | loss: 0.71896 | train_accuracy: 0.69065 | valid_accuracy: 0.65238 |  0:00:08s\n",
      "epoch 87 | loss: 0.71415 | train_accuracy: 0.68129 | valid_accuracy: 0.64218 |  0:00:08s\n",
      "epoch 88 | loss: 0.72015 | train_accuracy: 0.6932  | valid_accuracy: 0.65918 |  0:00:08s\n",
      "epoch 89 | loss: 0.71895 | train_accuracy: 0.68044 | valid_accuracy: 0.65306 |  0:00:08s\n",
      "epoch 90 | loss: 0.72437 | train_accuracy: 0.68639 | valid_accuracy: 0.65442 |  0:00:08s\n",
      "epoch 91 | loss: 0.72512 | train_accuracy: 0.67109 | valid_accuracy: 0.62789 |  0:00:08s\n",
      "epoch 92 | loss: 0.7278  | train_accuracy: 0.69014 | valid_accuracy: 0.65374 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.72416 | train_accuracy: 0.68639 | valid_accuracy: 0.65306 |  0:00:08s\n",
      "epoch 94 | loss: 0.7006  | train_accuracy: 0.68895 | valid_accuracy: 0.65578 |  0:00:08s\n",
      "epoch 95 | loss: 0.71583 | train_accuracy: 0.69218 | valid_accuracy: 0.65306 |  0:00:08s\n",
      "epoch 96 | loss: 0.71987 | train_accuracy: 0.69915 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 97 | loss: 0.71025 | train_accuracy: 0.68452 | valid_accuracy: 0.65782 |  0:00:09s\n",
      "epoch 98 | loss: 0.71131 | train_accuracy: 0.68078 | valid_accuracy: 0.65442 |  0:00:09s\n",
      "epoch 99 | loss: 0.71572 | train_accuracy: 0.67857 | valid_accuracy: 0.65306 |  0:00:09s\n",
      "epoch 100| loss: 0.70531 | train_accuracy: 0.70204 | valid_accuracy: 0.67143 |  0:00:09s\n",
      "epoch 101| loss: 0.72718 | train_accuracy: 0.69507 | valid_accuracy: 0.66735 |  0:00:09s\n",
      "epoch 102| loss: 0.70858 | train_accuracy: 0.69218 | valid_accuracy: 0.66531 |  0:00:09s\n",
      "epoch 103| loss: 0.69601 | train_accuracy: 0.70221 | valid_accuracy: 0.66395 |  0:00:09s\n",
      "epoch 104| loss: 0.70941 | train_accuracy: 0.70272 | valid_accuracy: 0.66803 |  0:00:09s\n",
      "epoch 105| loss: 0.70162 | train_accuracy: 0.69405 | valid_accuracy: 0.6619  |  0:00:09s\n",
      "epoch 106| loss: 0.71517 | train_accuracy: 0.69439 | valid_accuracy: 0.66939 |  0:00:10s\n",
      "epoch 107| loss: 0.70484 | train_accuracy: 0.6835  | valid_accuracy: 0.64626 |  0:00:10s\n",
      "epoch 108| loss: 0.69794 | train_accuracy: 0.70051 | valid_accuracy: 0.67143 |  0:00:10s\n",
      "epoch 109| loss: 0.71307 | train_accuracy: 0.68997 | valid_accuracy: 0.65374 |  0:00:10s\n",
      "epoch 110| loss: 0.69285 | train_accuracy: 0.70085 | valid_accuracy: 0.67551 |  0:00:10s\n",
      "epoch 111| loss: 0.70269 | train_accuracy: 0.70493 | valid_accuracy: 0.66531 |  0:00:10s\n",
      "epoch 112| loss: 0.69313 | train_accuracy: 0.69575 | valid_accuracy: 0.65646 |  0:00:10s\n",
      "epoch 113| loss: 0.70116 | train_accuracy: 0.70289 | valid_accuracy: 0.67347 |  0:00:10s\n",
      "epoch 114| loss: 0.70178 | train_accuracy: 0.70969 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 115| loss: 0.69373 | train_accuracy: 0.70068 | valid_accuracy: 0.67755 |  0:00:10s\n",
      "epoch 116| loss: 0.71207 | train_accuracy: 0.69932 | valid_accuracy: 0.66871 |  0:00:10s\n",
      "epoch 117| loss: 0.70899 | train_accuracy: 0.6983  | valid_accuracy: 0.6517  |  0:00:11s\n",
      "epoch 118| loss: 0.70058 | train_accuracy: 0.6949  | valid_accuracy: 0.66395 |  0:00:11s\n",
      "epoch 119| loss: 0.71108 | train_accuracy: 0.68912 | valid_accuracy: 0.67755 |  0:00:11s\n",
      "epoch 120| loss: 0.70438 | train_accuracy: 0.70884 | valid_accuracy: 0.67687 |  0:00:11s\n",
      "epoch 121| loss: 0.70117 | train_accuracy: 0.70663 | valid_accuracy: 0.67143 |  0:00:11s\n",
      "epoch 122| loss: 0.70918 | train_accuracy: 0.70442 | valid_accuracy: 0.65646 |  0:00:11s\n",
      "epoch 123| loss: 0.69076 | train_accuracy: 0.70187 | valid_accuracy: 0.66667 |  0:00:11s\n",
      "epoch 124| loss: 0.6918  | train_accuracy: 0.71003 | valid_accuracy: 0.67619 |  0:00:11s\n",
      "epoch 125| loss: 0.68113 | train_accuracy: 0.70833 | valid_accuracy: 0.67211 |  0:00:11s\n",
      "epoch 126| loss: 0.70357 | train_accuracy: 0.71241 | valid_accuracy: 0.67075 |  0:00:11s\n",
      "epoch 127| loss: 0.68359 | train_accuracy: 0.70017 | valid_accuracy: 0.66463 |  0:00:12s\n",
      "epoch 128| loss: 0.68427 | train_accuracy: 0.70068 | valid_accuracy: 0.67143 |  0:00:12s\n",
      "epoch 129| loss: 0.6933  | train_accuracy: 0.7051  | valid_accuracy: 0.6619  |  0:00:12s\n",
      "epoch 130| loss: 0.68551 | train_accuracy: 0.69762 | valid_accuracy: 0.66667 |  0:00:12s\n",
      "epoch 131| loss: 0.69803 | train_accuracy: 0.71378 | valid_accuracy: 0.67959 |  0:00:12s\n",
      "epoch 132| loss: 0.67592 | train_accuracy: 0.71684 | valid_accuracy: 0.67823 |  0:00:12s\n",
      "epoch 133| loss: 0.67691 | train_accuracy: 0.71361 | valid_accuracy: 0.67279 |  0:00:12s\n",
      "epoch 134| loss: 0.68804 | train_accuracy: 0.72177 | valid_accuracy: 0.68027 |  0:00:12s\n",
      "epoch 135| loss: 0.6868  | train_accuracy: 0.70816 | valid_accuracy: 0.66735 |  0:00:12s\n",
      "epoch 136| loss: 0.69374 | train_accuracy: 0.70595 | valid_accuracy: 0.66327 |  0:00:12s\n",
      "epoch 137| loss: 0.67273 | train_accuracy: 0.7233  | valid_accuracy: 0.69048 |  0:00:12s\n",
      "epoch 138| loss: 0.68863 | train_accuracy: 0.7102  | valid_accuracy: 0.66803 |  0:00:13s\n",
      "epoch 139| loss: 0.69888 | train_accuracy: 0.71224 | valid_accuracy: 0.67279 |  0:00:13s\n",
      "epoch 140| loss: 0.68455 | train_accuracy: 0.71241 | valid_accuracy: 0.67619 |  0:00:13s\n",
      "epoch 141| loss: 0.67885 | train_accuracy: 0.71616 | valid_accuracy: 0.66735 |  0:00:13s\n",
      "epoch 142| loss: 0.67838 | train_accuracy: 0.71752 | valid_accuracy: 0.67415 |  0:00:13s\n",
      "epoch 143| loss: 0.68072 | train_accuracy: 0.7165  | valid_accuracy: 0.67415 |  0:00:13s\n",
      "epoch 144| loss: 0.68278 | train_accuracy: 0.71769 | valid_accuracy: 0.68367 |  0:00:13s\n",
      "epoch 145| loss: 0.67005 | train_accuracy: 0.71139 | valid_accuracy: 0.67211 |  0:00:13s\n",
      "epoch 146| loss: 0.67451 | train_accuracy: 0.71684 | valid_accuracy: 0.67755 |  0:00:13s\n",
      "epoch 147| loss: 0.68654 | train_accuracy: 0.72585 | valid_accuracy: 0.69048 |  0:00:13s\n",
      "epoch 148| loss: 0.67624 | train_accuracy: 0.70646 | valid_accuracy: 0.67143 |  0:00:13s\n",
      "epoch 149| loss: 0.67638 | train_accuracy: 0.69711 | valid_accuracy: 0.67143 |  0:00:14s\n",
      "epoch 150| loss: 0.66884 | train_accuracy: 0.72262 | valid_accuracy: 0.69184 |  0:00:14s\n",
      "epoch 151| loss: 0.67506 | train_accuracy: 0.72024 | valid_accuracy: 0.68163 |  0:00:14s\n",
      "epoch 152| loss: 0.66034 | train_accuracy: 0.71769 | valid_accuracy: 0.68367 |  0:00:14s\n",
      "epoch 153| loss: 0.67399 | train_accuracy: 0.72687 | valid_accuracy: 0.68435 |  0:00:14s\n",
      "epoch 154| loss: 0.65905 | train_accuracy: 0.71565 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 155| loss: 0.6644  | train_accuracy: 0.71446 | valid_accuracy: 0.68163 |  0:00:14s\n",
      "epoch 156| loss: 0.67986 | train_accuracy: 0.71054 | valid_accuracy: 0.67891 |  0:00:14s\n",
      "epoch 157| loss: 0.68807 | train_accuracy: 0.72517 | valid_accuracy: 0.68844 |  0:00:14s\n",
      "epoch 158| loss: 0.6702  | train_accuracy: 0.7131  | valid_accuracy: 0.67959 |  0:00:14s\n",
      "epoch 159| loss: 0.67033 | train_accuracy: 0.72466 | valid_accuracy: 0.68095 |  0:00:14s\n",
      "epoch 160| loss: 0.67045 | train_accuracy: 0.72653 | valid_accuracy: 0.68844 |  0:00:15s\n",
      "epoch 161| loss: 0.67638 | train_accuracy: 0.71565 | valid_accuracy: 0.67075 |  0:00:15s\n",
      "epoch 162| loss: 0.6614  | train_accuracy: 0.72041 | valid_accuracy: 0.68435 |  0:00:15s\n",
      "epoch 163| loss: 0.66964 | train_accuracy: 0.72262 | valid_accuracy: 0.69116 |  0:00:15s\n",
      "epoch 164| loss: 0.67762 | train_accuracy: 0.71463 | valid_accuracy: 0.67415 |  0:00:15s\n",
      "epoch 165| loss: 0.675   | train_accuracy: 0.71463 | valid_accuracy: 0.67347 |  0:00:15s\n",
      "epoch 166| loss: 0.67111 | train_accuracy: 0.7148  | valid_accuracy: 0.68571 |  0:00:15s\n",
      "epoch 167| loss: 0.67835 | train_accuracy: 0.71667 | valid_accuracy: 0.67959 |  0:00:15s\n",
      "epoch 168| loss: 0.66902 | train_accuracy: 0.72704 | valid_accuracy: 0.69524 |  0:00:15s\n",
      "epoch 169| loss: 0.68677 | train_accuracy: 0.7148  | valid_accuracy: 0.68639 |  0:00:15s\n",
      "epoch 170| loss: 0.6732  | train_accuracy: 0.71718 | valid_accuracy: 0.68435 |  0:00:16s\n",
      "epoch 171| loss: 0.66731 | train_accuracy: 0.72602 | valid_accuracy: 0.69252 |  0:00:16s\n",
      "epoch 172| loss: 0.67003 | train_accuracy: 0.72908 | valid_accuracy: 0.69184 |  0:00:16s\n",
      "epoch 173| loss: 0.6625  | train_accuracy: 0.72041 | valid_accuracy: 0.69184 |  0:00:16s\n",
      "epoch 174| loss: 0.66227 | train_accuracy: 0.72449 | valid_accuracy: 0.6932  |  0:00:16s\n",
      "epoch 175| loss: 0.6696  | train_accuracy: 0.72772 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 176| loss: 0.65642 | train_accuracy: 0.73027 | valid_accuracy: 0.69116 |  0:00:16s\n",
      "epoch 177| loss: 0.6608  | train_accuracy: 0.71701 | valid_accuracy: 0.68095 |  0:00:16s\n",
      "epoch 178| loss: 0.67315 | train_accuracy: 0.72228 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 179| loss: 0.66119 | train_accuracy: 0.72551 | valid_accuracy: 0.68912 |  0:00:16s\n",
      "epoch 180| loss: 0.66214 | train_accuracy: 0.71667 | valid_accuracy: 0.67823 |  0:00:16s\n",
      "epoch 181| loss: 0.6555  | train_accuracy: 0.71718 | valid_accuracy: 0.69116 |  0:00:17s\n",
      "epoch 182| loss: 0.66231 | train_accuracy: 0.71565 | valid_accuracy: 0.68503 |  0:00:17s\n",
      "epoch 183| loss: 0.66129 | train_accuracy: 0.73299 | valid_accuracy: 0.69524 |  0:00:17s\n",
      "epoch 184| loss: 0.66466 | train_accuracy: 0.72755 | valid_accuracy: 0.67687 |  0:00:17s\n",
      "epoch 185| loss: 0.65116 | train_accuracy: 0.72398 | valid_accuracy: 0.68639 |  0:00:17s\n",
      "epoch 186| loss: 0.66736 | train_accuracy: 0.72993 | valid_accuracy: 0.68912 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187| loss: 0.671   | train_accuracy: 0.71871 | valid_accuracy: 0.68299 |  0:00:17s\n",
      "epoch 188| loss: 0.64925 | train_accuracy: 0.73095 | valid_accuracy: 0.69524 |  0:00:17s\n",
      "epoch 189| loss: 0.66191 | train_accuracy: 0.72908 | valid_accuracy: 0.68912 |  0:00:17s\n",
      "epoch 190| loss: 0.65854 | train_accuracy: 0.72126 | valid_accuracy: 0.68571 |  0:00:17s\n",
      "epoch 191| loss: 0.64858 | train_accuracy: 0.73044 | valid_accuracy: 0.69252 |  0:00:18s\n",
      "epoch 192| loss: 0.65185 | train_accuracy: 0.73384 | valid_accuracy: 0.69388 |  0:00:18s\n",
      "epoch 193| loss: 0.64637 | train_accuracy: 0.7216  | valid_accuracy: 0.69592 |  0:00:18s\n",
      "epoch 194| loss: 0.64307 | train_accuracy: 0.72024 | valid_accuracy: 0.69252 |  0:00:18s\n",
      "epoch 195| loss: 0.65447 | train_accuracy: 0.72279 | valid_accuracy: 0.69524 |  0:00:18s\n",
      "epoch 196| loss: 0.66755 | train_accuracy: 0.73605 | valid_accuracy: 0.69524 |  0:00:18s\n",
      "epoch 197| loss: 0.66858 | train_accuracy: 0.72891 | valid_accuracy: 0.68844 |  0:00:18s\n",
      "epoch 198| loss: 0.65681 | train_accuracy: 0.72704 | valid_accuracy: 0.68844 |  0:00:18s\n",
      "epoch 199| loss: 0.65341 | train_accuracy: 0.73793 | valid_accuracy: 0.6898  |  0:00:18s\n",
      "epoch 200| loss: 0.66868 | train_accuracy: 0.73537 | valid_accuracy: 0.69388 |  0:00:18s\n",
      "epoch 201| loss: 0.6459  | train_accuracy: 0.72891 | valid_accuracy: 0.68435 |  0:00:18s\n",
      "epoch 202| loss: 0.65104 | train_accuracy: 0.74269 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 203| loss: 0.66104 | train_accuracy: 0.73248 | valid_accuracy: 0.68776 |  0:00:19s\n",
      "epoch 204| loss: 0.66369 | train_accuracy: 0.72721 | valid_accuracy: 0.68231 |  0:00:19s\n",
      "epoch 205| loss: 0.65587 | train_accuracy: 0.73367 | valid_accuracy: 0.70204 |  0:00:19s\n",
      "epoch 206| loss: 0.64575 | train_accuracy: 0.73146 | valid_accuracy: 0.7034  |  0:00:19s\n",
      "epoch 207| loss: 0.66348 | train_accuracy: 0.72398 | valid_accuracy: 0.69048 |  0:00:19s\n",
      "epoch 208| loss: 0.65133 | train_accuracy: 0.72925 | valid_accuracy: 0.68844 |  0:00:19s\n",
      "epoch 209| loss: 0.65693 | train_accuracy: 0.7369  | valid_accuracy: 0.69456 |  0:00:19s\n",
      "epoch 210| loss: 0.66177 | train_accuracy: 0.73384 | valid_accuracy: 0.68844 |  0:00:19s\n",
      "epoch 211| loss: 0.65978 | train_accuracy: 0.72738 | valid_accuracy: 0.69592 |  0:00:19s\n",
      "epoch 212| loss: 0.65548 | train_accuracy: 0.72653 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 213| loss: 0.65154 | train_accuracy: 0.73622 | valid_accuracy: 0.68707 |  0:00:20s\n",
      "epoch 214| loss: 0.64638 | train_accuracy: 0.74014 | valid_accuracy: 0.68707 |  0:00:20s\n",
      "epoch 215| loss: 0.65347 | train_accuracy: 0.73367 | valid_accuracy: 0.68299 |  0:00:20s\n",
      "epoch 216| loss: 0.64583 | train_accuracy: 0.72738 | valid_accuracy: 0.6966  |  0:00:20s\n",
      "epoch 217| loss: 0.64865 | train_accuracy: 0.72874 | valid_accuracy: 0.69864 |  0:00:20s\n",
      "epoch 218| loss: 0.66554 | train_accuracy: 0.7301  | valid_accuracy: 0.69728 |  0:00:20s\n",
      "epoch 219| loss: 0.6456  | train_accuracy: 0.72823 | valid_accuracy: 0.68503 |  0:00:20s\n",
      "epoch 220| loss: 0.65281 | train_accuracy: 0.73027 | valid_accuracy: 0.68571 |  0:00:20s\n",
      "epoch 221| loss: 0.64755 | train_accuracy: 0.73776 | valid_accuracy: 0.7     |  0:00:20s\n",
      "epoch 222| loss: 0.64552 | train_accuracy: 0.73622 | valid_accuracy: 0.69184 |  0:00:20s\n",
      "epoch 223| loss: 0.64088 | train_accuracy: 0.73639 | valid_accuracy: 0.69252 |  0:00:21s\n",
      "epoch 224| loss: 0.6446  | train_accuracy: 0.73401 | valid_accuracy: 0.69864 |  0:00:21s\n",
      "epoch 225| loss: 0.65099 | train_accuracy: 0.73759 | valid_accuracy: 0.6966  |  0:00:21s\n",
      "epoch 226| loss: 0.65385 | train_accuracy: 0.73827 | valid_accuracy: 0.7     |  0:00:21s\n",
      "epoch 227| loss: 0.65433 | train_accuracy: 0.7381  | valid_accuracy: 0.70136 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 227 with best_epoch = 202 and best_valid_accuracy = 0.70816\n",
      "223\n",
      "202\n",
      "epoch 0  | loss: 1.61997 | train_accuracy: 0.32364 | valid_accuracy: 0.30476 |  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1  | loss: 1.1768  | train_accuracy: 0.28963 | valid_accuracy: 0.27891 |  0:00:00s\n",
      "epoch 2  | loss: 1.11681 | train_accuracy: 0.2881  | valid_accuracy: 0.25918 |  0:00:00s\n",
      "epoch 3  | loss: 1.0667  | train_accuracy: 0.30493 | valid_accuracy: 0.27891 |  0:00:00s\n",
      "epoch 4  | loss: 1.0088  | train_accuracy: 0.32568 | valid_accuracy: 0.31361 |  0:00:00s\n",
      "epoch 5  | loss: 0.97275 | train_accuracy: 0.3665  | valid_accuracy: 0.35646 |  0:00:00s\n",
      "epoch 6  | loss: 0.9713  | train_accuracy: 0.33741 | valid_accuracy: 0.33673 |  0:00:00s\n",
      "epoch 7  | loss: 0.96577 | train_accuracy: 0.36582 | valid_accuracy: 0.36054 |  0:00:00s\n",
      "epoch 8  | loss: 0.93838 | train_accuracy: 0.38095 | valid_accuracy: 0.37755 |  0:00:00s\n",
      "epoch 9  | loss: 0.92453 | train_accuracy: 0.40493 | valid_accuracy: 0.40136 |  0:00:00s\n",
      "epoch 10 | loss: 0.91087 | train_accuracy: 0.45034 | valid_accuracy: 0.47959 |  0:00:01s\n",
      "epoch 11 | loss: 0.90065 | train_accuracy: 0.39711 | valid_accuracy: 0.38095 |  0:00:01s\n",
      "epoch 12 | loss: 0.90538 | train_accuracy: 0.51922 | valid_accuracy: 0.51905 |  0:00:01s\n",
      "epoch 13 | loss: 0.90462 | train_accuracy: 0.50663 | valid_accuracy: 0.51497 |  0:00:01s\n",
      "epoch 14 | loss: 0.89347 | train_accuracy: 0.48486 | valid_accuracy: 0.48844 |  0:00:01s\n",
      "epoch 15 | loss: 0.87773 | train_accuracy: 0.49575 | valid_accuracy: 0.50408 |  0:00:01s\n",
      "epoch 16 | loss: 0.86687 | train_accuracy: 0.49881 | valid_accuracy: 0.51565 |  0:00:01s\n",
      "epoch 17 | loss: 0.87028 | train_accuracy: 0.50119 | valid_accuracy: 0.51837 |  0:00:01s\n",
      "epoch 18 | loss: 0.86084 | train_accuracy: 0.48061 | valid_accuracy: 0.48844 |  0:00:01s\n",
      "epoch 19 | loss: 0.86607 | train_accuracy: 0.48759 | valid_accuracy: 0.49524 |  0:00:01s\n",
      "epoch 20 | loss: 0.85528 | train_accuracy: 0.48469 | valid_accuracy: 0.4966  |  0:00:01s\n",
      "epoch 21 | loss: 0.85096 | train_accuracy: 0.49728 | valid_accuracy: 0.49728 |  0:00:02s\n",
      "epoch 22 | loss: 0.85297 | train_accuracy: 0.47891 | valid_accuracy: 0.48639 |  0:00:02s\n",
      "epoch 23 | loss: 0.84661 | train_accuracy: 0.52313 | valid_accuracy: 0.52993 |  0:00:02s\n",
      "epoch 24 | loss: 0.83596 | train_accuracy: 0.50221 | valid_accuracy: 0.4966  |  0:00:02s\n",
      "epoch 25 | loss: 0.82006 | train_accuracy: 0.4881  | valid_accuracy: 0.49184 |  0:00:02s\n",
      "epoch 26 | loss: 0.82855 | train_accuracy: 0.53027 | valid_accuracy: 0.53878 |  0:00:02s\n",
      "epoch 27 | loss: 0.81773 | train_accuracy: 0.50731 | valid_accuracy: 0.51905 |  0:00:02s\n",
      "epoch 28 | loss: 0.81625 | train_accuracy: 0.52517 | valid_accuracy: 0.52993 |  0:00:02s\n",
      "epoch 29 | loss: 0.82041 | train_accuracy: 0.52789 | valid_accuracy: 0.52381 |  0:00:02s\n",
      "epoch 30 | loss: 0.80196 | train_accuracy: 0.5301  | valid_accuracy: 0.52109 |  0:00:02s\n",
      "epoch 31 | loss: 0.81117 | train_accuracy: 0.53401 | valid_accuracy: 0.51973 |  0:00:03s\n",
      "epoch 32 | loss: 0.81205 | train_accuracy: 0.52636 | valid_accuracy: 0.51633 |  0:00:03s\n",
      "epoch 33 | loss: 0.80525 | train_accuracy: 0.55085 | valid_accuracy: 0.54014 |  0:00:03s\n",
      "epoch 34 | loss: 0.80867 | train_accuracy: 0.54966 | valid_accuracy: 0.5449  |  0:00:03s\n",
      "epoch 35 | loss: 0.80792 | train_accuracy: 0.5602  | valid_accuracy: 0.55102 |  0:00:03s\n",
      "epoch 36 | loss: 0.79511 | train_accuracy: 0.55595 | valid_accuracy: 0.54898 |  0:00:03s\n",
      "epoch 37 | loss: 0.79132 | train_accuracy: 0.56293 | valid_accuracy: 0.55646 |  0:00:03s\n",
      "epoch 38 | loss: 0.78759 | train_accuracy: 0.56582 | valid_accuracy: 0.55578 |  0:00:03s\n",
      "epoch 39 | loss: 0.78367 | train_accuracy: 0.56531 | valid_accuracy: 0.5517  |  0:00:03s\n",
      "epoch 40 | loss: 0.78386 | train_accuracy: 0.57279 | valid_accuracy: 0.56327 |  0:00:03s\n",
      "epoch 41 | loss: 0.78638 | train_accuracy: 0.58129 | valid_accuracy: 0.57075 |  0:00:03s\n",
      "epoch 42 | loss: 0.78072 | train_accuracy: 0.58588 | valid_accuracy: 0.56871 |  0:00:04s\n",
      "epoch 43 | loss: 0.77586 | train_accuracy: 0.59269 | valid_accuracy: 0.57891 |  0:00:04s\n",
      "epoch 44 | loss: 0.77727 | train_accuracy: 0.61616 | valid_accuracy: 0.5898  |  0:00:04s\n",
      "epoch 45 | loss: 0.774   | train_accuracy: 0.63418 | valid_accuracy: 0.62449 |  0:00:04s\n",
      "epoch 46 | loss: 0.76631 | train_accuracy: 0.59405 | valid_accuracy: 0.57619 |  0:00:04s\n",
      "epoch 47 | loss: 0.77051 | train_accuracy: 0.60748 | valid_accuracy: 0.59116 |  0:00:04s\n",
      "epoch 48 | loss: 0.77439 | train_accuracy: 0.62942 | valid_accuracy: 0.6102  |  0:00:04s\n",
      "epoch 49 | loss: 0.77036 | train_accuracy: 0.62687 | valid_accuracy: 0.61156 |  0:00:04s\n",
      "epoch 50 | loss: 0.77616 | train_accuracy: 0.63367 | valid_accuracy: 0.62041 |  0:00:04s\n",
      "epoch 51 | loss: 0.76527 | train_accuracy: 0.64269 | valid_accuracy: 0.62653 |  0:00:04s\n",
      "epoch 52 | loss: 0.74537 | train_accuracy: 0.64201 | valid_accuracy: 0.62449 |  0:00:04s\n",
      "epoch 53 | loss: 0.74937 | train_accuracy: 0.64065 | valid_accuracy: 0.62313 |  0:00:05s\n",
      "epoch 54 | loss: 0.76607 | train_accuracy: 0.64813 | valid_accuracy: 0.62721 |  0:00:05s\n",
      "epoch 55 | loss: 0.77338 | train_accuracy: 0.65221 | valid_accuracy: 0.63605 |  0:00:05s\n",
      "epoch 56 | loss: 0.75866 | train_accuracy: 0.65629 | valid_accuracy: 0.63878 |  0:00:05s\n",
      "epoch 57 | loss: 0.7552  | train_accuracy: 0.65527 | valid_accuracy: 0.64354 |  0:00:05s\n",
      "epoch 58 | loss: 0.75529 | train_accuracy: 0.65238 | valid_accuracy: 0.63061 |  0:00:05s\n",
      "epoch 59 | loss: 0.75821 | train_accuracy: 0.64507 | valid_accuracy: 0.62585 |  0:00:05s\n",
      "epoch 60 | loss: 0.75244 | train_accuracy: 0.64592 | valid_accuracy: 0.62381 |  0:00:05s\n",
      "epoch 61 | loss: 0.76719 | train_accuracy: 0.65017 | valid_accuracy: 0.63401 |  0:00:05s\n",
      "epoch 62 | loss: 0.75094 | train_accuracy: 0.66259 | valid_accuracy: 0.64898 |  0:00:05s\n",
      "epoch 63 | loss: 0.74839 | train_accuracy: 0.66939 | valid_accuracy: 0.65442 |  0:00:06s\n",
      "epoch 64 | loss: 0.75754 | train_accuracy: 0.67347 | valid_accuracy: 0.66259 |  0:00:06s\n",
      "epoch 65 | loss: 0.72977 | train_accuracy: 0.6568  | valid_accuracy: 0.65986 |  0:00:06s\n",
      "epoch 66 | loss: 0.73151 | train_accuracy: 0.66361 | valid_accuracy: 0.64422 |  0:00:06s\n",
      "epoch 67 | loss: 0.74461 | train_accuracy: 0.67704 | valid_accuracy: 0.66054 |  0:00:06s\n",
      "epoch 68 | loss: 0.73513 | train_accuracy: 0.6801  | valid_accuracy: 0.65714 |  0:00:06s\n",
      "epoch 69 | loss: 0.76231 | train_accuracy: 0.66956 | valid_accuracy: 0.6551  |  0:00:06s\n",
      "epoch 70 | loss: 0.73851 | train_accuracy: 0.67398 | valid_accuracy: 0.6585  |  0:00:06s\n",
      "epoch 71 | loss: 0.73493 | train_accuracy: 0.68452 | valid_accuracy: 0.65034 |  0:00:06s\n",
      "epoch 72 | loss: 0.72251 | train_accuracy: 0.67755 | valid_accuracy: 0.66531 |  0:00:06s\n",
      "epoch 73 | loss: 0.72674 | train_accuracy: 0.68401 | valid_accuracy: 0.6517  |  0:00:06s\n",
      "epoch 74 | loss: 0.73089 | train_accuracy: 0.67908 | valid_accuracy: 0.65034 |  0:00:07s\n",
      "epoch 75 | loss: 0.72158 | train_accuracy: 0.67959 | valid_accuracy: 0.66327 |  0:00:07s\n",
      "epoch 76 | loss: 0.71555 | train_accuracy: 0.6801  | valid_accuracy: 0.67279 |  0:00:07s\n",
      "epoch 77 | loss: 0.73727 | train_accuracy: 0.69201 | valid_accuracy: 0.68163 |  0:00:07s\n",
      "epoch 78 | loss: 0.71796 | train_accuracy: 0.69065 | valid_accuracy: 0.67959 |  0:00:07s\n",
      "epoch 79 | loss: 0.71651 | train_accuracy: 0.6835  | valid_accuracy: 0.67415 |  0:00:07s\n",
      "epoch 80 | loss: 0.71547 | train_accuracy: 0.69116 | valid_accuracy: 0.66939 |  0:00:07s\n",
      "epoch 81 | loss: 0.71263 | train_accuracy: 0.69626 | valid_accuracy: 0.68231 |  0:00:07s\n",
      "epoch 82 | loss: 0.72585 | train_accuracy: 0.69167 | valid_accuracy: 0.68435 |  0:00:07s\n",
      "epoch 83 | loss: 0.71586 | train_accuracy: 0.69473 | valid_accuracy: 0.68367 |  0:00:07s\n",
      "epoch 84 | loss: 0.71064 | train_accuracy: 0.69082 | valid_accuracy: 0.67279 |  0:00:07s\n",
      "epoch 85 | loss: 0.70682 | train_accuracy: 0.69609 | valid_accuracy: 0.67959 |  0:00:08s\n",
      "epoch 86 | loss: 0.70801 | train_accuracy: 0.69609 | valid_accuracy: 0.68027 |  0:00:08s\n",
      "epoch 87 | loss: 0.71392 | train_accuracy: 0.70646 | valid_accuracy: 0.68844 |  0:00:08s\n",
      "epoch 88 | loss: 0.72209 | train_accuracy: 0.69099 | valid_accuracy: 0.67347 |  0:00:08s\n",
      "epoch 89 | loss: 0.71685 | train_accuracy: 0.69524 | valid_accuracy: 0.69252 |  0:00:08s\n",
      "epoch 90 | loss: 0.69767 | train_accuracy: 0.69235 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 91 | loss: 0.70289 | train_accuracy: 0.69082 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 92 | loss: 0.70763 | train_accuracy: 0.69898 | valid_accuracy: 0.68776 |  0:00:08s\n",
      "epoch 93 | loss: 0.71634 | train_accuracy: 0.69711 | valid_accuracy: 0.67619 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 | loss: 0.70533 | train_accuracy: 0.69405 | valid_accuracy: 0.66939 |  0:00:08s\n",
      "epoch 95 | loss: 0.71516 | train_accuracy: 0.69847 | valid_accuracy: 0.68571 |  0:00:09s\n",
      "epoch 96 | loss: 0.69854 | train_accuracy: 0.71037 | valid_accuracy: 0.69796 |  0:00:09s\n",
      "epoch 97 | loss: 0.69285 | train_accuracy: 0.69762 | valid_accuracy: 0.68367 |  0:00:09s\n",
      "epoch 98 | loss: 0.70149 | train_accuracy: 0.69983 | valid_accuracy: 0.68571 |  0:00:09s\n",
      "epoch 99 | loss: 0.69521 | train_accuracy: 0.70425 | valid_accuracy: 0.70136 |  0:00:09s\n",
      "epoch 100| loss: 0.70253 | train_accuracy: 0.69881 | valid_accuracy: 0.69388 |  0:00:09s\n",
      "epoch 101| loss: 0.70697 | train_accuracy: 0.7     | valid_accuracy: 0.67619 |  0:00:09s\n",
      "epoch 102| loss: 0.69415 | train_accuracy: 0.70748 | valid_accuracy: 0.69796 |  0:00:09s\n",
      "epoch 103| loss: 0.68577 | train_accuracy: 0.69643 | valid_accuracy: 0.68231 |  0:00:09s\n",
      "epoch 104| loss: 0.68628 | train_accuracy: 0.69626 | valid_accuracy: 0.6898  |  0:00:09s\n",
      "epoch 105| loss: 0.68593 | train_accuracy: 0.70697 | valid_accuracy: 0.67551 |  0:00:09s\n",
      "epoch 106| loss: 0.68091 | train_accuracy: 0.68214 | valid_accuracy: 0.67143 |  0:00:10s\n",
      "epoch 107| loss: 0.69162 | train_accuracy: 0.71395 | valid_accuracy: 0.69456 |  0:00:10s\n",
      "epoch 108| loss: 0.69052 | train_accuracy: 0.70187 | valid_accuracy: 0.68707 |  0:00:10s\n",
      "epoch 109| loss: 0.68263 | train_accuracy: 0.71514 | valid_accuracy: 0.70136 |  0:00:10s\n",
      "epoch 110| loss: 0.67831 | train_accuracy: 0.70544 | valid_accuracy: 0.69116 |  0:00:10s\n",
      "epoch 111| loss: 0.67018 | train_accuracy: 0.7102  | valid_accuracy: 0.7     |  0:00:10s\n",
      "epoch 112| loss: 0.69275 | train_accuracy: 0.70051 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 113| loss: 0.68695 | train_accuracy: 0.71361 | valid_accuracy: 0.68844 |  0:00:10s\n",
      "epoch 114| loss: 0.68058 | train_accuracy: 0.71361 | valid_accuracy: 0.68571 |  0:00:10s\n",
      "epoch 115| loss: 0.6827  | train_accuracy: 0.72194 | valid_accuracy: 0.69932 |  0:00:10s\n",
      "epoch 116| loss: 0.69044 | train_accuracy: 0.70901 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 117| loss: 0.66761 | train_accuracy: 0.72092 | valid_accuracy: 0.69796 |  0:00:11s\n",
      "epoch 118| loss: 0.68279 | train_accuracy: 0.70765 | valid_accuracy: 0.68707 |  0:00:11s\n",
      "epoch 119| loss: 0.67172 | train_accuracy: 0.72007 | valid_accuracy: 0.7     |  0:00:11s\n",
      "epoch 120| loss: 0.67888 | train_accuracy: 0.71327 | valid_accuracy: 0.68707 |  0:00:11s\n",
      "epoch 121| loss: 0.68501 | train_accuracy: 0.71241 | valid_accuracy: 0.7     |  0:00:11s\n",
      "epoch 122| loss: 0.66874 | train_accuracy: 0.71973 | valid_accuracy: 0.70952 |  0:00:11s\n",
      "epoch 123| loss: 0.66978 | train_accuracy: 0.72313 | valid_accuracy: 0.72177 |  0:00:11s\n",
      "epoch 124| loss: 0.69152 | train_accuracy: 0.72398 | valid_accuracy: 0.69932 |  0:00:11s\n",
      "epoch 125| loss: 0.67822 | train_accuracy: 0.71139 | valid_accuracy: 0.69524 |  0:00:11s\n",
      "epoch 126| loss: 0.69131 | train_accuracy: 0.72279 | valid_accuracy: 0.70952 |  0:00:11s\n",
      "epoch 127| loss: 0.67169 | train_accuracy: 0.72177 | valid_accuracy: 0.70204 |  0:00:12s\n",
      "epoch 128| loss: 0.66481 | train_accuracy: 0.71956 | valid_accuracy: 0.70884 |  0:00:12s\n",
      "epoch 129| loss: 0.67794 | train_accuracy: 0.71616 | valid_accuracy: 0.68776 |  0:00:12s\n",
      "epoch 130| loss: 0.6686  | train_accuracy: 0.71888 | valid_accuracy: 0.71088 |  0:00:12s\n",
      "epoch 131| loss: 0.66267 | train_accuracy: 0.72313 | valid_accuracy: 0.71633 |  0:00:12s\n",
      "epoch 132| loss: 0.66607 | train_accuracy: 0.7267  | valid_accuracy: 0.70748 |  0:00:12s\n",
      "epoch 133| loss: 0.67751 | train_accuracy: 0.72432 | valid_accuracy: 0.70612 |  0:00:12s\n",
      "epoch 134| loss: 0.66785 | train_accuracy: 0.72449 | valid_accuracy: 0.71497 |  0:00:12s\n",
      "epoch 135| loss: 0.67433 | train_accuracy: 0.73537 | valid_accuracy: 0.72177 |  0:00:12s\n",
      "epoch 136| loss: 0.66632 | train_accuracy: 0.725   | valid_accuracy: 0.71088 |  0:00:12s\n",
      "epoch 137| loss: 0.66058 | train_accuracy: 0.7335  | valid_accuracy: 0.71293 |  0:00:12s\n",
      "epoch 138| loss: 0.65949 | train_accuracy: 0.72891 | valid_accuracy: 0.71701 |  0:00:13s\n",
      "epoch 139| loss: 0.65724 | train_accuracy: 0.7267  | valid_accuracy: 0.71701 |  0:00:13s\n",
      "epoch 140| loss: 0.66348 | train_accuracy: 0.73265 | valid_accuracy: 0.70816 |  0:00:13s\n",
      "epoch 141| loss: 0.66089 | train_accuracy: 0.72483 | valid_accuracy: 0.71497 |  0:00:13s\n",
      "epoch 142| loss: 0.67509 | train_accuracy: 0.7301  | valid_accuracy: 0.71497 |  0:00:13s\n",
      "epoch 143| loss: 0.65925 | train_accuracy: 0.72789 | valid_accuracy: 0.70612 |  0:00:13s\n",
      "epoch 144| loss: 0.66713 | train_accuracy: 0.71973 | valid_accuracy: 0.69932 |  0:00:13s\n",
      "epoch 145| loss: 0.67167 | train_accuracy: 0.72347 | valid_accuracy: 0.70204 |  0:00:13s\n",
      "epoch 146| loss: 0.65993 | train_accuracy: 0.73163 | valid_accuracy: 0.70476 |  0:00:13s\n",
      "epoch 147| loss: 0.64753 | train_accuracy: 0.72772 | valid_accuracy: 0.71224 |  0:00:13s\n",
      "epoch 148| loss: 0.65702 | train_accuracy: 0.73827 | valid_accuracy: 0.71905 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 148 with best_epoch = 123 and best_valid_accuracy = 0.72177\n",
      "147\n",
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.63328 | train_accuracy: 0.31088 | valid_accuracy: 0.32925 |  0:00:00s\n",
      "epoch 1  | loss: 1.1634  | train_accuracy: 0.32942 | valid_accuracy: 0.31837 |  0:00:00s\n",
      "epoch 2  | loss: 1.05347 | train_accuracy: 0.34728 | valid_accuracy: 0.32721 |  0:00:00s\n",
      "epoch 3  | loss: 1.00929 | train_accuracy: 0.38673 | valid_accuracy: 0.36871 |  0:00:00s\n",
      "epoch 4  | loss: 0.9748  | train_accuracy: 0.3915  | valid_accuracy: 0.38027 |  0:00:00s\n",
      "epoch 5  | loss: 0.95653 | train_accuracy: 0.4818  | valid_accuracy: 0.50068 |  0:00:00s\n",
      "epoch 6  | loss: 0.93961 | train_accuracy: 0.49116 | valid_accuracy: 0.50748 |  0:00:00s\n",
      "epoch 7  | loss: 0.92453 | train_accuracy: 0.49898 | valid_accuracy: 0.51156 |  0:00:00s\n",
      "epoch 8  | loss: 0.92116 | train_accuracy: 0.39218 | valid_accuracy: 0.43129 |  0:00:00s\n",
      "epoch 9  | loss: 0.92749 | train_accuracy: 0.5131  | valid_accuracy: 0.5449  |  0:00:01s\n",
      "epoch 10 | loss: 0.91544 | train_accuracy: 0.44813 | valid_accuracy: 0.48027 |  0:00:01s\n",
      "epoch 11 | loss: 0.91705 | train_accuracy: 0.47109 | valid_accuracy: 0.50068 |  0:00:01s\n",
      "epoch 12 | loss: 0.91136 | train_accuracy: 0.49099 | valid_accuracy: 0.52585 |  0:00:01s\n",
      "epoch 13 | loss: 0.89762 | train_accuracy: 0.45374 | valid_accuracy: 0.49252 |  0:00:01s\n",
      "epoch 14 | loss: 0.89869 | train_accuracy: 0.50629 | valid_accuracy: 0.54354 |  0:00:01s\n",
      "epoch 15 | loss: 0.89664 | train_accuracy: 0.49507 | valid_accuracy: 0.52449 |  0:00:01s\n",
      "epoch 16 | loss: 0.90025 | train_accuracy: 0.49388 | valid_accuracy: 0.48435 |  0:00:01s\n",
      "epoch 17 | loss: 0.88852 | train_accuracy: 0.47143 | valid_accuracy: 0.47143 |  0:00:01s\n",
      "epoch 18 | loss: 0.88682 | train_accuracy: 0.48741 | valid_accuracy: 0.48027 |  0:00:01s\n",
      "epoch 19 | loss: 0.88377 | train_accuracy: 0.52007 | valid_accuracy: 0.50068 |  0:00:01s\n",
      "epoch 20 | loss: 0.88092 | train_accuracy: 0.50901 | valid_accuracy: 0.4966  |  0:00:02s\n",
      "epoch 21 | loss: 0.88062 | train_accuracy: 0.4915  | valid_accuracy: 0.48707 |  0:00:02s\n",
      "epoch 22 | loss: 0.86537 | train_accuracy: 0.53946 | valid_accuracy: 0.53946 |  0:00:02s\n",
      "epoch 23 | loss: 0.85744 | train_accuracy: 0.50969 | valid_accuracy: 0.51156 |  0:00:02s\n",
      "epoch 24 | loss: 0.86387 | train_accuracy: 0.5398  | valid_accuracy: 0.5415  |  0:00:02s\n",
      "epoch 25 | loss: 0.86635 | train_accuracy: 0.54133 | valid_accuracy: 0.53878 |  0:00:02s\n",
      "epoch 26 | loss: 0.87406 | train_accuracy: 0.54269 | valid_accuracy: 0.53605 |  0:00:02s\n",
      "epoch 27 | loss: 0.87176 | train_accuracy: 0.54405 | valid_accuracy: 0.53129 |  0:00:02s\n",
      "epoch 28 | loss: 0.85596 | train_accuracy: 0.5318  | valid_accuracy: 0.53265 |  0:00:02s\n",
      "epoch 29 | loss: 0.87039 | train_accuracy: 0.56207 | valid_accuracy: 0.5585  |  0:00:02s\n",
      "epoch 30 | loss: 0.85254 | train_accuracy: 0.57279 | valid_accuracy: 0.57075 |  0:00:02s\n",
      "epoch 31 | loss: 0.83961 | train_accuracy: 0.56378 | valid_accuracy: 0.55918 |  0:00:03s\n",
      "epoch 32 | loss: 0.842   | train_accuracy: 0.56054 | valid_accuracy: 0.55646 |  0:00:03s\n",
      "epoch 33 | loss: 0.84259 | train_accuracy: 0.5699  | valid_accuracy: 0.56395 |  0:00:03s\n",
      "epoch 34 | loss: 0.83001 | train_accuracy: 0.57109 | valid_accuracy: 0.57687 |  0:00:03s\n",
      "epoch 35 | loss: 0.81813 | train_accuracy: 0.56973 | valid_accuracy: 0.56531 |  0:00:03s\n",
      "epoch 36 | loss: 0.82671 | train_accuracy: 0.57398 | valid_accuracy: 0.56871 |  0:00:03s\n",
      "epoch 37 | loss: 0.8149  | train_accuracy: 0.5852  | valid_accuracy: 0.57551 |  0:00:03s\n",
      "epoch 38 | loss: 0.82141 | train_accuracy: 0.59218 | valid_accuracy: 0.58571 |  0:00:03s\n",
      "epoch 39 | loss: 0.81801 | train_accuracy: 0.56565 | valid_accuracy: 0.56803 |  0:00:03s\n",
      "epoch 40 | loss: 0.80625 | train_accuracy: 0.59677 | valid_accuracy: 0.5966  |  0:00:03s\n",
      "epoch 41 | loss: 0.80337 | train_accuracy: 0.59065 | valid_accuracy: 0.58571 |  0:00:03s\n",
      "epoch 42 | loss: 0.80835 | train_accuracy: 0.60306 | valid_accuracy: 0.60544 |  0:00:04s\n",
      "epoch 43 | loss: 0.8089  | train_accuracy: 0.59099 | valid_accuracy: 0.58163 |  0:00:04s\n",
      "epoch 44 | loss: 0.81902 | train_accuracy: 0.59779 | valid_accuracy: 0.59932 |  0:00:04s\n",
      "epoch 45 | loss: 0.81254 | train_accuracy: 0.60714 | valid_accuracy: 0.60612 |  0:00:04s\n",
      "epoch 46 | loss: 0.79755 | train_accuracy: 0.61446 | valid_accuracy: 0.61497 |  0:00:04s\n",
      "epoch 47 | loss: 0.80427 | train_accuracy: 0.61718 | valid_accuracy: 0.61973 |  0:00:04s\n",
      "epoch 48 | loss: 0.82478 | train_accuracy: 0.6051  | valid_accuracy: 0.60272 |  0:00:04s\n",
      "epoch 49 | loss: 0.80279 | train_accuracy: 0.61922 | valid_accuracy: 0.62449 |  0:00:04s\n",
      "epoch 50 | loss: 0.79486 | train_accuracy: 0.63078 | valid_accuracy: 0.62993 |  0:00:04s\n",
      "epoch 51 | loss: 0.78982 | train_accuracy: 0.6199  | valid_accuracy: 0.61837 |  0:00:04s\n",
      "epoch 52 | loss: 0.79644 | train_accuracy: 0.62687 | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 53 | loss: 0.78428 | train_accuracy: 0.61888 | valid_accuracy: 0.62517 |  0:00:05s\n",
      "epoch 54 | loss: 0.79856 | train_accuracy: 0.6301  | valid_accuracy: 0.63401 |  0:00:05s\n",
      "epoch 55 | loss: 0.8027  | train_accuracy: 0.63895 | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 56 | loss: 0.78913 | train_accuracy: 0.6381  | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 57 | loss: 0.79844 | train_accuracy: 0.63997 | valid_accuracy: 0.63265 |  0:00:05s\n",
      "epoch 58 | loss: 0.78116 | train_accuracy: 0.64728 | valid_accuracy: 0.64558 |  0:00:05s\n",
      "epoch 59 | loss: 0.78662 | train_accuracy: 0.64286 | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 60 | loss: 0.78123 | train_accuracy: 0.64167 | valid_accuracy: 0.6415  |  0:00:05s\n",
      "epoch 61 | loss: 0.79268 | train_accuracy: 0.6335  | valid_accuracy: 0.63197 |  0:00:05s\n",
      "epoch 62 | loss: 0.77351 | train_accuracy: 0.64388 | valid_accuracy: 0.64558 |  0:00:06s\n",
      "epoch 63 | loss: 0.77454 | train_accuracy: 0.65391 | valid_accuracy: 0.64762 |  0:00:06s\n",
      "epoch 64 | loss: 0.78303 | train_accuracy: 0.65357 | valid_accuracy: 0.65646 |  0:00:06s\n",
      "epoch 65 | loss: 0.77998 | train_accuracy: 0.6585  | valid_accuracy: 0.64966 |  0:00:06s\n",
      "epoch 66 | loss: 0.77818 | train_accuracy: 0.65544 | valid_accuracy: 0.64966 |  0:00:06s\n",
      "epoch 67 | loss: 0.77642 | train_accuracy: 0.65935 | valid_accuracy: 0.64626 |  0:00:06s\n",
      "epoch 68 | loss: 0.76676 | train_accuracy: 0.65272 | valid_accuracy: 0.65442 |  0:00:06s\n",
      "epoch 69 | loss: 0.76712 | train_accuracy: 0.65816 | valid_accuracy: 0.66327 |  0:00:06s\n",
      "epoch 70 | loss: 0.76477 | train_accuracy: 0.66854 | valid_accuracy: 0.65578 |  0:00:06s\n",
      "epoch 71 | loss: 0.75988 | train_accuracy: 0.65425 | valid_accuracy: 0.65306 |  0:00:06s\n",
      "epoch 72 | loss: 0.75791 | train_accuracy: 0.66803 | valid_accuracy: 0.65986 |  0:00:06s\n",
      "epoch 73 | loss: 0.75885 | train_accuracy: 0.66701 | valid_accuracy: 0.66735 |  0:00:07s\n",
      "epoch 74 | loss: 0.75007 | train_accuracy: 0.66344 | valid_accuracy: 0.65986 |  0:00:07s\n",
      "epoch 75 | loss: 0.75339 | train_accuracy: 0.67364 | valid_accuracy: 0.65918 |  0:00:07s\n",
      "epoch 76 | loss: 0.75858 | train_accuracy: 0.6682  | valid_accuracy: 0.65442 |  0:00:07s\n",
      "epoch 77 | loss: 0.76584 | train_accuracy: 0.66514 | valid_accuracy: 0.65714 |  0:00:07s\n",
      "epoch 78 | loss: 0.76055 | train_accuracy: 0.66344 | valid_accuracy: 0.6483  |  0:00:07s\n",
      "epoch 79 | loss: 0.7632  | train_accuracy: 0.66752 | valid_accuracy: 0.66054 |  0:00:07s\n",
      "epoch 80 | loss: 0.75372 | train_accuracy: 0.66769 | valid_accuracy: 0.65578 |  0:00:07s\n",
      "epoch 81 | loss: 0.75598 | train_accuracy: 0.67211 | valid_accuracy: 0.66463 |  0:00:07s\n",
      "epoch 82 | loss: 0.7544  | train_accuracy: 0.66531 | valid_accuracy: 0.66395 |  0:00:07s\n",
      "epoch 83 | loss: 0.74702 | train_accuracy: 0.67789 | valid_accuracy: 0.67347 |  0:00:07s\n",
      "epoch 84 | loss: 0.74824 | train_accuracy: 0.67534 | valid_accuracy: 0.66327 |  0:00:08s\n",
      "epoch 85 | loss: 0.75237 | train_accuracy: 0.67228 | valid_accuracy: 0.66054 |  0:00:08s\n",
      "epoch 86 | loss: 0.75338 | train_accuracy: 0.67942 | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 87 | loss: 0.74859 | train_accuracy: 0.67364 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 88 | loss: 0.74723 | train_accuracy: 0.66854 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 89 | loss: 0.75733 | train_accuracy: 0.68639 | valid_accuracy: 0.67143 |  0:00:08s\n",
      "epoch 90 | loss: 0.74772 | train_accuracy: 0.67806 | valid_accuracy: 0.66463 |  0:00:08s\n",
      "epoch 91 | loss: 0.72928 | train_accuracy: 0.67364 | valid_accuracy: 0.64898 |  0:00:08s\n",
      "epoch 92 | loss: 0.75516 | train_accuracy: 0.68112 | valid_accuracy: 0.66871 |  0:00:08s\n",
      "epoch 93 | loss: 0.73222 | train_accuracy: 0.68112 | valid_accuracy: 0.66259 |  0:00:08s\n",
      "epoch 94 | loss: 0.72943 | train_accuracy: 0.68656 | valid_accuracy: 0.66803 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 | loss: 0.72378 | train_accuracy: 0.68452 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 96 | loss: 0.73597 | train_accuracy: 0.69133 | valid_accuracy: 0.67755 |  0:00:09s\n",
      "epoch 97 | loss: 0.72877 | train_accuracy: 0.68316 | valid_accuracy: 0.67551 |  0:00:09s\n",
      "epoch 98 | loss: 0.72994 | train_accuracy: 0.68095 | valid_accuracy: 0.66667 |  0:00:09s\n",
      "epoch 99 | loss: 0.73126 | train_accuracy: 0.68078 | valid_accuracy: 0.67007 |  0:00:09s\n",
      "epoch 100| loss: 0.72379 | train_accuracy: 0.67806 | valid_accuracy: 0.66871 |  0:00:09s\n",
      "epoch 101| loss: 0.71546 | train_accuracy: 0.69728 | valid_accuracy: 0.67279 |  0:00:09s\n",
      "epoch 102| loss: 0.72084 | train_accuracy: 0.69337 | valid_accuracy: 0.66871 |  0:00:09s\n",
      "epoch 103| loss: 0.71907 | train_accuracy: 0.68656 | valid_accuracy: 0.65714 |  0:00:09s\n",
      "epoch 104| loss: 0.72024 | train_accuracy: 0.68861 | valid_accuracy: 0.68027 |  0:00:09s\n",
      "epoch 105| loss: 0.72881 | train_accuracy: 0.69473 | valid_accuracy: 0.67075 |  0:00:10s\n",
      "epoch 106| loss: 0.71584 | train_accuracy: 0.68895 | valid_accuracy: 0.67347 |  0:00:10s\n",
      "epoch 107| loss: 0.71317 | train_accuracy: 0.69762 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 108| loss: 0.72329 | train_accuracy: 0.6852  | valid_accuracy: 0.67551 |  0:00:10s\n",
      "epoch 109| loss: 0.72199 | train_accuracy: 0.69473 | valid_accuracy: 0.67755 |  0:00:10s\n",
      "epoch 110| loss: 0.71694 | train_accuracy: 0.69745 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 111| loss: 0.71848 | train_accuracy: 0.68673 | valid_accuracy: 0.66122 |  0:00:10s\n",
      "epoch 112| loss: 0.70954 | train_accuracy: 0.69354 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 113| loss: 0.71738 | train_accuracy: 0.70102 | valid_accuracy: 0.67143 |  0:00:10s\n",
      "epoch 114| loss: 0.72049 | train_accuracy: 0.69439 | valid_accuracy: 0.67891 |  0:00:10s\n",
      "epoch 115| loss: 0.71702 | train_accuracy: 0.70306 | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 116| loss: 0.71098 | train_accuracy: 0.70051 | valid_accuracy: 0.67823 |  0:00:11s\n",
      "epoch 117| loss: 0.71916 | train_accuracy: 0.7051  | valid_accuracy: 0.67007 |  0:00:11s\n",
      "epoch 118| loss: 0.71042 | train_accuracy: 0.6898  | valid_accuracy: 0.66735 |  0:00:11s\n",
      "epoch 119| loss: 0.71061 | train_accuracy: 0.69847 | valid_accuracy: 0.68435 |  0:00:11s\n",
      "epoch 120| loss: 0.70595 | train_accuracy: 0.70459 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 121| loss: 0.71946 | train_accuracy: 0.68265 | valid_accuracy: 0.65646 |  0:00:11s\n",
      "epoch 122| loss: 0.71376 | train_accuracy: 0.70153 | valid_accuracy: 0.68095 |  0:00:11s\n",
      "epoch 123| loss: 0.71845 | train_accuracy: 0.69932 | valid_accuracy: 0.68639 |  0:00:11s\n",
      "epoch 124| loss: 0.70104 | train_accuracy: 0.70034 | valid_accuracy: 0.68571 |  0:00:11s\n",
      "epoch 125| loss: 0.71373 | train_accuracy: 0.70884 | valid_accuracy: 0.68435 |  0:00:11s\n",
      "epoch 126| loss: 0.70048 | train_accuracy: 0.70391 | valid_accuracy: 0.68571 |  0:00:12s\n",
      "epoch 127| loss: 0.70076 | train_accuracy: 0.70629 | valid_accuracy: 0.69048 |  0:00:12s\n",
      "epoch 128| loss: 0.70426 | train_accuracy: 0.70765 | valid_accuracy: 0.68571 |  0:00:12s\n",
      "epoch 129| loss: 0.70146 | train_accuracy: 0.71088 | valid_accuracy: 0.68299 |  0:00:12s\n",
      "epoch 130| loss: 0.70393 | train_accuracy: 0.70986 | valid_accuracy: 0.67687 |  0:00:12s\n",
      "epoch 131| loss: 0.69953 | train_accuracy: 0.69949 | valid_accuracy: 0.68163 |  0:00:12s\n",
      "epoch 132| loss: 0.68692 | train_accuracy: 0.7131  | valid_accuracy: 0.68776 |  0:00:12s\n",
      "epoch 133| loss: 0.69365 | train_accuracy: 0.7102  | valid_accuracy: 0.69116 |  0:00:12s\n",
      "epoch 134| loss: 0.70224 | train_accuracy: 0.69728 | valid_accuracy: 0.68231 |  0:00:12s\n",
      "epoch 135| loss: 0.69282 | train_accuracy: 0.70629 | valid_accuracy: 0.68299 |  0:00:12s\n",
      "epoch 136| loss: 0.69309 | train_accuracy: 0.72245 | valid_accuracy: 0.68844 |  0:00:12s\n",
      "epoch 137| loss: 0.69441 | train_accuracy: 0.71514 | valid_accuracy: 0.69116 |  0:00:13s\n",
      "epoch 138| loss: 0.69898 | train_accuracy: 0.70595 | valid_accuracy: 0.68571 |  0:00:13s\n",
      "epoch 139| loss: 0.69368 | train_accuracy: 0.70034 | valid_accuracy: 0.68503 |  0:00:13s\n",
      "epoch 140| loss: 0.70704 | train_accuracy: 0.7068  | valid_accuracy: 0.68435 |  0:00:13s\n",
      "epoch 141| loss: 0.70388 | train_accuracy: 0.71173 | valid_accuracy: 0.69932 |  0:00:13s\n",
      "epoch 142| loss: 0.69691 | train_accuracy: 0.70561 | valid_accuracy: 0.69388 |  0:00:13s\n",
      "epoch 143| loss: 0.68038 | train_accuracy: 0.70714 | valid_accuracy: 0.68912 |  0:00:13s\n",
      "epoch 144| loss: 0.68561 | train_accuracy: 0.7148  | valid_accuracy: 0.7     |  0:00:13s\n",
      "epoch 145| loss: 0.70392 | train_accuracy: 0.71037 | valid_accuracy: 0.68776 |  0:00:13s\n",
      "epoch 146| loss: 0.68684 | train_accuracy: 0.71412 | valid_accuracy: 0.6932  |  0:00:13s\n",
      "epoch 147| loss: 0.69816 | train_accuracy: 0.70816 | valid_accuracy: 0.69116 |  0:00:13s\n",
      "epoch 148| loss: 0.68734 | train_accuracy: 0.69864 | valid_accuracy: 0.68027 |  0:00:14s\n",
      "epoch 149| loss: 0.6867  | train_accuracy: 0.71224 | valid_accuracy: 0.69796 |  0:00:14s\n",
      "epoch 150| loss: 0.67938 | train_accuracy: 0.70459 | valid_accuracy: 0.69184 |  0:00:14s\n",
      "epoch 151| loss: 0.68976 | train_accuracy: 0.70204 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 152| loss: 0.69437 | train_accuracy: 0.70918 | valid_accuracy: 0.68571 |  0:00:14s\n",
      "epoch 153| loss: 0.69088 | train_accuracy: 0.70935 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 154| loss: 0.7025  | train_accuracy: 0.70918 | valid_accuracy: 0.69592 |  0:00:14s\n",
      "epoch 155| loss: 0.69481 | train_accuracy: 0.71241 | valid_accuracy: 0.68435 |  0:00:14s\n",
      "epoch 156| loss: 0.68492 | train_accuracy: 0.70799 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 157| loss: 0.67985 | train_accuracy: 0.71344 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 158| loss: 0.67658 | train_accuracy: 0.71463 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 159| loss: 0.69397 | train_accuracy: 0.70833 | valid_accuracy: 0.68435 |  0:00:15s\n",
      "epoch 160| loss: 0.67755 | train_accuracy: 0.71582 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 161| loss: 0.67831 | train_accuracy: 0.7165  | valid_accuracy: 0.68776 |  0:00:15s\n",
      "epoch 162| loss: 0.68817 | train_accuracy: 0.72092 | valid_accuracy: 0.69592 |  0:00:15s\n",
      "epoch 163| loss: 0.67572 | train_accuracy: 0.72296 | valid_accuracy: 0.69864 |  0:00:15s\n",
      "epoch 164| loss: 0.69368 | train_accuracy: 0.72177 | valid_accuracy: 0.69864 |  0:00:15s\n",
      "epoch 165| loss: 0.69022 | train_accuracy: 0.72041 | valid_accuracy: 0.70204 |  0:00:15s\n",
      "epoch 166| loss: 0.66529 | train_accuracy: 0.71037 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 167| loss: 0.68208 | train_accuracy: 0.71378 | valid_accuracy: 0.68299 |  0:00:15s\n",
      "epoch 168| loss: 0.68055 | train_accuracy: 0.72687 | valid_accuracy: 0.69456 |  0:00:15s\n",
      "epoch 169| loss: 0.66762 | train_accuracy: 0.71667 | valid_accuracy: 0.69388 |  0:00:16s\n",
      "epoch 170| loss: 0.67002 | train_accuracy: 0.72177 | valid_accuracy: 0.69864 |  0:00:16s\n",
      "epoch 171| loss: 0.67963 | train_accuracy: 0.71939 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 172| loss: 0.66539 | train_accuracy: 0.72364 | valid_accuracy: 0.69388 |  0:00:16s\n",
      "epoch 173| loss: 0.66571 | train_accuracy: 0.72517 | valid_accuracy: 0.7     |  0:00:16s\n",
      "epoch 174| loss: 0.6657  | train_accuracy: 0.72075 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 175| loss: 0.6648  | train_accuracy: 0.72432 | valid_accuracy: 0.6966  |  0:00:16s\n",
      "epoch 176| loss: 0.66868 | train_accuracy: 0.72313 | valid_accuracy: 0.70068 |  0:00:16s\n",
      "epoch 177| loss: 0.66952 | train_accuracy: 0.72959 | valid_accuracy: 0.70816 |  0:00:16s\n",
      "epoch 178| loss: 0.6705  | train_accuracy: 0.72245 | valid_accuracy: 0.69524 |  0:00:16s\n",
      "epoch 179| loss: 0.67791 | train_accuracy: 0.72262 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 180| loss: 0.66648 | train_accuracy: 0.72194 | valid_accuracy: 0.70408 |  0:00:17s\n",
      "epoch 181| loss: 0.66588 | train_accuracy: 0.72364 | valid_accuracy: 0.7     |  0:00:17s\n",
      "epoch 182| loss: 0.67022 | train_accuracy: 0.7216  | valid_accuracy: 0.68639 |  0:00:17s\n",
      "epoch 183| loss: 0.67812 | train_accuracy: 0.72415 | valid_accuracy: 0.69252 |  0:00:17s\n",
      "epoch 184| loss: 0.66393 | train_accuracy: 0.72296 | valid_accuracy: 0.69184 |  0:00:17s\n",
      "epoch 185| loss: 0.67565 | train_accuracy: 0.72517 | valid_accuracy: 0.7     |  0:00:17s\n",
      "epoch 186| loss: 0.67243 | train_accuracy: 0.72279 | valid_accuracy: 0.70136 |  0:00:17s\n",
      "epoch 187| loss: 0.65133 | train_accuracy: 0.71735 | valid_accuracy: 0.69932 |  0:00:17s\n",
      "epoch 188| loss: 0.68419 | train_accuracy: 0.72687 | valid_accuracy: 0.69524 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189| loss: 0.67067 | train_accuracy: 0.7216  | valid_accuracy: 0.69388 |  0:00:17s\n",
      "epoch 190| loss: 0.67456 | train_accuracy: 0.72857 | valid_accuracy: 0.70544 |  0:00:18s\n",
      "epoch 191| loss: 0.65541 | train_accuracy: 0.72466 | valid_accuracy: 0.70272 |  0:00:18s\n",
      "epoch 192| loss: 0.66493 | train_accuracy: 0.72636 | valid_accuracy: 0.70476 |  0:00:18s\n",
      "epoch 193| loss: 0.66509 | train_accuracy: 0.72483 | valid_accuracy: 0.70816 |  0:00:18s\n",
      "epoch 194| loss: 0.67433 | train_accuracy: 0.72908 | valid_accuracy: 0.71088 |  0:00:18s\n",
      "epoch 195| loss: 0.66063 | train_accuracy: 0.73095 | valid_accuracy: 0.70136 |  0:00:18s\n",
      "epoch 196| loss: 0.66502 | train_accuracy: 0.72653 | valid_accuracy: 0.69252 |  0:00:18s\n",
      "epoch 197| loss: 0.67643 | train_accuracy: 0.72262 | valid_accuracy: 0.70136 |  0:00:18s\n",
      "epoch 198| loss: 0.65234 | train_accuracy: 0.72687 | valid_accuracy: 0.70476 |  0:00:18s\n",
      "epoch 199| loss: 0.66488 | train_accuracy: 0.72636 | valid_accuracy: 0.6966  |  0:00:18s\n",
      "epoch 200| loss: 0.66715 | train_accuracy: 0.73044 | valid_accuracy: 0.70748 |  0:00:18s\n",
      "epoch 201| loss: 0.67456 | train_accuracy: 0.72398 | valid_accuracy: 0.69796 |  0:00:19s\n",
      "epoch 202| loss: 0.65982 | train_accuracy: 0.72347 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 203| loss: 0.67493 | train_accuracy: 0.72721 | valid_accuracy: 0.69728 |  0:00:19s\n",
      "epoch 204| loss: 0.66155 | train_accuracy: 0.7267  | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 205| loss: 0.65949 | train_accuracy: 0.72585 | valid_accuracy: 0.7034  |  0:00:19s\n",
      "epoch 206| loss: 0.66424 | train_accuracy: 0.72925 | valid_accuracy: 0.70408 |  0:00:19s\n",
      "epoch 207| loss: 0.6639  | train_accuracy: 0.73112 | valid_accuracy: 0.7034  |  0:00:19s\n",
      "epoch 208| loss: 0.66023 | train_accuracy: 0.73095 | valid_accuracy: 0.7     |  0:00:19s\n",
      "epoch 209| loss: 0.65998 | train_accuracy: 0.73537 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 210| loss: 0.66857 | train_accuracy: 0.72585 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 211| loss: 0.65461 | train_accuracy: 0.72279 | valid_accuracy: 0.7     |  0:00:19s\n",
      "epoch 212| loss: 0.66297 | train_accuracy: 0.72908 | valid_accuracy: 0.70272 |  0:00:20s\n",
      "epoch 213| loss: 0.66027 | train_accuracy: 0.7284  | valid_accuracy: 0.72041 |  0:00:20s\n",
      "epoch 214| loss: 0.67456 | train_accuracy: 0.73401 | valid_accuracy: 0.70816 |  0:00:20s\n",
      "epoch 215| loss: 0.65908 | train_accuracy: 0.7369  | valid_accuracy: 0.70408 |  0:00:20s\n",
      "epoch 216| loss: 0.65874 | train_accuracy: 0.73622 | valid_accuracy: 0.70272 |  0:00:20s\n",
      "epoch 217| loss: 0.64917 | train_accuracy: 0.73452 | valid_accuracy: 0.71088 |  0:00:20s\n",
      "epoch 218| loss: 0.64354 | train_accuracy: 0.73044 | valid_accuracy: 0.70748 |  0:00:20s\n",
      "epoch 219| loss: 0.64789 | train_accuracy: 0.73316 | valid_accuracy: 0.70476 |  0:00:20s\n",
      "epoch 220| loss: 0.66689 | train_accuracy: 0.7352  | valid_accuracy: 0.70408 |  0:00:20s\n",
      "epoch 221| loss: 0.66216 | train_accuracy: 0.72704 | valid_accuracy: 0.69456 |  0:00:20s\n",
      "epoch 222| loss: 0.65637 | train_accuracy: 0.72789 | valid_accuracy: 0.70476 |  0:00:20s\n",
      "epoch 223| loss: 0.67914 | train_accuracy: 0.73163 | valid_accuracy: 0.7068  |  0:00:21s\n",
      "epoch 224| loss: 0.65484 | train_accuracy: 0.73027 | valid_accuracy: 0.70408 |  0:00:21s\n",
      "epoch 225| loss: 0.65903 | train_accuracy: 0.72721 | valid_accuracy: 0.69796 |  0:00:21s\n",
      "epoch 226| loss: 0.65937 | train_accuracy: 0.73129 | valid_accuracy: 0.70544 |  0:00:21s\n",
      "epoch 227| loss: 0.64882 | train_accuracy: 0.73248 | valid_accuracy: 0.70544 |  0:00:21s\n",
      "epoch 228| loss: 0.67114 | train_accuracy: 0.72908 | valid_accuracy: 0.70136 |  0:00:21s\n",
      "epoch 229| loss: 0.64649 | train_accuracy: 0.73061 | valid_accuracy: 0.70952 |  0:00:21s\n",
      "epoch 230| loss: 0.64551 | train_accuracy: 0.73605 | valid_accuracy: 0.71088 |  0:00:21s\n",
      "epoch 231| loss: 0.64557 | train_accuracy: 0.73503 | valid_accuracy: 0.70816 |  0:00:21s\n",
      "epoch 232| loss: 0.66494 | train_accuracy: 0.73759 | valid_accuracy: 0.70476 |  0:00:21s\n",
      "epoch 233| loss: 0.65147 | train_accuracy: 0.73316 | valid_accuracy: 0.70748 |  0:00:22s\n",
      "epoch 234| loss: 0.64924 | train_accuracy: 0.72942 | valid_accuracy: 0.70408 |  0:00:22s\n",
      "epoch 235| loss: 0.65607 | train_accuracy: 0.73588 | valid_accuracy: 0.71293 |  0:00:22s\n",
      "epoch 236| loss: 0.65233 | train_accuracy: 0.73622 | valid_accuracy: 0.71293 |  0:00:22s\n",
      "epoch 237| loss: 0.6607  | train_accuracy: 0.73503 | valid_accuracy: 0.71156 |  0:00:22s\n",
      "epoch 238| loss: 0.64632 | train_accuracy: 0.73452 | valid_accuracy: 0.71497 |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 238 with best_epoch = 213 and best_valid_accuracy = 0.72041\n",
      "218\n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.6219  | train_accuracy: 0.33588 | valid_accuracy: 0.33401 |  0:00:00s\n",
      "epoch 1  | loss: 1.16128 | train_accuracy: 0.31582 | valid_accuracy: 0.31769 |  0:00:00s\n",
      "epoch 2  | loss: 1.05408 | train_accuracy: 0.2949  | valid_accuracy: 0.30068 |  0:00:00s\n",
      "epoch 3  | loss: 0.99992 | train_accuracy: 0.37092 | valid_accuracy: 0.35442 |  0:00:00s\n",
      "epoch 4  | loss: 0.96247 | train_accuracy: 0.34762 | valid_accuracy: 0.3483  |  0:00:00s\n",
      "epoch 5  | loss: 0.95919 | train_accuracy: 0.37177 | valid_accuracy: 0.36395 |  0:00:00s\n",
      "epoch 6  | loss: 0.92373 | train_accuracy: 0.46616 | valid_accuracy: 0.45918 |  0:00:00s\n",
      "epoch 7  | loss: 0.91329 | train_accuracy: 0.53163 | valid_accuracy: 0.51701 |  0:00:00s\n",
      "epoch 8  | loss: 0.90408 | train_accuracy: 0.49558 | valid_accuracy: 0.48299 |  0:00:00s\n",
      "epoch 9  | loss: 0.87807 | train_accuracy: 0.40391 | valid_accuracy: 0.41156 |  0:00:00s\n",
      "epoch 10 | loss: 0.88828 | train_accuracy: 0.39422 | valid_accuracy: 0.40476 |  0:00:01s\n",
      "epoch 11 | loss: 0.87849 | train_accuracy: 0.39269 | valid_accuracy: 0.41293 |  0:00:01s\n",
      "epoch 12 | loss: 0.87732 | train_accuracy: 0.43367 | valid_accuracy: 0.44014 |  0:00:01s\n",
      "epoch 13 | loss: 0.8602  | train_accuracy: 0.41088 | valid_accuracy: 0.41973 |  0:00:01s\n",
      "epoch 14 | loss: 0.86205 | train_accuracy: 0.44524 | valid_accuracy: 0.44354 |  0:00:01s\n",
      "epoch 15 | loss: 0.8487  | train_accuracy: 0.39575 | valid_accuracy: 0.39864 |  0:00:01s\n",
      "epoch 16 | loss: 0.84122 | train_accuracy: 0.39983 | valid_accuracy: 0.39932 |  0:00:01s\n",
      "epoch 17 | loss: 0.84195 | train_accuracy: 0.5085  | valid_accuracy: 0.5     |  0:00:01s\n",
      "epoch 18 | loss: 0.83797 | train_accuracy: 0.54762 | valid_accuracy: 0.53061 |  0:00:01s\n",
      "epoch 19 | loss: 0.82605 | train_accuracy: 0.53741 | valid_accuracy: 0.51088 |  0:00:01s\n",
      "epoch 20 | loss: 0.82799 | train_accuracy: 0.55578 | valid_accuracy: 0.53401 |  0:00:02s\n",
      "epoch 21 | loss: 0.83243 | train_accuracy: 0.58078 | valid_accuracy: 0.58163 |  0:00:02s\n",
      "epoch 22 | loss: 0.82751 | train_accuracy: 0.56412 | valid_accuracy: 0.55102 |  0:00:02s\n",
      "epoch 23 | loss: 0.81681 | train_accuracy: 0.58299 | valid_accuracy: 0.58163 |  0:00:02s\n",
      "epoch 24 | loss: 0.8247  | train_accuracy: 0.58146 | valid_accuracy: 0.58231 |  0:00:02s\n",
      "epoch 25 | loss: 0.82333 | train_accuracy: 0.59048 | valid_accuracy: 0.58844 |  0:00:02s\n",
      "epoch 26 | loss: 0.80752 | train_accuracy: 0.58435 | valid_accuracy: 0.57619 |  0:00:02s\n",
      "epoch 27 | loss: 0.80979 | train_accuracy: 0.59949 | valid_accuracy: 0.59388 |  0:00:02s\n",
      "epoch 28 | loss: 0.79554 | train_accuracy: 0.59099 | valid_accuracy: 0.59184 |  0:00:02s\n",
      "epoch 29 | loss: 0.80974 | train_accuracy: 0.6034  | valid_accuracy: 0.59388 |  0:00:02s\n",
      "epoch 30 | loss: 0.80645 | train_accuracy: 0.60238 | valid_accuracy: 0.60068 |  0:00:02s\n",
      "epoch 31 | loss: 0.80875 | train_accuracy: 0.59847 | valid_accuracy: 0.60204 |  0:00:03s\n",
      "epoch 32 | loss: 0.80035 | train_accuracy: 0.6051  | valid_accuracy: 0.59932 |  0:00:03s\n",
      "epoch 33 | loss: 0.8038  | train_accuracy: 0.59201 | valid_accuracy: 0.58844 |  0:00:03s\n",
      "epoch 34 | loss: 0.80054 | train_accuracy: 0.58895 | valid_accuracy: 0.58844 |  0:00:03s\n",
      "epoch 35 | loss: 0.81981 | train_accuracy: 0.61156 | valid_accuracy: 0.59864 |  0:00:03s\n",
      "epoch 36 | loss: 0.80109 | train_accuracy: 0.62602 | valid_accuracy: 0.61565 |  0:00:03s\n",
      "epoch 37 | loss: 0.79156 | train_accuracy: 0.62874 | valid_accuracy: 0.60884 |  0:00:03s\n",
      "epoch 38 | loss: 0.79593 | train_accuracy: 0.62721 | valid_accuracy: 0.61905 |  0:00:03s\n",
      "epoch 39 | loss: 0.77731 | train_accuracy: 0.63639 | valid_accuracy: 0.61088 |  0:00:03s\n",
      "epoch 40 | loss: 0.7732  | train_accuracy: 0.62653 | valid_accuracy: 0.61701 |  0:00:03s\n",
      "epoch 41 | loss: 0.76396 | train_accuracy: 0.63299 | valid_accuracy: 0.62449 |  0:00:03s\n",
      "epoch 42 | loss: 0.7901  | train_accuracy: 0.62959 | valid_accuracy: 0.60884 |  0:00:04s\n",
      "epoch 43 | loss: 0.77527 | train_accuracy: 0.64371 | valid_accuracy: 0.62041 |  0:00:04s\n",
      "epoch 44 | loss: 0.77461 | train_accuracy: 0.65068 | valid_accuracy: 0.64558 |  0:00:04s\n",
      "epoch 45 | loss: 0.77889 | train_accuracy: 0.6449  | valid_accuracy: 0.61837 |  0:00:04s\n",
      "epoch 46 | loss: 0.76202 | train_accuracy: 0.64303 | valid_accuracy: 0.62177 |  0:00:04s\n",
      "epoch 47 | loss: 0.77282 | train_accuracy: 0.64252 | valid_accuracy: 0.62925 |  0:00:04s\n",
      "epoch 48 | loss: 0.7636  | train_accuracy: 0.64099 | valid_accuracy: 0.61769 |  0:00:04s\n",
      "epoch 49 | loss: 0.76856 | train_accuracy: 0.64507 | valid_accuracy: 0.63605 |  0:00:04s\n",
      "epoch 50 | loss: 0.75755 | train_accuracy: 0.64796 | valid_accuracy: 0.62993 |  0:00:04s\n",
      "epoch 51 | loss: 0.75795 | train_accuracy: 0.65646 | valid_accuracy: 0.63401 |  0:00:04s\n",
      "epoch 52 | loss: 0.76342 | train_accuracy: 0.66207 | valid_accuracy: 0.64286 |  0:00:05s\n",
      "epoch 53 | loss: 0.7654  | train_accuracy: 0.66224 | valid_accuracy: 0.65102 |  0:00:05s\n",
      "epoch 54 | loss: 0.75849 | train_accuracy: 0.65374 | valid_accuracy: 0.62449 |  0:00:05s\n",
      "epoch 55 | loss: 0.75705 | train_accuracy: 0.66276 | valid_accuracy: 0.63265 |  0:00:05s\n",
      "epoch 56 | loss: 0.76233 | train_accuracy: 0.65867 | valid_accuracy: 0.64762 |  0:00:05s\n",
      "epoch 57 | loss: 0.74436 | train_accuracy: 0.66088 | valid_accuracy: 0.63605 |  0:00:05s\n",
      "epoch 58 | loss: 0.7569  | train_accuracy: 0.6619  | valid_accuracy: 0.65578 |  0:00:05s\n",
      "epoch 59 | loss: 0.75672 | train_accuracy: 0.6602  | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 60 | loss: 0.74812 | train_accuracy: 0.67058 | valid_accuracy: 0.65986 |  0:00:05s\n",
      "epoch 61 | loss: 0.7322  | train_accuracy: 0.6665  | valid_accuracy: 0.65102 |  0:00:05s\n",
      "epoch 62 | loss: 0.75306 | train_accuracy: 0.67194 | valid_accuracy: 0.65238 |  0:00:05s\n",
      "epoch 63 | loss: 0.73929 | train_accuracy: 0.67177 | valid_accuracy: 0.64626 |  0:00:06s\n",
      "epoch 64 | loss: 0.75601 | train_accuracy: 0.67398 | valid_accuracy: 0.63946 |  0:00:06s\n",
      "epoch 65 | loss: 0.74223 | train_accuracy: 0.68639 | valid_accuracy: 0.64558 |  0:00:06s\n",
      "epoch 66 | loss: 0.72961 | train_accuracy: 0.66361 | valid_accuracy: 0.64082 |  0:00:06s\n",
      "epoch 67 | loss: 0.73276 | train_accuracy: 0.6835  | valid_accuracy: 0.6483  |  0:00:06s\n",
      "epoch 68 | loss: 0.74087 | train_accuracy: 0.68724 | valid_accuracy: 0.65102 |  0:00:06s\n",
      "epoch 69 | loss: 0.72479 | train_accuracy: 0.68878 | valid_accuracy: 0.66122 |  0:00:06s\n",
      "epoch 70 | loss: 0.73856 | train_accuracy: 0.69116 | valid_accuracy: 0.6585  |  0:00:06s\n",
      "epoch 71 | loss: 0.72579 | train_accuracy: 0.69167 | valid_accuracy: 0.66259 |  0:00:06s\n",
      "epoch 72 | loss: 0.72138 | train_accuracy: 0.68163 | valid_accuracy: 0.65102 |  0:00:06s\n",
      "epoch 73 | loss: 0.70753 | train_accuracy: 0.6898  | valid_accuracy: 0.67143 |  0:00:06s\n",
      "epoch 74 | loss: 0.72707 | train_accuracy: 0.6801  | valid_accuracy: 0.66395 |  0:00:07s\n",
      "epoch 75 | loss: 0.73329 | train_accuracy: 0.69133 | valid_accuracy: 0.66871 |  0:00:07s\n",
      "epoch 76 | loss: 0.72875 | train_accuracy: 0.69473 | valid_accuracy: 0.6585  |  0:00:07s\n",
      "epoch 77 | loss: 0.73537 | train_accuracy: 0.69133 | valid_accuracy: 0.66054 |  0:00:07s\n",
      "epoch 78 | loss: 0.72085 | train_accuracy: 0.69048 | valid_accuracy: 0.6551  |  0:00:07s\n",
      "epoch 79 | loss: 0.72167 | train_accuracy: 0.68095 | valid_accuracy: 0.65918 |  0:00:07s\n",
      "epoch 80 | loss: 0.72607 | train_accuracy: 0.68912 | valid_accuracy: 0.6551  |  0:00:07s\n",
      "epoch 81 | loss: 0.71988 | train_accuracy: 0.69388 | valid_accuracy: 0.66327 |  0:00:07s\n",
      "epoch 82 | loss: 0.70151 | train_accuracy: 0.6949  | valid_accuracy: 0.65986 |  0:00:07s\n",
      "epoch 83 | loss: 0.71526 | train_accuracy: 0.70238 | valid_accuracy: 0.67483 |  0:00:07s\n",
      "epoch 84 | loss: 0.70586 | train_accuracy: 0.69388 | valid_accuracy: 0.66531 |  0:00:08s\n",
      "epoch 85 | loss: 0.72074 | train_accuracy: 0.69286 | valid_accuracy: 0.66395 |  0:00:08s\n",
      "epoch 86 | loss: 0.72581 | train_accuracy: 0.69711 | valid_accuracy: 0.66327 |  0:00:08s\n",
      "epoch 87 | loss: 0.71131 | train_accuracy: 0.70085 | valid_accuracy: 0.66463 |  0:00:08s\n",
      "epoch 88 | loss: 0.71193 | train_accuracy: 0.68895 | valid_accuracy: 0.66531 |  0:00:08s\n",
      "epoch 89 | loss: 0.70614 | train_accuracy: 0.69524 | valid_accuracy: 0.66463 |  0:00:08s\n",
      "epoch 90 | loss: 0.70875 | train_accuracy: 0.70527 | valid_accuracy: 0.66667 |  0:00:08s\n",
      "epoch 91 | loss: 0.71469 | train_accuracy: 0.70833 | valid_accuracy: 0.67347 |  0:00:08s\n",
      "epoch 92 | loss: 0.70945 | train_accuracy: 0.6932  | valid_accuracy: 0.65986 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.70376 | train_accuracy: 0.69745 | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 94 | loss: 0.70661 | train_accuracy: 0.70221 | valid_accuracy: 0.65578 |  0:00:08s\n",
      "epoch 95 | loss: 0.71226 | train_accuracy: 0.6983  | valid_accuracy: 0.66531 |  0:00:09s\n",
      "epoch 96 | loss: 0.71646 | train_accuracy: 0.70119 | valid_accuracy: 0.64626 |  0:00:09s\n",
      "epoch 97 | loss: 0.71079 | train_accuracy: 0.7017  | valid_accuracy: 0.6585  |  0:00:09s\n",
      "epoch 98 | loss: 0.70677 | train_accuracy: 0.69881 | valid_accuracy: 0.66259 |  0:00:09s\n",
      "epoch 99 | loss: 0.70854 | train_accuracy: 0.70799 | valid_accuracy: 0.65986 |  0:00:09s\n",
      "epoch 100| loss: 0.69734 | train_accuracy: 0.70714 | valid_accuracy: 0.67007 |  0:00:09s\n",
      "epoch 101| loss: 0.69255 | train_accuracy: 0.70527 | valid_accuracy: 0.66735 |  0:00:09s\n",
      "epoch 102| loss: 0.70392 | train_accuracy: 0.70187 | valid_accuracy: 0.66463 |  0:00:09s\n",
      "epoch 103| loss: 0.69382 | train_accuracy: 0.70595 | valid_accuracy: 0.65918 |  0:00:09s\n",
      "epoch 104| loss: 0.69596 | train_accuracy: 0.70714 | valid_accuracy: 0.66803 |  0:00:09s\n",
      "epoch 105| loss: 0.70403 | train_accuracy: 0.70714 | valid_accuracy: 0.66395 |  0:00:10s\n",
      "epoch 106| loss: 0.68784 | train_accuracy: 0.7148  | valid_accuracy: 0.67891 |  0:00:10s\n",
      "epoch 107| loss: 0.69637 | train_accuracy: 0.7119  | valid_accuracy: 0.66599 |  0:00:10s\n",
      "epoch 108| loss: 0.69557 | train_accuracy: 0.7182  | valid_accuracy: 0.67823 |  0:00:10s\n",
      "epoch 109| loss: 0.70309 | train_accuracy: 0.71224 | valid_accuracy: 0.67075 |  0:00:10s\n",
      "epoch 110| loss: 0.68704 | train_accuracy: 0.72092 | valid_accuracy: 0.67891 |  0:00:10s\n",
      "epoch 111| loss: 0.68757 | train_accuracy: 0.71922 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 112| loss: 0.68668 | train_accuracy: 0.71105 | valid_accuracy: 0.66531 |  0:00:10s\n",
      "epoch 113| loss: 0.68587 | train_accuracy: 0.71837 | valid_accuracy: 0.67959 |  0:00:10s\n",
      "epoch 114| loss: 0.68086 | train_accuracy: 0.72228 | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 115| loss: 0.69128 | train_accuracy: 0.72024 | valid_accuracy: 0.67211 |  0:00:10s\n",
      "epoch 116| loss: 0.6848  | train_accuracy: 0.71701 | valid_accuracy: 0.67143 |  0:00:11s\n",
      "epoch 117| loss: 0.70199 | train_accuracy: 0.71327 | valid_accuracy: 0.65986 |  0:00:11s\n",
      "epoch 118| loss: 0.69577 | train_accuracy: 0.70731 | valid_accuracy: 0.66735 |  0:00:11s\n",
      "epoch 119| loss: 0.68636 | train_accuracy: 0.7051  | valid_accuracy: 0.66735 |  0:00:11s\n",
      "epoch 120| loss: 0.69102 | train_accuracy: 0.7131  | valid_accuracy: 0.66803 |  0:00:11s\n",
      "epoch 121| loss: 0.68252 | train_accuracy: 0.72211 | valid_accuracy: 0.68299 |  0:00:11s\n",
      "epoch 122| loss: 0.67979 | train_accuracy: 0.71803 | valid_accuracy: 0.67619 |  0:00:11s\n",
      "epoch 123| loss: 0.68873 | train_accuracy: 0.7085  | valid_accuracy: 0.67755 |  0:00:11s\n",
      "epoch 124| loss: 0.67694 | train_accuracy: 0.72092 | valid_accuracy: 0.68231 |  0:00:11s\n",
      "epoch 125| loss: 0.6856  | train_accuracy: 0.72585 | valid_accuracy: 0.68163 |  0:00:11s\n",
      "epoch 126| loss: 0.66768 | train_accuracy: 0.73061 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 127| loss: 0.67207 | train_accuracy: 0.72449 | valid_accuracy: 0.69524 |  0:00:12s\n",
      "epoch 128| loss: 0.67068 | train_accuracy: 0.72143 | valid_accuracy: 0.68435 |  0:00:12s\n",
      "epoch 129| loss: 0.66212 | train_accuracy: 0.72364 | valid_accuracy: 0.67483 |  0:00:12s\n",
      "epoch 130| loss: 0.67708 | train_accuracy: 0.72891 | valid_accuracy: 0.68367 |  0:00:12s\n",
      "epoch 131| loss: 0.67846 | train_accuracy: 0.73214 | valid_accuracy: 0.68707 |  0:00:12s\n",
      "epoch 132| loss: 0.6588  | train_accuracy: 0.73571 | valid_accuracy: 0.68299 |  0:00:12s\n",
      "epoch 133| loss: 0.66209 | train_accuracy: 0.72806 | valid_accuracy: 0.67959 |  0:00:12s\n",
      "epoch 134| loss: 0.65954 | train_accuracy: 0.72755 | valid_accuracy: 0.68367 |  0:00:12s\n",
      "epoch 135| loss: 0.67586 | train_accuracy: 0.73197 | valid_accuracy: 0.68367 |  0:00:12s\n",
      "epoch 136| loss: 0.6664  | train_accuracy: 0.72738 | valid_accuracy: 0.69048 |  0:00:12s\n",
      "epoch 137| loss: 0.68195 | train_accuracy: 0.72874 | valid_accuracy: 0.68639 |  0:00:13s\n",
      "epoch 138| loss: 0.66158 | train_accuracy: 0.71412 | valid_accuracy: 0.67415 |  0:00:13s\n",
      "epoch 139| loss: 0.66703 | train_accuracy: 0.72347 | valid_accuracy: 0.68503 |  0:00:13s\n",
      "epoch 140| loss: 0.67375 | train_accuracy: 0.74252 | valid_accuracy: 0.70068 |  0:00:13s\n",
      "epoch 141| loss: 0.65439 | train_accuracy: 0.74218 | valid_accuracy: 0.7034  |  0:00:13s\n",
      "epoch 142| loss: 0.67469 | train_accuracy: 0.73163 | valid_accuracy: 0.69456 |  0:00:13s\n",
      "epoch 143| loss: 0.67645 | train_accuracy: 0.73673 | valid_accuracy: 0.69524 |  0:00:13s\n",
      "epoch 144| loss: 0.65464 | train_accuracy: 0.73793 | valid_accuracy: 0.68912 |  0:00:13s\n",
      "epoch 145| loss: 0.65806 | train_accuracy: 0.73231 | valid_accuracy: 0.70204 |  0:00:13s\n",
      "epoch 146| loss: 0.65527 | train_accuracy: 0.7284  | valid_accuracy: 0.68707 |  0:00:13s\n",
      "epoch 147| loss: 0.6601  | train_accuracy: 0.73316 | valid_accuracy: 0.69524 |  0:00:13s\n",
      "epoch 148| loss: 0.65679 | train_accuracy: 0.73861 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 149| loss: 0.66438 | train_accuracy: 0.7301  | valid_accuracy: 0.6898  |  0:00:14s\n",
      "epoch 150| loss: 0.6678  | train_accuracy: 0.74082 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 151| loss: 0.65209 | train_accuracy: 0.73741 | valid_accuracy: 0.69456 |  0:00:14s\n",
      "epoch 152| loss: 0.65583 | train_accuracy: 0.74252 | valid_accuracy: 0.69932 |  0:00:14s\n",
      "epoch 153| loss: 0.65125 | train_accuracy: 0.74864 | valid_accuracy: 0.7034  |  0:00:14s\n",
      "epoch 154| loss: 0.65518 | train_accuracy: 0.73333 | valid_accuracy: 0.68912 |  0:00:14s\n",
      "epoch 155| loss: 0.6519  | train_accuracy: 0.74405 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 156| loss: 0.66137 | train_accuracy: 0.7335  | valid_accuracy: 0.69932 |  0:00:14s\n",
      "epoch 157| loss: 0.64363 | train_accuracy: 0.7335  | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 158| loss: 0.6656  | train_accuracy: 0.74609 | valid_accuracy: 0.69796 |  0:00:15s\n",
      "epoch 159| loss: 0.64492 | train_accuracy: 0.75017 | valid_accuracy: 0.7068  |  0:00:15s\n",
      "epoch 160| loss: 0.64964 | train_accuracy: 0.75391 | valid_accuracy: 0.71293 |  0:00:15s\n",
      "epoch 161| loss: 0.66294 | train_accuracy: 0.75578 | valid_accuracy: 0.70408 |  0:00:15s\n",
      "epoch 162| loss: 0.6418  | train_accuracy: 0.75255 | valid_accuracy: 0.70136 |  0:00:15s\n",
      "epoch 163| loss: 0.65226 | train_accuracy: 0.74575 | valid_accuracy: 0.69932 |  0:00:15s\n",
      "epoch 164| loss: 0.64865 | train_accuracy: 0.74762 | valid_accuracy: 0.70272 |  0:00:15s\n",
      "epoch 165| loss: 0.64872 | train_accuracy: 0.74082 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 166| loss: 0.65339 | train_accuracy: 0.7517  | valid_accuracy: 0.70612 |  0:00:15s\n",
      "epoch 167| loss: 0.65696 | train_accuracy: 0.74337 | valid_accuracy: 0.70544 |  0:00:15s\n",
      "epoch 168| loss: 0.64017 | train_accuracy: 0.74847 | valid_accuracy: 0.69456 |  0:00:15s\n",
      "epoch 169| loss: 0.65208 | train_accuracy: 0.74286 | valid_accuracy: 0.70408 |  0:00:16s\n",
      "epoch 170| loss: 0.6398  | train_accuracy: 0.74694 | valid_accuracy: 0.70612 |  0:00:16s\n",
      "epoch 171| loss: 0.64604 | train_accuracy: 0.74626 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 172| loss: 0.64341 | train_accuracy: 0.75017 | valid_accuracy: 0.70748 |  0:00:16s\n",
      "epoch 173| loss: 0.62955 | train_accuracy: 0.74082 | valid_accuracy: 0.69524 |  0:00:16s\n",
      "epoch 174| loss: 0.63625 | train_accuracy: 0.75323 | valid_accuracy: 0.7     |  0:00:16s\n",
      "epoch 175| loss: 0.6341  | train_accuracy: 0.75136 | valid_accuracy: 0.70612 |  0:00:16s\n",
      "epoch 176| loss: 0.64144 | train_accuracy: 0.75391 | valid_accuracy: 0.71565 |  0:00:16s\n",
      "epoch 177| loss: 0.64204 | train_accuracy: 0.73895 | valid_accuracy: 0.6932  |  0:00:16s\n",
      "epoch 178| loss: 0.63973 | train_accuracy: 0.74898 | valid_accuracy: 0.70884 |  0:00:16s\n",
      "epoch 179| loss: 0.6404  | train_accuracy: 0.74218 | valid_accuracy: 0.70204 |  0:00:16s\n",
      "epoch 180| loss: 0.63993 | train_accuracy: 0.74796 | valid_accuracy: 0.71156 |  0:00:17s\n",
      "epoch 181| loss: 0.63953 | train_accuracy: 0.74728 | valid_accuracy: 0.71429 |  0:00:17s\n",
      "epoch 182| loss: 0.64202 | train_accuracy: 0.75323 | valid_accuracy: 0.71224 |  0:00:17s\n",
      "epoch 183| loss: 0.62247 | train_accuracy: 0.75153 | valid_accuracy: 0.7102  |  0:00:17s\n",
      "epoch 184| loss: 0.63238 | train_accuracy: 0.75068 | valid_accuracy: 0.7068  |  0:00:17s\n",
      "epoch 185| loss: 0.64519 | train_accuracy: 0.75187 | valid_accuracy: 0.70272 |  0:00:17s\n",
      "epoch 186| loss: 0.62781 | train_accuracy: 0.75051 | valid_accuracy: 0.70884 |  0:00:17s\n",
      "epoch 187| loss: 0.63493 | train_accuracy: 0.74201 | valid_accuracy: 0.70136 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188| loss: 0.63145 | train_accuracy: 0.75051 | valid_accuracy: 0.71156 |  0:00:17s\n",
      "epoch 189| loss: 0.64442 | train_accuracy: 0.74762 | valid_accuracy: 0.7     |  0:00:17s\n",
      "epoch 190| loss: 0.63957 | train_accuracy: 0.75102 | valid_accuracy: 0.70612 |  0:00:17s\n",
      "epoch 191| loss: 0.64267 | train_accuracy: 0.76173 | valid_accuracy: 0.72517 |  0:00:18s\n",
      "epoch 192| loss: 0.64347 | train_accuracy: 0.75085 | valid_accuracy: 0.71361 |  0:00:18s\n",
      "epoch 193| loss: 0.63297 | train_accuracy: 0.75357 | valid_accuracy: 0.71361 |  0:00:18s\n",
      "epoch 194| loss: 0.63961 | train_accuracy: 0.74711 | valid_accuracy: 0.69864 |  0:00:18s\n",
      "epoch 195| loss: 0.6404  | train_accuracy: 0.7466  | valid_accuracy: 0.6966  |  0:00:18s\n",
      "epoch 196| loss: 0.63606 | train_accuracy: 0.75544 | valid_accuracy: 0.71224 |  0:00:18s\n",
      "epoch 197| loss: 0.63664 | train_accuracy: 0.75816 | valid_accuracy: 0.71156 |  0:00:18s\n",
      "epoch 198| loss: 0.63927 | train_accuracy: 0.76037 | valid_accuracy: 0.71293 |  0:00:18s\n",
      "epoch 199| loss: 0.62694 | train_accuracy: 0.7551  | valid_accuracy: 0.7068  |  0:00:18s\n",
      "epoch 200| loss: 0.62261 | train_accuracy: 0.74847 | valid_accuracy: 0.7034  |  0:00:18s\n",
      "epoch 201| loss: 0.64087 | train_accuracy: 0.75731 | valid_accuracy: 0.71497 |  0:00:18s\n",
      "epoch 202| loss: 0.62742 | train_accuracy: 0.76463 | valid_accuracy: 0.71293 |  0:00:19s\n",
      "epoch 203| loss: 0.63286 | train_accuracy: 0.75119 | valid_accuracy: 0.71156 |  0:00:19s\n",
      "epoch 204| loss: 0.62704 | train_accuracy: 0.75    | valid_accuracy: 0.70408 |  0:00:19s\n",
      "epoch 205| loss: 0.63671 | train_accuracy: 0.75221 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 206| loss: 0.64088 | train_accuracy: 0.75493 | valid_accuracy: 0.71293 |  0:00:19s\n",
      "epoch 207| loss: 0.62596 | train_accuracy: 0.75408 | valid_accuracy: 0.71224 |  0:00:19s\n",
      "epoch 208| loss: 0.6403  | train_accuracy: 0.75068 | valid_accuracy: 0.70884 |  0:00:19s\n",
      "epoch 209| loss: 0.63354 | train_accuracy: 0.76241 | valid_accuracy: 0.71769 |  0:00:19s\n",
      "epoch 210| loss: 0.637   | train_accuracy: 0.76139 | valid_accuracy: 0.71497 |  0:00:19s\n",
      "epoch 211| loss: 0.6327  | train_accuracy: 0.76139 | valid_accuracy: 0.71497 |  0:00:19s\n",
      "epoch 212| loss: 0.62751 | train_accuracy: 0.76156 | valid_accuracy: 0.70952 |  0:00:20s\n",
      "epoch 213| loss: 0.62389 | train_accuracy: 0.75867 | valid_accuracy: 0.70544 |  0:00:20s\n",
      "epoch 214| loss: 0.61694 | train_accuracy: 0.75969 | valid_accuracy: 0.71429 |  0:00:20s\n",
      "epoch 215| loss: 0.63406 | train_accuracy: 0.7534  | valid_accuracy: 0.7102  |  0:00:20s\n",
      "epoch 216| loss: 0.61557 | train_accuracy: 0.76378 | valid_accuracy: 0.71088 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 216 with best_epoch = 191 and best_valid_accuracy = 0.72517\n",
      "216\n",
      "191\n",
      "epoch 0  | loss: 1.70919 | train_accuracy: 0.35629 | valid_accuracy: 0.35578 |  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1  | loss: 1.22248 | train_accuracy: 0.38673 | valid_accuracy: 0.38095 |  0:00:00s\n",
      "epoch 2  | loss: 1.09514 | train_accuracy: 0.38299 | valid_accuracy: 0.36395 |  0:00:00s\n",
      "epoch 3  | loss: 1.03716 | train_accuracy: 0.40731 | valid_accuracy: 0.40612 |  0:00:00s\n",
      "epoch 4  | loss: 0.99247 | train_accuracy: 0.41769 | valid_accuracy: 0.41156 |  0:00:00s\n",
      "epoch 5  | loss: 0.97343 | train_accuracy: 0.42534 | valid_accuracy: 0.44082 |  0:00:00s\n",
      "epoch 6  | loss: 0.94536 | train_accuracy: 0.4835  | valid_accuracy: 0.50816 |  0:00:00s\n",
      "epoch 7  | loss: 0.93648 | train_accuracy: 0.48027 | valid_accuracy: 0.51633 |  0:00:00s\n",
      "epoch 8  | loss: 0.9163  | train_accuracy: 0.52075 | valid_accuracy: 0.54014 |  0:00:00s\n",
      "epoch 9  | loss: 0.90844 | train_accuracy: 0.49779 | valid_accuracy: 0.52313 |  0:00:00s\n",
      "epoch 10 | loss: 0.90103 | train_accuracy: 0.47789 | valid_accuracy: 0.49456 |  0:00:01s\n",
      "epoch 11 | loss: 0.89278 | train_accuracy: 0.48265 | valid_accuracy: 0.50748 |  0:00:01s\n",
      "epoch 12 | loss: 0.8876  | train_accuracy: 0.42568 | valid_accuracy: 0.43401 |  0:00:01s\n",
      "epoch 13 | loss: 0.87578 | train_accuracy: 0.45561 | valid_accuracy: 0.47075 |  0:00:01s\n",
      "epoch 14 | loss: 0.87895 | train_accuracy: 0.4233  | valid_accuracy: 0.44218 |  0:00:01s\n",
      "epoch 15 | loss: 0.87319 | train_accuracy: 0.44796 | valid_accuracy: 0.47143 |  0:00:01s\n",
      "epoch 16 | loss: 0.87235 | train_accuracy: 0.46361 | valid_accuracy: 0.48367 |  0:00:01s\n",
      "epoch 17 | loss: 0.8791  | train_accuracy: 0.48469 | valid_accuracy: 0.51361 |  0:00:01s\n",
      "epoch 18 | loss: 0.86393 | train_accuracy: 0.4733  | valid_accuracy: 0.48503 |  0:00:01s\n",
      "epoch 19 | loss: 0.85898 | train_accuracy: 0.49303 | valid_accuracy: 0.51156 |  0:00:01s\n",
      "epoch 20 | loss: 0.84622 | train_accuracy: 0.49966 | valid_accuracy: 0.51973 |  0:00:01s\n",
      "epoch 21 | loss: 0.84016 | train_accuracy: 0.46395 | valid_accuracy: 0.49048 |  0:00:02s\n",
      "epoch 22 | loss: 0.83505 | train_accuracy: 0.48044 | valid_accuracy: 0.49252 |  0:00:02s\n",
      "epoch 23 | loss: 0.83052 | train_accuracy: 0.52976 | valid_accuracy: 0.56939 |  0:00:02s\n",
      "epoch 24 | loss: 0.83713 | train_accuracy: 0.53759 | valid_accuracy: 0.55102 |  0:00:02s\n",
      "epoch 25 | loss: 0.83969 | train_accuracy: 0.54422 | valid_accuracy: 0.56803 |  0:00:02s\n",
      "epoch 26 | loss: 0.81891 | train_accuracy: 0.52279 | valid_accuracy: 0.5415  |  0:00:02s\n",
      "epoch 27 | loss: 0.81678 | train_accuracy: 0.53367 | valid_accuracy: 0.55034 |  0:00:02s\n",
      "epoch 28 | loss: 0.82559 | train_accuracy: 0.54201 | valid_accuracy: 0.55782 |  0:00:02s\n",
      "epoch 29 | loss: 0.81164 | train_accuracy: 0.59915 | valid_accuracy: 0.62993 |  0:00:02s\n",
      "epoch 30 | loss: 0.80494 | train_accuracy: 0.56156 | valid_accuracy: 0.58367 |  0:00:02s\n",
      "epoch 31 | loss: 0.8096  | train_accuracy: 0.56939 | valid_accuracy: 0.59184 |  0:00:02s\n",
      "epoch 32 | loss: 0.80265 | train_accuracy: 0.57194 | valid_accuracy: 0.6034  |  0:00:03s\n",
      "epoch 33 | loss: 0.80674 | train_accuracy: 0.55799 | valid_accuracy: 0.57823 |  0:00:03s\n",
      "epoch 34 | loss: 0.80593 | train_accuracy: 0.54286 | valid_accuracy: 0.55578 |  0:00:03s\n",
      "epoch 35 | loss: 0.80653 | train_accuracy: 0.53844 | valid_accuracy: 0.53878 |  0:00:03s\n",
      "epoch 36 | loss: 0.80307 | train_accuracy: 0.62075 | valid_accuracy: 0.6449  |  0:00:03s\n",
      "epoch 37 | loss: 0.80703 | train_accuracy: 0.61276 | valid_accuracy: 0.62517 |  0:00:03s\n",
      "epoch 38 | loss: 0.80296 | train_accuracy: 0.61037 | valid_accuracy: 0.63197 |  0:00:03s\n",
      "epoch 39 | loss: 0.81029 | train_accuracy: 0.62245 | valid_accuracy: 0.6449  |  0:00:03s\n",
      "epoch 40 | loss: 0.78922 | train_accuracy: 0.62449 | valid_accuracy: 0.64762 |  0:00:03s\n",
      "epoch 41 | loss: 0.78487 | train_accuracy: 0.62806 | valid_accuracy: 0.65578 |  0:00:03s\n",
      "epoch 42 | loss: 0.80557 | train_accuracy: 0.61905 | valid_accuracy: 0.6483  |  0:00:03s\n",
      "epoch 43 | loss: 0.7978  | train_accuracy: 0.61854 | valid_accuracy: 0.65782 |  0:00:04s\n",
      "epoch 44 | loss: 0.79125 | train_accuracy: 0.63673 | valid_accuracy: 0.6619  |  0:00:04s\n",
      "epoch 45 | loss: 0.7936  | train_accuracy: 0.64133 | valid_accuracy: 0.65986 |  0:00:04s\n",
      "epoch 46 | loss: 0.77043 | train_accuracy: 0.63282 | valid_accuracy: 0.6585  |  0:00:04s\n",
      "epoch 47 | loss: 0.77795 | train_accuracy: 0.63231 | valid_accuracy: 0.67143 |  0:00:04s\n",
      "epoch 48 | loss: 0.77955 | train_accuracy: 0.63963 | valid_accuracy: 0.6517  |  0:00:04s\n",
      "epoch 49 | loss: 0.78046 | train_accuracy: 0.62687 | valid_accuracy: 0.6483  |  0:00:04s\n",
      "epoch 50 | loss: 0.77017 | train_accuracy: 0.65748 | valid_accuracy: 0.66871 |  0:00:04s\n",
      "epoch 51 | loss: 0.7649  | train_accuracy: 0.65867 | valid_accuracy: 0.6619  |  0:00:04s\n",
      "epoch 52 | loss: 0.78074 | train_accuracy: 0.63861 | valid_accuracy: 0.6585  |  0:00:04s\n",
      "epoch 53 | loss: 0.77417 | train_accuracy: 0.65969 | valid_accuracy: 0.67415 |  0:00:05s\n",
      "epoch 54 | loss: 0.7625  | train_accuracy: 0.64439 | valid_accuracy: 0.66735 |  0:00:05s\n",
      "epoch 55 | loss: 0.76684 | train_accuracy: 0.63401 | valid_accuracy: 0.65578 |  0:00:05s\n",
      "epoch 56 | loss: 0.76779 | train_accuracy: 0.6585  | valid_accuracy: 0.67075 |  0:00:05s\n",
      "epoch 57 | loss: 0.77072 | train_accuracy: 0.66003 | valid_accuracy: 0.6585  |  0:00:05s\n",
      "epoch 58 | loss: 0.76995 | train_accuracy: 0.65527 | valid_accuracy: 0.66395 |  0:00:05s\n",
      "epoch 59 | loss: 0.75358 | train_accuracy: 0.65629 | valid_accuracy: 0.6619  |  0:00:05s\n",
      "epoch 60 | loss: 0.76431 | train_accuracy: 0.66684 | valid_accuracy: 0.6585  |  0:00:05s\n",
      "epoch 61 | loss: 0.76021 | train_accuracy: 0.65221 | valid_accuracy: 0.66599 |  0:00:05s\n",
      "epoch 62 | loss: 0.75012 | train_accuracy: 0.67228 | valid_accuracy: 0.66667 |  0:00:05s\n",
      "epoch 63 | loss: 0.75018 | train_accuracy: 0.66105 | valid_accuracy: 0.66259 |  0:00:05s\n",
      "epoch 64 | loss: 0.75549 | train_accuracy: 0.66786 | valid_accuracy: 0.67415 |  0:00:06s\n",
      "epoch 65 | loss: 0.75    | train_accuracy: 0.66922 | valid_accuracy: 0.66599 |  0:00:06s\n",
      "epoch 66 | loss: 0.75302 | train_accuracy: 0.66514 | valid_accuracy: 0.65918 |  0:00:06s\n",
      "epoch 67 | loss: 0.75451 | train_accuracy: 0.67466 | valid_accuracy: 0.68571 |  0:00:06s\n",
      "epoch 68 | loss: 0.75334 | train_accuracy: 0.67075 | valid_accuracy: 0.67823 |  0:00:06s\n",
      "epoch 69 | loss: 0.73638 | train_accuracy: 0.66395 | valid_accuracy: 0.67075 |  0:00:06s\n",
      "epoch 70 | loss: 0.74568 | train_accuracy: 0.68078 | valid_accuracy: 0.67075 |  0:00:06s\n",
      "epoch 71 | loss: 0.74633 | train_accuracy: 0.67262 | valid_accuracy: 0.67619 |  0:00:06s\n",
      "epoch 72 | loss: 0.75209 | train_accuracy: 0.66497 | valid_accuracy: 0.66054 |  0:00:06s\n",
      "epoch 73 | loss: 0.7526  | train_accuracy: 0.67313 | valid_accuracy: 0.66735 |  0:00:06s\n",
      "epoch 74 | loss: 0.74809 | train_accuracy: 0.67585 | valid_accuracy: 0.68231 |  0:00:07s\n",
      "epoch 75 | loss: 0.74267 | train_accuracy: 0.66446 | valid_accuracy: 0.67415 |  0:00:07s\n",
      "epoch 76 | loss: 0.74161 | train_accuracy: 0.66837 | valid_accuracy: 0.66395 |  0:00:07s\n",
      "epoch 77 | loss: 0.73502 | train_accuracy: 0.675   | valid_accuracy: 0.67687 |  0:00:07s\n",
      "epoch 78 | loss: 0.73984 | train_accuracy: 0.68265 | valid_accuracy: 0.68844 |  0:00:07s\n",
      "epoch 79 | loss: 0.7335  | train_accuracy: 0.68146 | valid_accuracy: 0.68299 |  0:00:07s\n",
      "epoch 80 | loss: 0.7397  | train_accuracy: 0.66973 | valid_accuracy: 0.67755 |  0:00:07s\n",
      "epoch 81 | loss: 0.7223  | train_accuracy: 0.68027 | valid_accuracy: 0.68299 |  0:00:07s\n",
      "epoch 82 | loss: 0.72656 | train_accuracy: 0.67721 | valid_accuracy: 0.68844 |  0:00:07s\n",
      "epoch 83 | loss: 0.71814 | train_accuracy: 0.68061 | valid_accuracy: 0.67687 |  0:00:07s\n",
      "epoch 84 | loss: 0.73281 | train_accuracy: 0.68997 | valid_accuracy: 0.68027 |  0:00:07s\n",
      "epoch 85 | loss: 0.72783 | train_accuracy: 0.6869  | valid_accuracy: 0.68095 |  0:00:08s\n",
      "epoch 86 | loss: 0.7297  | train_accuracy: 0.67075 | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 87 | loss: 0.72737 | train_accuracy: 0.68435 | valid_accuracy: 0.6932  |  0:00:08s\n",
      "epoch 88 | loss: 0.73552 | train_accuracy: 0.68929 | valid_accuracy: 0.68095 |  0:00:08s\n",
      "epoch 89 | loss: 0.72832 | train_accuracy: 0.67517 | valid_accuracy: 0.66259 |  0:00:08s\n",
      "epoch 90 | loss: 0.72246 | train_accuracy: 0.68469 | valid_accuracy: 0.68367 |  0:00:08s\n",
      "epoch 91 | loss: 0.716   | train_accuracy: 0.68895 | valid_accuracy: 0.69796 |  0:00:08s\n",
      "epoch 92 | loss: 0.72156 | train_accuracy: 0.68401 | valid_accuracy: 0.69388 |  0:00:08s\n",
      "epoch 93 | loss: 0.70686 | train_accuracy: 0.69014 | valid_accuracy: 0.69184 |  0:00:08s\n",
      "epoch 94 | loss: 0.72177 | train_accuracy: 0.69609 | valid_accuracy: 0.67755 |  0:00:08s\n",
      "epoch 95 | loss: 0.72849 | train_accuracy: 0.6869  | valid_accuracy: 0.67483 |  0:00:09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96 | loss: 0.72823 | train_accuracy: 0.67364 | valid_accuracy: 0.67483 |  0:00:09s\n",
      "epoch 97 | loss: 0.7028  | train_accuracy: 0.68793 | valid_accuracy: 0.6619  |  0:00:09s\n",
      "epoch 98 | loss: 0.73194 | train_accuracy: 0.66224 | valid_accuracy: 0.65306 |  0:00:09s\n",
      "epoch 99 | loss: 0.71242 | train_accuracy: 0.67874 | valid_accuracy: 0.69048 |  0:00:09s\n",
      "epoch 100| loss: 0.71678 | train_accuracy: 0.67908 | valid_accuracy: 0.68571 |  0:00:09s\n",
      "epoch 101| loss: 0.6995  | train_accuracy: 0.69235 | valid_accuracy: 0.69456 |  0:00:09s\n",
      "epoch 102| loss: 0.69997 | train_accuracy: 0.70102 | valid_accuracy: 0.6966  |  0:00:09s\n",
      "epoch 103| loss: 0.72596 | train_accuracy: 0.68963 | valid_accuracy: 0.68299 |  0:00:09s\n",
      "epoch 104| loss: 0.70917 | train_accuracy: 0.68112 | valid_accuracy: 0.67347 |  0:00:09s\n",
      "epoch 105| loss: 0.69873 | train_accuracy: 0.68741 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 106| loss: 0.70337 | train_accuracy: 0.70102 | valid_accuracy: 0.69116 |  0:00:10s\n",
      "epoch 107| loss: 0.69859 | train_accuracy: 0.69932 | valid_accuracy: 0.68503 |  0:00:10s\n",
      "epoch 108| loss: 0.70462 | train_accuracy: 0.70136 | valid_accuracy: 0.68912 |  0:00:10s\n",
      "epoch 109| loss: 0.71234 | train_accuracy: 0.70136 | valid_accuracy: 0.6966  |  0:00:10s\n",
      "epoch 110| loss: 0.70209 | train_accuracy: 0.70612 | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 111| loss: 0.70734 | train_accuracy: 0.69626 | valid_accuracy: 0.67619 |  0:00:10s\n",
      "epoch 112| loss: 0.70415 | train_accuracy: 0.70952 | valid_accuracy: 0.69388 |  0:00:10s\n",
      "epoch 113| loss: 0.70653 | train_accuracy: 0.69932 | valid_accuracy: 0.69252 |  0:00:10s\n",
      "epoch 114| loss: 0.69877 | train_accuracy: 0.69983 | valid_accuracy: 0.69048 |  0:00:10s\n",
      "epoch 115| loss: 0.6972  | train_accuracy: 0.70595 | valid_accuracy: 0.70204 |  0:00:10s\n",
      "epoch 116| loss: 0.6854  | train_accuracy: 0.69813 | valid_accuracy: 0.69252 |  0:00:11s\n",
      "epoch 117| loss: 0.70623 | train_accuracy: 0.70204 | valid_accuracy: 0.6898  |  0:00:11s\n",
      "epoch 118| loss: 0.69286 | train_accuracy: 0.70306 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 119| loss: 0.68525 | train_accuracy: 0.72432 | valid_accuracy: 0.70136 |  0:00:11s\n",
      "epoch 120| loss: 0.70037 | train_accuracy: 0.69558 | valid_accuracy: 0.67891 |  0:00:11s\n",
      "epoch 121| loss: 0.69177 | train_accuracy: 0.70136 | valid_accuracy: 0.6932  |  0:00:11s\n",
      "epoch 122| loss: 0.69229 | train_accuracy: 0.69898 | valid_accuracy: 0.68299 |  0:00:11s\n",
      "epoch 123| loss: 0.68325 | train_accuracy: 0.7068  | valid_accuracy: 0.68095 |  0:00:11s\n",
      "epoch 124| loss: 0.68762 | train_accuracy: 0.71241 | valid_accuracy: 0.69864 |  0:00:11s\n",
      "epoch 125| loss: 0.68384 | train_accuracy: 0.71412 | valid_accuracy: 0.69388 |  0:00:11s\n",
      "epoch 126| loss: 0.68418 | train_accuracy: 0.70833 | valid_accuracy: 0.70408 |  0:00:11s\n",
      "epoch 127| loss: 0.69687 | train_accuracy: 0.7034  | valid_accuracy: 0.69388 |  0:00:12s\n",
      "epoch 128| loss: 0.69293 | train_accuracy: 0.70663 | valid_accuracy: 0.7     |  0:00:12s\n",
      "epoch 129| loss: 0.67165 | train_accuracy: 0.70799 | valid_accuracy: 0.69796 |  0:00:12s\n",
      "epoch 130| loss: 0.68036 | train_accuracy: 0.71037 | valid_accuracy: 0.70816 |  0:00:12s\n",
      "epoch 131| loss: 0.68229 | train_accuracy: 0.70136 | valid_accuracy: 0.6932  |  0:00:12s\n",
      "epoch 132| loss: 0.69585 | train_accuracy: 0.69014 | valid_accuracy: 0.67415 |  0:00:12s\n",
      "epoch 133| loss: 0.68014 | train_accuracy: 0.68793 | valid_accuracy: 0.68027 |  0:00:12s\n",
      "epoch 134| loss: 0.68824 | train_accuracy: 0.70459 | valid_accuracy: 0.70068 |  0:00:12s\n",
      "epoch 135| loss: 0.67856 | train_accuracy: 0.70901 | valid_accuracy: 0.69932 |  0:00:12s\n",
      "epoch 136| loss: 0.68705 | train_accuracy: 0.71395 | valid_accuracy: 0.69456 |  0:00:12s\n",
      "epoch 137| loss: 0.69097 | train_accuracy: 0.71735 | valid_accuracy: 0.70136 |  0:00:12s\n",
      "epoch 138| loss: 0.66959 | train_accuracy: 0.70697 | valid_accuracy: 0.68571 |  0:00:13s\n",
      "epoch 139| loss: 0.6957  | train_accuracy: 0.70918 | valid_accuracy: 0.68095 |  0:00:13s\n",
      "epoch 140| loss: 0.6821  | train_accuracy: 0.72483 | valid_accuracy: 0.69864 |  0:00:13s\n",
      "epoch 141| loss: 0.68127 | train_accuracy: 0.72041 | valid_accuracy: 0.70748 |  0:00:13s\n",
      "epoch 142| loss: 0.67355 | train_accuracy: 0.72806 | valid_accuracy: 0.71429 |  0:00:13s\n",
      "epoch 143| loss: 0.67225 | train_accuracy: 0.72007 | valid_accuracy: 0.69796 |  0:00:13s\n",
      "epoch 144| loss: 0.66875 | train_accuracy: 0.71803 | valid_accuracy: 0.69456 |  0:00:13s\n",
      "epoch 145| loss: 0.67671 | train_accuracy: 0.71871 | valid_accuracy: 0.7068  |  0:00:13s\n",
      "epoch 146| loss: 0.66122 | train_accuracy: 0.71769 | valid_accuracy: 0.70544 |  0:00:13s\n",
      "epoch 147| loss: 0.6755  | train_accuracy: 0.71378 | valid_accuracy: 0.7068  |  0:00:13s\n",
      "epoch 148| loss: 0.67187 | train_accuracy: 0.72313 | valid_accuracy: 0.71156 |  0:00:13s\n",
      "epoch 149| loss: 0.67601 | train_accuracy: 0.72126 | valid_accuracy: 0.70544 |  0:00:14s\n",
      "epoch 150| loss: 0.67938 | train_accuracy: 0.71803 | valid_accuracy: 0.69184 |  0:00:14s\n",
      "epoch 151| loss: 0.66364 | train_accuracy: 0.71973 | valid_accuracy: 0.70204 |  0:00:14s\n",
      "epoch 152| loss: 0.6513  | train_accuracy: 0.7131  | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 153| loss: 0.66936 | train_accuracy: 0.71718 | valid_accuracy: 0.69864 |  0:00:14s\n",
      "epoch 154| loss: 0.6607  | train_accuracy: 0.72075 | valid_accuracy: 0.69864 |  0:00:14s\n",
      "epoch 155| loss: 0.66062 | train_accuracy: 0.72143 | valid_accuracy: 0.69728 |  0:00:14s\n",
      "epoch 156| loss: 0.67371 | train_accuracy: 0.71327 | valid_accuracy: 0.69592 |  0:00:14s\n",
      "epoch 157| loss: 0.67578 | train_accuracy: 0.72653 | valid_accuracy: 0.70816 |  0:00:14s\n",
      "epoch 158| loss: 0.6687  | train_accuracy: 0.72024 | valid_accuracy: 0.7068  |  0:00:14s\n",
      "epoch 159| loss: 0.67012 | train_accuracy: 0.72432 | valid_accuracy: 0.70272 |  0:00:15s\n",
      "epoch 160| loss: 0.65796 | train_accuracy: 0.72585 | valid_accuracy: 0.7068  |  0:00:15s\n",
      "epoch 161| loss: 0.6724  | train_accuracy: 0.72194 | valid_accuracy: 0.7034  |  0:00:15s\n",
      "epoch 162| loss: 0.68397 | train_accuracy: 0.71105 | valid_accuracy: 0.68844 |  0:00:15s\n",
      "epoch 163| loss: 0.66335 | train_accuracy: 0.71633 | valid_accuracy: 0.69116 |  0:00:15s\n",
      "epoch 164| loss: 0.67116 | train_accuracy: 0.72194 | valid_accuracy: 0.70748 |  0:00:15s\n",
      "epoch 165| loss: 0.64854 | train_accuracy: 0.72041 | valid_accuracy: 0.70476 |  0:00:15s\n",
      "epoch 166| loss: 0.66246 | train_accuracy: 0.72024 | valid_accuracy: 0.70136 |  0:00:15s\n",
      "epoch 167| loss: 0.65984 | train_accuracy: 0.71497 | valid_accuracy: 0.70544 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 167 with best_epoch = 142 and best_valid_accuracy = 0.71429\n",
      "165\n",
      "142\n",
      "Fold 1: Train Accuracy=0.7364, Valid Accuracy=0.6925, Epoch = 223\n",
      "Fold 2: Train Accuracy=0.7277, Valid Accuracy=0.7122, Epoch = 147\n",
      "Fold 3: Train Accuracy=0.7304, Valid Accuracy=0.7075, Epoch = 218\n",
      "Fold 4: Train Accuracy=0.7638, Valid Accuracy=0.7109, Epoch = 216\n",
      "Fold 5: Train Accuracy=0.7204, Valid Accuracy=0.7048, Epoch = 165\n",
      "Mean Train Accuracy=0.7357, Mean Valid Accuracy=0.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_tabnet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 데이터를 나누기 위한 K 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "best_train_accuracies = []\n",
    "best_valid_accuracies = []\n",
    "\n",
    "epoch_idx = []\n",
    "\n",
    "dict_train = {}\n",
    "dict_val = {}\n",
    "\n",
    "keys = 0\n",
    "\n",
    "# K-fold 교차 검증 반복\n",
    "for train_idx, val_idx in kf.split(x_train_50):\n",
    "    X_train_fold, X_val_fold = x_train_50[train_idx], x_train_50[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_50[train_idx], y_train_50[val_idx]\n",
    "    \n",
    "    # 모델 초기화\n",
    "    clf = TabNetClassifier(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=3e-2),\n",
    "        scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type='sparsemax'\n",
    "    )\n",
    "\n",
    "    # 모델 학습\n",
    "    clf.fit(\n",
    "        X_train=X_train_fold, y_train=y_train_fold,\n",
    "        eval_set=[(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=1000, patience=25,\n",
    "        from_unsupervised=unsupervised_model\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 가장 작은 loss 를 기준으로 train accuracy, valid accuracy 값 저장\n",
    "    best_idx =clf.history['loss'].index(min(clf.history['loss']))\n",
    "    best_train_accuracy = clf.history['train_accuracy'][best_idx]\n",
    "    best_valid_accuracy = clf.history['valid_accuracy'][best_idx]\n",
    "    best_train_accuracies.append(best_train_accuracy)\n",
    "    best_valid_accuracies.append(best_valid_accuracy)\n",
    "    \n",
    "    # 폴드별 train accuracy와 valid accuracy 기록\n",
    "    train_accuracies.append(clf.history['train_accuracy'][best_idx])\n",
    "    valid_accuracies.append(clf.history['valid_accuracy'][best_idx])\n",
    "    \n",
    "    \n",
    "    # fold 별 train, valid accuracy 평균으로 plot 을 위함\n",
    "    dict_train[keys] = clf.history['train_accuracy']\n",
    "    dict_val[keys] = clf.history['valid_accuracy']\n",
    "    keys +=1\n",
    "    \n",
    "    print(clf.history['loss'].index(min(clf.history['loss'])))\n",
    "    print(clf.history['valid_accuracy'].index(max(clf.history['valid_accuracy'])))\n",
    "    \n",
    "    epoch_idx.append(best_idx)\n",
    "    \n",
    "# 폴드별 best train accuracy와 valid accuracy 출력\n",
    "for i, (train_acc, valid_acc) in enumerate(zip(best_train_accuracies, best_valid_accuracies)):\n",
    "    print(f\"Fold {i+1}: Train Accuracy={train_acc:.4f}, Valid Accuracy={valid_acc:.4f}, Epoch = {epoch_idx[i]}\")\n",
    "\n",
    "# Train accuracy와 valid accuracy의 평균 계산\n",
    "mean_train_accuracy = np.mean(best_train_accuracies)\n",
    "mean_valid_accuracy = np.mean(best_valid_accuracies)\n",
    "\n",
    "print(f\"Mean Train Accuracy={mean_train_accuracy:.4f}, Mean Valid Accuracy={mean_valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f3a5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on validation set: 0.7142857142857143\n",
      "Accuracy score on test set:  0.6361720067453626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69       823\n",
      "           1       0.47      0.57      0.52       629\n",
      "           2       0.73      0.48      0.58       504\n",
      "           3       0.82      0.75      0.78       416\n",
      "\n",
      "    accuracy                           0.64      2372\n",
      "   macro avg       0.67      0.63      0.64      2372\n",
      "weighted avg       0.65      0.64      0.64      2372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "K-Fold 는 알아서 train val 을 나눠준다. \n",
    "따라서, 우리는 test랑 k-fold 에서 나눠준 validation set이랑 비교하면 된다.\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = clf.predict(x_test)\n",
    "test_acc = accuracy_score(preds, y_test)\n",
    "\n",
    "preds_valid = clf.predict(X_val_fold)\n",
    "valid_acc = accuracy_score(preds_valid, y_val_fold)\n",
    "\n",
    "print(\"Accuracy score on validation set:\", valid_acc)\n",
    "print(\"Accuracy score on test set: \",test_acc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71f0bf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(clf.feature_importances_, index=train_ecs.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ec5a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "위치 경도 좌표 제거 o \n",
    "'''\n",
    "# 비지도 학습 전 전처리 (dtype object remove)\n",
    "sample_size = round(len(ecs)*0.5)  # 2:1 비율\n",
    "x_train = collison.sample(n = sample_size, random_state = 42)\n",
    "\n",
    "# collison feature 선별\n",
    "x_train = x_train[['dOsCPADist','dTsCPADist', 'dOsRisk', 'dTsCPADist', 'dTsRisk',\n",
    "                 'izCategory','dDCPA', 'dTCPA', 'RNG', 'MaxRisk']]\n",
    "x_train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "x_train.to_csv('test1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39a361a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.64372 | train_accuracy: 0.37092 | valid_accuracy: 0.34218 |  0:00:00s\n",
      "epoch 1  | loss: 1.18977 | train_accuracy: 0.45595 | valid_accuracy: 0.43537 |  0:00:00s\n",
      "epoch 2  | loss: 1.08933 | train_accuracy: 0.45612 | valid_accuracy: 0.41769 |  0:00:00s\n",
      "epoch 3  | loss: 1.01931 | train_accuracy: 0.4267  | valid_accuracy: 0.3932  |  0:00:00s\n",
      "epoch 4  | loss: 0.97044 | train_accuracy: 0.37993 | valid_accuracy: 0.36803 |  0:00:00s\n",
      "epoch 5  | loss: 0.95161 | train_accuracy: 0.36616 | valid_accuracy: 0.36803 |  0:00:00s\n",
      "epoch 6  | loss: 0.94008 | train_accuracy: 0.41854 | valid_accuracy: 0.43061 |  0:00:00s\n",
      "epoch 7  | loss: 0.92132 | train_accuracy: 0.42874 | valid_accuracy: 0.44898 |  0:00:00s\n",
      "epoch 8  | loss: 0.89409 | train_accuracy: 0.44439 | valid_accuracy: 0.45442 |  0:00:00s\n",
      "epoch 9  | loss: 0.90106 | train_accuracy: 0.44796 | valid_accuracy: 0.46054 |  0:00:01s\n",
      "epoch 10 | loss: 0.88269 | train_accuracy: 0.38622 | valid_accuracy: 0.4034  |  0:00:01s\n",
      "epoch 11 | loss: 0.88464 | train_accuracy: 0.4301  | valid_accuracy: 0.44082 |  0:00:01s\n",
      "epoch 12 | loss: 0.87231 | train_accuracy: 0.40493 | valid_accuracy: 0.39728 |  0:00:01s\n",
      "epoch 13 | loss: 0.86601 | train_accuracy: 0.42347 | valid_accuracy: 0.41905 |  0:00:01s\n",
      "epoch 14 | loss: 0.86956 | train_accuracy: 0.41105 | valid_accuracy: 0.39524 |  0:00:01s\n",
      "epoch 15 | loss: 0.85597 | train_accuracy: 0.38537 | valid_accuracy: 0.37415 |  0:00:01s\n",
      "epoch 16 | loss: 0.84875 | train_accuracy: 0.37687 | valid_accuracy: 0.37279 |  0:00:01s\n",
      "epoch 17 | loss: 0.84033 | train_accuracy: 0.35255 | valid_accuracy: 0.35102 |  0:00:01s\n",
      "epoch 18 | loss: 0.82648 | train_accuracy: 0.38367 | valid_accuracy: 0.38912 |  0:00:01s\n",
      "epoch 19 | loss: 0.82858 | train_accuracy: 0.36361 | valid_accuracy: 0.37415 |  0:00:01s\n",
      "epoch 20 | loss: 0.82455 | train_accuracy: 0.37483 | valid_accuracy: 0.38435 |  0:00:02s\n",
      "epoch 21 | loss: 0.81918 | train_accuracy: 0.35731 | valid_accuracy: 0.36054 |  0:00:02s\n",
      "epoch 22 | loss: 0.81411 | train_accuracy: 0.37942 | valid_accuracy: 0.37687 |  0:00:02s\n",
      "epoch 23 | loss: 0.82784 | train_accuracy: 0.39762 | valid_accuracy: 0.38912 |  0:00:02s\n",
      "epoch 24 | loss: 0.82135 | train_accuracy: 0.44609 | valid_accuracy: 0.43946 |  0:00:02s\n",
      "epoch 25 | loss: 0.82865 | train_accuracy: 0.47194 | valid_accuracy: 0.45578 |  0:00:02s\n",
      "epoch 26 | loss: 0.8103  | train_accuracy: 0.46888 | valid_accuracy: 0.4585  |  0:00:02s\n",
      "epoch 27 | loss: 0.81768 | train_accuracy: 0.49643 | valid_accuracy: 0.47619 |  0:00:02s\n",
      "epoch 28 | loss: 0.81558 | train_accuracy: 0.49898 | valid_accuracy: 0.48231 |  0:00:02s\n",
      "epoch 29 | loss: 0.7975  | train_accuracy: 0.5119  | valid_accuracy: 0.48844 |  0:00:02s\n",
      "epoch 30 | loss: 0.80686 | train_accuracy: 0.54779 | valid_accuracy: 0.53061 |  0:00:02s\n",
      "epoch 31 | loss: 0.80144 | train_accuracy: 0.53673 | valid_accuracy: 0.51224 |  0:00:03s\n",
      "epoch 32 | loss: 0.79259 | train_accuracy: 0.54473 | valid_accuracy: 0.52721 |  0:00:03s\n",
      "epoch 33 | loss: 0.79901 | train_accuracy: 0.54286 | valid_accuracy: 0.51565 |  0:00:03s\n",
      "epoch 34 | loss: 0.78384 | train_accuracy: 0.55493 | valid_accuracy: 0.52585 |  0:00:03s\n",
      "epoch 35 | loss: 0.79284 | train_accuracy: 0.58707 | valid_accuracy: 0.56054 |  0:00:03s\n",
      "epoch 36 | loss: 0.77993 | train_accuracy: 0.5551  | valid_accuracy: 0.52041 |  0:00:03s\n",
      "epoch 37 | loss: 0.79082 | train_accuracy: 0.54439 | valid_accuracy: 0.51361 |  0:00:03s\n",
      "epoch 38 | loss: 0.77836 | train_accuracy: 0.5881  | valid_accuracy: 0.55442 |  0:00:03s\n",
      "epoch 39 | loss: 0.78786 | train_accuracy: 0.58112 | valid_accuracy: 0.5551  |  0:00:03s\n",
      "epoch 40 | loss: 0.77824 | train_accuracy: 0.5869  | valid_accuracy: 0.5517  |  0:00:03s\n",
      "epoch 41 | loss: 0.78125 | train_accuracy: 0.61939 | valid_accuracy: 0.58027 |  0:00:04s\n",
      "epoch 42 | loss: 0.77311 | train_accuracy: 0.56531 | valid_accuracy: 0.52585 |  0:00:04s\n",
      "epoch 43 | loss: 0.78015 | train_accuracy: 0.62075 | valid_accuracy: 0.58299 |  0:00:04s\n",
      "epoch 44 | loss: 0.77315 | train_accuracy: 0.60952 | valid_accuracy: 0.58503 |  0:00:04s\n",
      "epoch 45 | loss: 0.76574 | train_accuracy: 0.58078 | valid_accuracy: 0.5449  |  0:00:04s\n",
      "epoch 46 | loss: 0.78344 | train_accuracy: 0.61207 | valid_accuracy: 0.5898  |  0:00:04s\n",
      "epoch 47 | loss: 0.77895 | train_accuracy: 0.61684 | valid_accuracy: 0.58844 |  0:00:04s\n",
      "epoch 48 | loss: 0.78219 | train_accuracy: 0.59677 | valid_accuracy: 0.56871 |  0:00:04s\n",
      "epoch 49 | loss: 0.81644 | train_accuracy: 0.61837 | valid_accuracy: 0.58027 |  0:00:04s\n",
      "epoch 50 | loss: 0.80177 | train_accuracy: 0.59065 | valid_accuracy: 0.57687 |  0:00:04s\n",
      "epoch 51 | loss: 0.7865  | train_accuracy: 0.63861 | valid_accuracy: 0.61973 |  0:00:04s\n",
      "epoch 52 | loss: 0.77246 | train_accuracy: 0.63418 | valid_accuracy: 0.59456 |  0:00:05s\n",
      "epoch 53 | loss: 0.7831  | train_accuracy: 0.64983 | valid_accuracy: 0.61429 |  0:00:05s\n",
      "epoch 54 | loss: 0.76826 | train_accuracy: 0.6517  | valid_accuracy: 0.62517 |  0:00:05s\n",
      "epoch 55 | loss: 0.77337 | train_accuracy: 0.65901 | valid_accuracy: 0.62585 |  0:00:05s\n",
      "epoch 56 | loss: 0.7603  | train_accuracy: 0.6381  | valid_accuracy: 0.60612 |  0:00:05s\n",
      "epoch 57 | loss: 0.7536  | train_accuracy: 0.65102 | valid_accuracy: 0.63129 |  0:00:05s\n",
      "epoch 58 | loss: 0.75607 | train_accuracy: 0.63503 | valid_accuracy: 0.60884 |  0:00:05s\n",
      "epoch 59 | loss: 0.75324 | train_accuracy: 0.66276 | valid_accuracy: 0.6381  |  0:00:05s\n",
      "epoch 60 | loss: 0.75786 | train_accuracy: 0.65119 | valid_accuracy: 0.63333 |  0:00:05s\n",
      "epoch 61 | loss: 0.75973 | train_accuracy: 0.64405 | valid_accuracy: 0.62449 |  0:00:05s\n",
      "epoch 62 | loss: 0.75618 | train_accuracy: 0.66088 | valid_accuracy: 0.6381  |  0:00:05s\n",
      "epoch 63 | loss: 0.75649 | train_accuracy: 0.65374 | valid_accuracy: 0.62993 |  0:00:06s\n",
      "epoch 64 | loss: 0.75821 | train_accuracy: 0.65272 | valid_accuracy: 0.62517 |  0:00:06s\n",
      "epoch 65 | loss: 0.75454 | train_accuracy: 0.67058 | valid_accuracy: 0.64354 |  0:00:06s\n",
      "epoch 66 | loss: 0.754   | train_accuracy: 0.63929 | valid_accuracy: 0.61497 |  0:00:06s\n",
      "epoch 67 | loss: 0.74073 | train_accuracy: 0.67262 | valid_accuracy: 0.65102 |  0:00:06s\n",
      "epoch 68 | loss: 0.73629 | train_accuracy: 0.6733  | valid_accuracy: 0.64966 |  0:00:06s\n",
      "epoch 69 | loss: 0.74811 | train_accuracy: 0.65901 | valid_accuracy: 0.63469 |  0:00:06s\n",
      "epoch 70 | loss: 0.73451 | train_accuracy: 0.6716  | valid_accuracy: 0.63469 |  0:00:06s\n",
      "epoch 71 | loss: 0.74574 | train_accuracy: 0.65731 | valid_accuracy: 0.63469 |  0:00:06s\n",
      "epoch 72 | loss: 0.74203 | train_accuracy: 0.65748 | valid_accuracy: 0.62857 |  0:00:06s\n",
      "epoch 73 | loss: 0.72975 | train_accuracy: 0.67619 | valid_accuracy: 0.65714 |  0:00:06s\n",
      "epoch 74 | loss: 0.7383  | train_accuracy: 0.65748 | valid_accuracy: 0.62449 |  0:00:07s\n",
      "epoch 75 | loss: 0.72626 | train_accuracy: 0.68044 | valid_accuracy: 0.65238 |  0:00:07s\n",
      "epoch 76 | loss: 0.72307 | train_accuracy: 0.67449 | valid_accuracy: 0.64558 |  0:00:07s\n",
      "epoch 77 | loss: 0.73599 | train_accuracy: 0.67211 | valid_accuracy: 0.65306 |  0:00:07s\n",
      "epoch 78 | loss: 0.72195 | train_accuracy: 0.67772 | valid_accuracy: 0.64626 |  0:00:07s\n",
      "epoch 79 | loss: 0.71947 | train_accuracy: 0.67789 | valid_accuracy: 0.6483  |  0:00:07s\n",
      "epoch 80 | loss: 0.73498 | train_accuracy: 0.66565 | valid_accuracy: 0.63946 |  0:00:07s\n",
      "epoch 81 | loss: 0.72261 | train_accuracy: 0.67976 | valid_accuracy: 0.64558 |  0:00:07s\n",
      "epoch 82 | loss: 0.71728 | train_accuracy: 0.67126 | valid_accuracy: 0.63946 |  0:00:07s\n",
      "epoch 83 | loss: 0.73156 | train_accuracy: 0.68571 | valid_accuracy: 0.65986 |  0:00:07s\n",
      "epoch 84 | loss: 0.71226 | train_accuracy: 0.67194 | valid_accuracy: 0.63946 |  0:00:08s\n",
      "epoch 85 | loss: 0.72447 | train_accuracy: 0.67347 | valid_accuracy: 0.64626 |  0:00:08s\n",
      "epoch 86 | loss: 0.71896 | train_accuracy: 0.69065 | valid_accuracy: 0.65238 |  0:00:08s\n",
      "epoch 87 | loss: 0.71415 | train_accuracy: 0.68129 | valid_accuracy: 0.64218 |  0:00:08s\n",
      "epoch 88 | loss: 0.72015 | train_accuracy: 0.6932  | valid_accuracy: 0.65918 |  0:00:08s\n",
      "epoch 89 | loss: 0.71895 | train_accuracy: 0.68044 | valid_accuracy: 0.65306 |  0:00:08s\n",
      "epoch 90 | loss: 0.72437 | train_accuracy: 0.68639 | valid_accuracy: 0.65442 |  0:00:08s\n",
      "epoch 91 | loss: 0.72512 | train_accuracy: 0.67109 | valid_accuracy: 0.62789 |  0:00:08s\n",
      "epoch 92 | loss: 0.7278  | train_accuracy: 0.69014 | valid_accuracy: 0.65374 |  0:00:08s\n",
      "epoch 93 | loss: 0.72416 | train_accuracy: 0.68639 | valid_accuracy: 0.65306 |  0:00:08s\n",
      "epoch 94 | loss: 0.7006  | train_accuracy: 0.68895 | valid_accuracy: 0.65578 |  0:00:09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 | loss: 0.71583 | train_accuracy: 0.69218 | valid_accuracy: 0.65306 |  0:00:09s\n",
      "epoch 96 | loss: 0.71987 | train_accuracy: 0.69915 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 97 | loss: 0.71025 | train_accuracy: 0.68452 | valid_accuracy: 0.65782 |  0:00:09s\n",
      "epoch 98 | loss: 0.71131 | train_accuracy: 0.68078 | valid_accuracy: 0.65442 |  0:00:09s\n",
      "epoch 99 | loss: 0.71572 | train_accuracy: 0.67857 | valid_accuracy: 0.65306 |  0:00:09s\n",
      "epoch 100| loss: 0.70531 | train_accuracy: 0.70204 | valid_accuracy: 0.67143 |  0:00:09s\n",
      "epoch 101| loss: 0.72718 | train_accuracy: 0.69507 | valid_accuracy: 0.66735 |  0:00:09s\n",
      "epoch 102| loss: 0.70858 | train_accuracy: 0.69218 | valid_accuracy: 0.66531 |  0:00:09s\n",
      "epoch 103| loss: 0.69601 | train_accuracy: 0.70221 | valid_accuracy: 0.66395 |  0:00:09s\n",
      "epoch 104| loss: 0.70941 | train_accuracy: 0.70272 | valid_accuracy: 0.66803 |  0:00:09s\n",
      "epoch 105| loss: 0.70162 | train_accuracy: 0.69405 | valid_accuracy: 0.6619  |  0:00:10s\n",
      "epoch 106| loss: 0.71517 | train_accuracy: 0.69439 | valid_accuracy: 0.66939 |  0:00:10s\n",
      "epoch 107| loss: 0.70484 | train_accuracy: 0.6835  | valid_accuracy: 0.64626 |  0:00:10s\n",
      "epoch 108| loss: 0.69794 | train_accuracy: 0.70051 | valid_accuracy: 0.67143 |  0:00:10s\n",
      "epoch 109| loss: 0.71307 | train_accuracy: 0.68997 | valid_accuracy: 0.65374 |  0:00:10s\n",
      "epoch 110| loss: 0.69285 | train_accuracy: 0.70085 | valid_accuracy: 0.67551 |  0:00:10s\n",
      "epoch 111| loss: 0.70269 | train_accuracy: 0.70493 | valid_accuracy: 0.66531 |  0:00:10s\n",
      "epoch 112| loss: 0.69313 | train_accuracy: 0.69575 | valid_accuracy: 0.65646 |  0:00:10s\n",
      "epoch 113| loss: 0.70116 | train_accuracy: 0.70289 | valid_accuracy: 0.67347 |  0:00:10s\n",
      "epoch 114| loss: 0.70178 | train_accuracy: 0.70969 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 115| loss: 0.69373 | train_accuracy: 0.70068 | valid_accuracy: 0.67755 |  0:00:10s\n",
      "epoch 116| loss: 0.71207 | train_accuracy: 0.69932 | valid_accuracy: 0.66871 |  0:00:11s\n",
      "epoch 117| loss: 0.70899 | train_accuracy: 0.6983  | valid_accuracy: 0.6517  |  0:00:11s\n",
      "epoch 118| loss: 0.70058 | train_accuracy: 0.6949  | valid_accuracy: 0.66395 |  0:00:11s\n",
      "epoch 119| loss: 0.71108 | train_accuracy: 0.68912 | valid_accuracy: 0.67755 |  0:00:11s\n",
      "epoch 120| loss: 0.70438 | train_accuracy: 0.70884 | valid_accuracy: 0.67687 |  0:00:11s\n",
      "epoch 121| loss: 0.70117 | train_accuracy: 0.70663 | valid_accuracy: 0.67143 |  0:00:11s\n",
      "epoch 122| loss: 0.70918 | train_accuracy: 0.70442 | valid_accuracy: 0.65646 |  0:00:11s\n",
      "epoch 123| loss: 0.69076 | train_accuracy: 0.70187 | valid_accuracy: 0.66667 |  0:00:11s\n",
      "epoch 124| loss: 0.6918  | train_accuracy: 0.71003 | valid_accuracy: 0.67619 |  0:00:11s\n",
      "epoch 125| loss: 0.68113 | train_accuracy: 0.70833 | valid_accuracy: 0.67211 |  0:00:11s\n",
      "epoch 126| loss: 0.70357 | train_accuracy: 0.71241 | valid_accuracy: 0.67075 |  0:00:11s\n",
      "epoch 127| loss: 0.68359 | train_accuracy: 0.70017 | valid_accuracy: 0.66463 |  0:00:12s\n",
      "epoch 128| loss: 0.68427 | train_accuracy: 0.70068 | valid_accuracy: 0.67143 |  0:00:12s\n",
      "epoch 129| loss: 0.6933  | train_accuracy: 0.7051  | valid_accuracy: 0.6619  |  0:00:12s\n",
      "epoch 130| loss: 0.68551 | train_accuracy: 0.69762 | valid_accuracy: 0.66667 |  0:00:12s\n",
      "epoch 131| loss: 0.69803 | train_accuracy: 0.71378 | valid_accuracy: 0.67959 |  0:00:12s\n",
      "epoch 132| loss: 0.67592 | train_accuracy: 0.71684 | valid_accuracy: 0.67823 |  0:00:12s\n",
      "epoch 133| loss: 0.67691 | train_accuracy: 0.71361 | valid_accuracy: 0.67279 |  0:00:12s\n",
      "epoch 134| loss: 0.68804 | train_accuracy: 0.72177 | valid_accuracy: 0.68027 |  0:00:12s\n",
      "epoch 135| loss: 0.6868  | train_accuracy: 0.70816 | valid_accuracy: 0.66735 |  0:00:12s\n",
      "epoch 136| loss: 0.69374 | train_accuracy: 0.70595 | valid_accuracy: 0.66327 |  0:00:12s\n",
      "epoch 137| loss: 0.67273 | train_accuracy: 0.7233  | valid_accuracy: 0.69048 |  0:00:13s\n",
      "epoch 138| loss: 0.68863 | train_accuracy: 0.7102  | valid_accuracy: 0.66803 |  0:00:13s\n",
      "epoch 139| loss: 0.69888 | train_accuracy: 0.71224 | valid_accuracy: 0.67279 |  0:00:13s\n",
      "epoch 140| loss: 0.68455 | train_accuracy: 0.71241 | valid_accuracy: 0.67619 |  0:00:13s\n",
      "epoch 141| loss: 0.67885 | train_accuracy: 0.71616 | valid_accuracy: 0.66735 |  0:00:13s\n",
      "epoch 142| loss: 0.67838 | train_accuracy: 0.71752 | valid_accuracy: 0.67415 |  0:00:13s\n",
      "epoch 143| loss: 0.68072 | train_accuracy: 0.7165  | valid_accuracy: 0.67415 |  0:00:13s\n",
      "epoch 144| loss: 0.68278 | train_accuracy: 0.71769 | valid_accuracy: 0.68367 |  0:00:13s\n",
      "epoch 145| loss: 0.67005 | train_accuracy: 0.71139 | valid_accuracy: 0.67211 |  0:00:13s\n",
      "epoch 146| loss: 0.67451 | train_accuracy: 0.71684 | valid_accuracy: 0.67755 |  0:00:13s\n",
      "epoch 147| loss: 0.68654 | train_accuracy: 0.72585 | valid_accuracy: 0.69048 |  0:00:13s\n",
      "epoch 148| loss: 0.67624 | train_accuracy: 0.70646 | valid_accuracy: 0.67143 |  0:00:14s\n",
      "epoch 149| loss: 0.67638 | train_accuracy: 0.69711 | valid_accuracy: 0.67143 |  0:00:14s\n",
      "epoch 150| loss: 0.66884 | train_accuracy: 0.72262 | valid_accuracy: 0.69184 |  0:00:14s\n",
      "epoch 151| loss: 0.67506 | train_accuracy: 0.72024 | valid_accuracy: 0.68163 |  0:00:14s\n",
      "epoch 152| loss: 0.66034 | train_accuracy: 0.71769 | valid_accuracy: 0.68367 |  0:00:14s\n",
      "epoch 153| loss: 0.67399 | train_accuracy: 0.72687 | valid_accuracy: 0.68435 |  0:00:14s\n",
      "epoch 154| loss: 0.65905 | train_accuracy: 0.71565 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 155| loss: 0.6644  | train_accuracy: 0.71446 | valid_accuracy: 0.68163 |  0:00:14s\n",
      "epoch 156| loss: 0.67986 | train_accuracy: 0.71054 | valid_accuracy: 0.67891 |  0:00:14s\n",
      "epoch 157| loss: 0.68807 | train_accuracy: 0.72517 | valid_accuracy: 0.68844 |  0:00:14s\n",
      "epoch 158| loss: 0.6702  | train_accuracy: 0.7131  | valid_accuracy: 0.67959 |  0:00:14s\n",
      "epoch 159| loss: 0.67033 | train_accuracy: 0.72466 | valid_accuracy: 0.68095 |  0:00:15s\n",
      "epoch 160| loss: 0.67045 | train_accuracy: 0.72653 | valid_accuracy: 0.68844 |  0:00:15s\n",
      "epoch 161| loss: 0.67638 | train_accuracy: 0.71565 | valid_accuracy: 0.67075 |  0:00:15s\n",
      "epoch 162| loss: 0.6614  | train_accuracy: 0.72041 | valid_accuracy: 0.68435 |  0:00:15s\n",
      "epoch 163| loss: 0.66964 | train_accuracy: 0.72262 | valid_accuracy: 0.69116 |  0:00:15s\n",
      "epoch 164| loss: 0.67762 | train_accuracy: 0.71463 | valid_accuracy: 0.67415 |  0:00:15s\n",
      "epoch 165| loss: 0.675   | train_accuracy: 0.71463 | valid_accuracy: 0.67347 |  0:00:15s\n",
      "epoch 166| loss: 0.67111 | train_accuracy: 0.7148  | valid_accuracy: 0.68571 |  0:00:15s\n",
      "epoch 167| loss: 0.67835 | train_accuracy: 0.71667 | valid_accuracy: 0.67959 |  0:00:15s\n",
      "epoch 168| loss: 0.66902 | train_accuracy: 0.72704 | valid_accuracy: 0.69524 |  0:00:15s\n",
      "epoch 169| loss: 0.68677 | train_accuracy: 0.7148  | valid_accuracy: 0.68639 |  0:00:16s\n",
      "epoch 170| loss: 0.6732  | train_accuracy: 0.71718 | valid_accuracy: 0.68435 |  0:00:16s\n",
      "epoch 171| loss: 0.66731 | train_accuracy: 0.72602 | valid_accuracy: 0.69252 |  0:00:16s\n",
      "epoch 172| loss: 0.67003 | train_accuracy: 0.72908 | valid_accuracy: 0.69184 |  0:00:16s\n",
      "epoch 173| loss: 0.6625  | train_accuracy: 0.72041 | valid_accuracy: 0.69184 |  0:00:16s\n",
      "epoch 174| loss: 0.66227 | train_accuracy: 0.72449 | valid_accuracy: 0.6932  |  0:00:16s\n",
      "epoch 175| loss: 0.6696  | train_accuracy: 0.72772 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 176| loss: 0.65642 | train_accuracy: 0.73027 | valid_accuracy: 0.69116 |  0:00:16s\n",
      "epoch 177| loss: 0.6608  | train_accuracy: 0.71701 | valid_accuracy: 0.68095 |  0:00:16s\n",
      "epoch 178| loss: 0.67315 | train_accuracy: 0.72228 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 179| loss: 0.66119 | train_accuracy: 0.72551 | valid_accuracy: 0.68912 |  0:00:16s\n",
      "epoch 180| loss: 0.66214 | train_accuracy: 0.71667 | valid_accuracy: 0.67823 |  0:00:17s\n",
      "epoch 181| loss: 0.6555  | train_accuracy: 0.71718 | valid_accuracy: 0.69116 |  0:00:17s\n",
      "epoch 182| loss: 0.66231 | train_accuracy: 0.71565 | valid_accuracy: 0.68503 |  0:00:17s\n",
      "epoch 183| loss: 0.66129 | train_accuracy: 0.73299 | valid_accuracy: 0.69524 |  0:00:17s\n",
      "epoch 184| loss: 0.66466 | train_accuracy: 0.72755 | valid_accuracy: 0.67687 |  0:00:17s\n",
      "epoch 185| loss: 0.65116 | train_accuracy: 0.72398 | valid_accuracy: 0.68639 |  0:00:17s\n",
      "epoch 186| loss: 0.66736 | train_accuracy: 0.72993 | valid_accuracy: 0.68912 |  0:00:17s\n",
      "epoch 187| loss: 0.671   | train_accuracy: 0.71871 | valid_accuracy: 0.68299 |  0:00:17s\n",
      "epoch 188| loss: 0.64925 | train_accuracy: 0.73095 | valid_accuracy: 0.69524 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189| loss: 0.66191 | train_accuracy: 0.72908 | valid_accuracy: 0.68912 |  0:00:17s\n",
      "epoch 190| loss: 0.65854 | train_accuracy: 0.72126 | valid_accuracy: 0.68571 |  0:00:18s\n",
      "epoch 191| loss: 0.64858 | train_accuracy: 0.73044 | valid_accuracy: 0.69252 |  0:00:18s\n",
      "epoch 192| loss: 0.65185 | train_accuracy: 0.73384 | valid_accuracy: 0.69388 |  0:00:18s\n",
      "epoch 193| loss: 0.64637 | train_accuracy: 0.7216  | valid_accuracy: 0.69592 |  0:00:18s\n",
      "epoch 194| loss: 0.64307 | train_accuracy: 0.72024 | valid_accuracy: 0.69252 |  0:00:18s\n",
      "epoch 195| loss: 0.65447 | train_accuracy: 0.72279 | valid_accuracy: 0.69524 |  0:00:18s\n",
      "epoch 196| loss: 0.66755 | train_accuracy: 0.73605 | valid_accuracy: 0.69524 |  0:00:18s\n",
      "epoch 197| loss: 0.66858 | train_accuracy: 0.72891 | valid_accuracy: 0.68844 |  0:00:18s\n",
      "epoch 198| loss: 0.65681 | train_accuracy: 0.72704 | valid_accuracy: 0.68844 |  0:00:18s\n",
      "epoch 199| loss: 0.65341 | train_accuracy: 0.73793 | valid_accuracy: 0.6898  |  0:00:18s\n",
      "epoch 200| loss: 0.66868 | train_accuracy: 0.73537 | valid_accuracy: 0.69388 |  0:00:18s\n",
      "epoch 201| loss: 0.6459  | train_accuracy: 0.72891 | valid_accuracy: 0.68435 |  0:00:19s\n",
      "epoch 202| loss: 0.65104 | train_accuracy: 0.74269 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 203| loss: 0.66104 | train_accuracy: 0.73248 | valid_accuracy: 0.68776 |  0:00:19s\n",
      "epoch 204| loss: 0.66369 | train_accuracy: 0.72721 | valid_accuracy: 0.68231 |  0:00:19s\n",
      "epoch 205| loss: 0.65587 | train_accuracy: 0.73367 | valid_accuracy: 0.70204 |  0:00:19s\n",
      "epoch 206| loss: 0.64575 | train_accuracy: 0.73146 | valid_accuracy: 0.7034  |  0:00:19s\n",
      "epoch 207| loss: 0.66348 | train_accuracy: 0.72398 | valid_accuracy: 0.69048 |  0:00:19s\n",
      "epoch 208| loss: 0.65133 | train_accuracy: 0.72925 | valid_accuracy: 0.68844 |  0:00:19s\n",
      "epoch 209| loss: 0.65693 | train_accuracy: 0.7369  | valid_accuracy: 0.69456 |  0:00:19s\n",
      "epoch 210| loss: 0.66177 | train_accuracy: 0.73384 | valid_accuracy: 0.68844 |  0:00:19s\n",
      "epoch 211| loss: 0.65978 | train_accuracy: 0.72738 | valid_accuracy: 0.69592 |  0:00:19s\n",
      "epoch 212| loss: 0.65548 | train_accuracy: 0.72653 | valid_accuracy: 0.70136 |  0:00:20s\n",
      "epoch 213| loss: 0.65154 | train_accuracy: 0.73622 | valid_accuracy: 0.68707 |  0:00:20s\n",
      "epoch 214| loss: 0.64638 | train_accuracy: 0.74014 | valid_accuracy: 0.68707 |  0:00:20s\n",
      "epoch 215| loss: 0.65347 | train_accuracy: 0.73367 | valid_accuracy: 0.68299 |  0:00:20s\n",
      "epoch 216| loss: 0.64583 | train_accuracy: 0.72738 | valid_accuracy: 0.6966  |  0:00:20s\n",
      "epoch 217| loss: 0.64865 | train_accuracy: 0.72874 | valid_accuracy: 0.69864 |  0:00:20s\n",
      "epoch 218| loss: 0.66554 | train_accuracy: 0.7301  | valid_accuracy: 0.69728 |  0:00:20s\n",
      "epoch 219| loss: 0.6456  | train_accuracy: 0.72823 | valid_accuracy: 0.68503 |  0:00:20s\n",
      "epoch 220| loss: 0.65281 | train_accuracy: 0.73027 | valid_accuracy: 0.68571 |  0:00:20s\n",
      "epoch 221| loss: 0.64755 | train_accuracy: 0.73776 | valid_accuracy: 0.7     |  0:00:20s\n",
      "epoch 222| loss: 0.64552 | train_accuracy: 0.73622 | valid_accuracy: 0.69184 |  0:00:20s\n",
      "epoch 223| loss: 0.64088 | train_accuracy: 0.73639 | valid_accuracy: 0.69252 |  0:00:21s\n",
      "epoch 224| loss: 0.6446  | train_accuracy: 0.73401 | valid_accuracy: 0.69864 |  0:00:21s\n",
      "epoch 225| loss: 0.65099 | train_accuracy: 0.73759 | valid_accuracy: 0.6966  |  0:00:21s\n",
      "epoch 226| loss: 0.65385 | train_accuracy: 0.73827 | valid_accuracy: 0.7     |  0:00:21s\n",
      "epoch 227| loss: 0.65433 | train_accuracy: 0.7381  | valid_accuracy: 0.70136 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 227 with best_epoch = 202 and best_valid_accuracy = 0.70816\n",
      "epoch 0  | loss: 1.61997 | train_accuracy: 0.32364 | valid_accuracy: 0.30476 |  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1  | loss: 1.1768  | train_accuracy: 0.28963 | valid_accuracy: 0.27891 |  0:00:00s\n",
      "epoch 2  | loss: 1.11681 | train_accuracy: 0.2881  | valid_accuracy: 0.25918 |  0:00:00s\n",
      "epoch 3  | loss: 1.0667  | train_accuracy: 0.30493 | valid_accuracy: 0.27891 |  0:00:00s\n",
      "epoch 4  | loss: 1.0088  | train_accuracy: 0.32568 | valid_accuracy: 0.31361 |  0:00:00s\n",
      "epoch 5  | loss: 0.97275 | train_accuracy: 0.3665  | valid_accuracy: 0.35646 |  0:00:00s\n",
      "epoch 6  | loss: 0.9713  | train_accuracy: 0.33741 | valid_accuracy: 0.33673 |  0:00:00s\n",
      "epoch 7  | loss: 0.96577 | train_accuracy: 0.36582 | valid_accuracy: 0.36054 |  0:00:00s\n",
      "epoch 8  | loss: 0.93838 | train_accuracy: 0.38095 | valid_accuracy: 0.37755 |  0:00:00s\n",
      "epoch 9  | loss: 0.92453 | train_accuracy: 0.40493 | valid_accuracy: 0.40136 |  0:00:00s\n",
      "epoch 10 | loss: 0.91087 | train_accuracy: 0.45034 | valid_accuracy: 0.47959 |  0:00:01s\n",
      "epoch 11 | loss: 0.90065 | train_accuracy: 0.39711 | valid_accuracy: 0.38095 |  0:00:01s\n",
      "epoch 12 | loss: 0.90538 | train_accuracy: 0.51922 | valid_accuracy: 0.51905 |  0:00:01s\n",
      "epoch 13 | loss: 0.90462 | train_accuracy: 0.50663 | valid_accuracy: 0.51497 |  0:00:01s\n",
      "epoch 14 | loss: 0.89347 | train_accuracy: 0.48486 | valid_accuracy: 0.48844 |  0:00:01s\n",
      "epoch 15 | loss: 0.87773 | train_accuracy: 0.49575 | valid_accuracy: 0.50408 |  0:00:01s\n",
      "epoch 16 | loss: 0.86687 | train_accuracy: 0.49881 | valid_accuracy: 0.51565 |  0:00:01s\n",
      "epoch 17 | loss: 0.87028 | train_accuracy: 0.50119 | valid_accuracy: 0.51837 |  0:00:01s\n",
      "epoch 18 | loss: 0.86084 | train_accuracy: 0.48061 | valid_accuracy: 0.48844 |  0:00:01s\n",
      "epoch 19 | loss: 0.86607 | train_accuracy: 0.48759 | valid_accuracy: 0.49524 |  0:00:01s\n",
      "epoch 20 | loss: 0.85528 | train_accuracy: 0.48469 | valid_accuracy: 0.4966  |  0:00:02s\n",
      "epoch 21 | loss: 0.85096 | train_accuracy: 0.49728 | valid_accuracy: 0.49728 |  0:00:02s\n",
      "epoch 22 | loss: 0.85297 | train_accuracy: 0.47891 | valid_accuracy: 0.48639 |  0:00:02s\n",
      "epoch 23 | loss: 0.84661 | train_accuracy: 0.52313 | valid_accuracy: 0.52993 |  0:00:02s\n",
      "epoch 24 | loss: 0.83596 | train_accuracy: 0.50221 | valid_accuracy: 0.4966  |  0:00:02s\n",
      "epoch 25 | loss: 0.82006 | train_accuracy: 0.4881  | valid_accuracy: 0.49184 |  0:00:02s\n",
      "epoch 26 | loss: 0.82855 | train_accuracy: 0.53027 | valid_accuracy: 0.53878 |  0:00:02s\n",
      "epoch 27 | loss: 0.81773 | train_accuracy: 0.50731 | valid_accuracy: 0.51905 |  0:00:02s\n",
      "epoch 28 | loss: 0.81625 | train_accuracy: 0.52517 | valid_accuracy: 0.52993 |  0:00:02s\n",
      "epoch 29 | loss: 0.82041 | train_accuracy: 0.52789 | valid_accuracy: 0.52381 |  0:00:02s\n",
      "epoch 30 | loss: 0.80196 | train_accuracy: 0.5301  | valid_accuracy: 0.52109 |  0:00:02s\n",
      "epoch 31 | loss: 0.81117 | train_accuracy: 0.53401 | valid_accuracy: 0.51973 |  0:00:03s\n",
      "epoch 32 | loss: 0.81205 | train_accuracy: 0.52636 | valid_accuracy: 0.51633 |  0:00:03s\n",
      "epoch 33 | loss: 0.80525 | train_accuracy: 0.55085 | valid_accuracy: 0.54014 |  0:00:03s\n",
      "epoch 34 | loss: 0.80867 | train_accuracy: 0.54966 | valid_accuracy: 0.5449  |  0:00:03s\n",
      "epoch 35 | loss: 0.80792 | train_accuracy: 0.5602  | valid_accuracy: 0.55102 |  0:00:03s\n",
      "epoch 36 | loss: 0.79511 | train_accuracy: 0.55595 | valid_accuracy: 0.54898 |  0:00:03s\n",
      "epoch 37 | loss: 0.79132 | train_accuracy: 0.56293 | valid_accuracy: 0.55646 |  0:00:03s\n",
      "epoch 38 | loss: 0.78759 | train_accuracy: 0.56582 | valid_accuracy: 0.55578 |  0:00:03s\n",
      "epoch 39 | loss: 0.78367 | train_accuracy: 0.56531 | valid_accuracy: 0.5517  |  0:00:03s\n",
      "epoch 40 | loss: 0.78386 | train_accuracy: 0.57279 | valid_accuracy: 0.56327 |  0:00:03s\n",
      "epoch 41 | loss: 0.78638 | train_accuracy: 0.58129 | valid_accuracy: 0.57075 |  0:00:03s\n",
      "epoch 42 | loss: 0.78072 | train_accuracy: 0.58588 | valid_accuracy: 0.56871 |  0:00:04s\n",
      "epoch 43 | loss: 0.77586 | train_accuracy: 0.59269 | valid_accuracy: 0.57891 |  0:00:04s\n",
      "epoch 44 | loss: 0.77727 | train_accuracy: 0.61616 | valid_accuracy: 0.5898  |  0:00:04s\n",
      "epoch 45 | loss: 0.774   | train_accuracy: 0.63418 | valid_accuracy: 0.62449 |  0:00:04s\n",
      "epoch 46 | loss: 0.76631 | train_accuracy: 0.59405 | valid_accuracy: 0.57619 |  0:00:04s\n",
      "epoch 47 | loss: 0.77051 | train_accuracy: 0.60748 | valid_accuracy: 0.59116 |  0:00:04s\n",
      "epoch 48 | loss: 0.77439 | train_accuracy: 0.62942 | valid_accuracy: 0.6102  |  0:00:04s\n",
      "epoch 49 | loss: 0.77036 | train_accuracy: 0.62687 | valid_accuracy: 0.61156 |  0:00:04s\n",
      "epoch 50 | loss: 0.77616 | train_accuracy: 0.63367 | valid_accuracy: 0.62041 |  0:00:04s\n",
      "epoch 51 | loss: 0.76527 | train_accuracy: 0.64269 | valid_accuracy: 0.62653 |  0:00:04s\n",
      "epoch 52 | loss: 0.74537 | train_accuracy: 0.64201 | valid_accuracy: 0.62449 |  0:00:05s\n",
      "epoch 53 | loss: 0.74937 | train_accuracy: 0.64065 | valid_accuracy: 0.62313 |  0:00:05s\n",
      "epoch 54 | loss: 0.76607 | train_accuracy: 0.64813 | valid_accuracy: 0.62721 |  0:00:05s\n",
      "epoch 55 | loss: 0.77338 | train_accuracy: 0.65221 | valid_accuracy: 0.63605 |  0:00:05s\n",
      "epoch 56 | loss: 0.75866 | train_accuracy: 0.65629 | valid_accuracy: 0.63878 |  0:00:05s\n",
      "epoch 57 | loss: 0.7552  | train_accuracy: 0.65527 | valid_accuracy: 0.64354 |  0:00:05s\n",
      "epoch 58 | loss: 0.75529 | train_accuracy: 0.65238 | valid_accuracy: 0.63061 |  0:00:05s\n",
      "epoch 59 | loss: 0.75821 | train_accuracy: 0.64507 | valid_accuracy: 0.62585 |  0:00:05s\n",
      "epoch 60 | loss: 0.75244 | train_accuracy: 0.64592 | valid_accuracy: 0.62381 |  0:00:05s\n",
      "epoch 61 | loss: 0.76719 | train_accuracy: 0.65017 | valid_accuracy: 0.63401 |  0:00:05s\n",
      "epoch 62 | loss: 0.75094 | train_accuracy: 0.66259 | valid_accuracy: 0.64898 |  0:00:05s\n",
      "epoch 63 | loss: 0.74839 | train_accuracy: 0.66939 | valid_accuracy: 0.65442 |  0:00:06s\n",
      "epoch 64 | loss: 0.75754 | train_accuracy: 0.67347 | valid_accuracy: 0.66259 |  0:00:06s\n",
      "epoch 65 | loss: 0.72977 | train_accuracy: 0.6568  | valid_accuracy: 0.65986 |  0:00:06s\n",
      "epoch 66 | loss: 0.73151 | train_accuracy: 0.66361 | valid_accuracy: 0.64422 |  0:00:06s\n",
      "epoch 67 | loss: 0.74461 | train_accuracy: 0.67704 | valid_accuracy: 0.66054 |  0:00:06s\n",
      "epoch 68 | loss: 0.73513 | train_accuracy: 0.6801  | valid_accuracy: 0.65714 |  0:00:06s\n",
      "epoch 69 | loss: 0.76231 | train_accuracy: 0.66956 | valid_accuracy: 0.6551  |  0:00:06s\n",
      "epoch 70 | loss: 0.73851 | train_accuracy: 0.67398 | valid_accuracy: 0.6585  |  0:00:06s\n",
      "epoch 71 | loss: 0.73493 | train_accuracy: 0.68452 | valid_accuracy: 0.65034 |  0:00:06s\n",
      "epoch 72 | loss: 0.72251 | train_accuracy: 0.67755 | valid_accuracy: 0.66531 |  0:00:06s\n",
      "epoch 73 | loss: 0.72674 | train_accuracy: 0.68401 | valid_accuracy: 0.6517  |  0:00:06s\n",
      "epoch 74 | loss: 0.73089 | train_accuracy: 0.67908 | valid_accuracy: 0.65034 |  0:00:07s\n",
      "epoch 75 | loss: 0.72158 | train_accuracy: 0.67959 | valid_accuracy: 0.66327 |  0:00:07s\n",
      "epoch 76 | loss: 0.71555 | train_accuracy: 0.6801  | valid_accuracy: 0.67279 |  0:00:07s\n",
      "epoch 77 | loss: 0.73727 | train_accuracy: 0.69201 | valid_accuracy: 0.68163 |  0:00:07s\n",
      "epoch 78 | loss: 0.71796 | train_accuracy: 0.69065 | valid_accuracy: 0.67959 |  0:00:07s\n",
      "epoch 79 | loss: 0.71651 | train_accuracy: 0.6835  | valid_accuracy: 0.67415 |  0:00:07s\n",
      "epoch 80 | loss: 0.71547 | train_accuracy: 0.69116 | valid_accuracy: 0.66939 |  0:00:07s\n",
      "epoch 81 | loss: 0.71263 | train_accuracy: 0.69626 | valid_accuracy: 0.68231 |  0:00:07s\n",
      "epoch 82 | loss: 0.72585 | train_accuracy: 0.69167 | valid_accuracy: 0.68435 |  0:00:07s\n",
      "epoch 83 | loss: 0.71586 | train_accuracy: 0.69473 | valid_accuracy: 0.68367 |  0:00:07s\n",
      "epoch 84 | loss: 0.71064 | train_accuracy: 0.69082 | valid_accuracy: 0.67279 |  0:00:08s\n",
      "epoch 85 | loss: 0.70682 | train_accuracy: 0.69609 | valid_accuracy: 0.67959 |  0:00:08s\n",
      "epoch 86 | loss: 0.70801 | train_accuracy: 0.69609 | valid_accuracy: 0.68027 |  0:00:08s\n",
      "epoch 87 | loss: 0.71392 | train_accuracy: 0.70646 | valid_accuracy: 0.68844 |  0:00:08s\n",
      "epoch 88 | loss: 0.72209 | train_accuracy: 0.69099 | valid_accuracy: 0.67347 |  0:00:08s\n",
      "epoch 89 | loss: 0.71685 | train_accuracy: 0.69524 | valid_accuracy: 0.69252 |  0:00:08s\n",
      "epoch 90 | loss: 0.69767 | train_accuracy: 0.69235 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 91 | loss: 0.70289 | train_accuracy: 0.69082 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 92 | loss: 0.70763 | train_accuracy: 0.69898 | valid_accuracy: 0.68776 |  0:00:08s\n",
      "epoch 93 | loss: 0.71634 | train_accuracy: 0.69711 | valid_accuracy: 0.67619 |  0:00:08s\n",
      "epoch 94 | loss: 0.70533 | train_accuracy: 0.69405 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 95 | loss: 0.71516 | train_accuracy: 0.69847 | valid_accuracy: 0.68571 |  0:00:09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96 | loss: 0.69854 | train_accuracy: 0.71037 | valid_accuracy: 0.69796 |  0:00:09s\n",
      "epoch 97 | loss: 0.69285 | train_accuracy: 0.69762 | valid_accuracy: 0.68367 |  0:00:09s\n",
      "epoch 98 | loss: 0.70149 | train_accuracy: 0.69983 | valid_accuracy: 0.68571 |  0:00:09s\n",
      "epoch 99 | loss: 0.69521 | train_accuracy: 0.70425 | valid_accuracy: 0.70136 |  0:00:09s\n",
      "epoch 100| loss: 0.70253 | train_accuracy: 0.69881 | valid_accuracy: 0.69388 |  0:00:09s\n",
      "epoch 101| loss: 0.70697 | train_accuracy: 0.7     | valid_accuracy: 0.67619 |  0:00:09s\n",
      "epoch 102| loss: 0.69415 | train_accuracy: 0.70748 | valid_accuracy: 0.69796 |  0:00:09s\n",
      "epoch 103| loss: 0.68577 | train_accuracy: 0.69643 | valid_accuracy: 0.68231 |  0:00:09s\n",
      "epoch 104| loss: 0.68628 | train_accuracy: 0.69626 | valid_accuracy: 0.6898  |  0:00:09s\n",
      "epoch 105| loss: 0.68593 | train_accuracy: 0.70697 | valid_accuracy: 0.67551 |  0:00:10s\n",
      "epoch 106| loss: 0.68091 | train_accuracy: 0.68214 | valid_accuracy: 0.67143 |  0:00:10s\n",
      "epoch 107| loss: 0.69162 | train_accuracy: 0.71395 | valid_accuracy: 0.69456 |  0:00:10s\n",
      "epoch 108| loss: 0.69052 | train_accuracy: 0.70187 | valid_accuracy: 0.68707 |  0:00:10s\n",
      "epoch 109| loss: 0.68263 | train_accuracy: 0.71514 | valid_accuracy: 0.70136 |  0:00:10s\n",
      "epoch 110| loss: 0.67831 | train_accuracy: 0.70544 | valid_accuracy: 0.69116 |  0:00:10s\n",
      "epoch 111| loss: 0.67018 | train_accuracy: 0.7102  | valid_accuracy: 0.7     |  0:00:10s\n",
      "epoch 112| loss: 0.69275 | train_accuracy: 0.70051 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 113| loss: 0.68695 | train_accuracy: 0.71361 | valid_accuracy: 0.68844 |  0:00:10s\n",
      "epoch 114| loss: 0.68058 | train_accuracy: 0.71361 | valid_accuracy: 0.68571 |  0:00:10s\n",
      "epoch 115| loss: 0.6827  | train_accuracy: 0.72194 | valid_accuracy: 0.69932 |  0:00:10s\n",
      "epoch 116| loss: 0.69044 | train_accuracy: 0.70901 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 117| loss: 0.66761 | train_accuracy: 0.72092 | valid_accuracy: 0.69796 |  0:00:11s\n",
      "epoch 118| loss: 0.68279 | train_accuracy: 0.70765 | valid_accuracy: 0.68707 |  0:00:11s\n",
      "epoch 119| loss: 0.67172 | train_accuracy: 0.72007 | valid_accuracy: 0.7     |  0:00:11s\n",
      "epoch 120| loss: 0.67888 | train_accuracy: 0.71327 | valid_accuracy: 0.68707 |  0:00:11s\n",
      "epoch 121| loss: 0.68501 | train_accuracy: 0.71241 | valid_accuracy: 0.7     |  0:00:11s\n",
      "epoch 122| loss: 0.66874 | train_accuracy: 0.71973 | valid_accuracy: 0.70952 |  0:00:11s\n",
      "epoch 123| loss: 0.66978 | train_accuracy: 0.72313 | valid_accuracy: 0.72177 |  0:00:11s\n",
      "epoch 124| loss: 0.69152 | train_accuracy: 0.72398 | valid_accuracy: 0.69932 |  0:00:11s\n",
      "epoch 125| loss: 0.67822 | train_accuracy: 0.71139 | valid_accuracy: 0.69524 |  0:00:11s\n",
      "epoch 126| loss: 0.69131 | train_accuracy: 0.72279 | valid_accuracy: 0.70952 |  0:00:11s\n",
      "epoch 127| loss: 0.67169 | train_accuracy: 0.72177 | valid_accuracy: 0.70204 |  0:00:12s\n",
      "epoch 128| loss: 0.66481 | train_accuracy: 0.71956 | valid_accuracy: 0.70884 |  0:00:12s\n",
      "epoch 129| loss: 0.67794 | train_accuracy: 0.71616 | valid_accuracy: 0.68776 |  0:00:12s\n",
      "epoch 130| loss: 0.6686  | train_accuracy: 0.71888 | valid_accuracy: 0.71088 |  0:00:12s\n",
      "epoch 131| loss: 0.66267 | train_accuracy: 0.72313 | valid_accuracy: 0.71633 |  0:00:12s\n",
      "epoch 132| loss: 0.66607 | train_accuracy: 0.7267  | valid_accuracy: 0.70748 |  0:00:12s\n",
      "epoch 133| loss: 0.67751 | train_accuracy: 0.72432 | valid_accuracy: 0.70612 |  0:00:12s\n",
      "epoch 134| loss: 0.66785 | train_accuracy: 0.72449 | valid_accuracy: 0.71497 |  0:00:12s\n",
      "epoch 135| loss: 0.67433 | train_accuracy: 0.73537 | valid_accuracy: 0.72177 |  0:00:12s\n",
      "epoch 136| loss: 0.66632 | train_accuracy: 0.725   | valid_accuracy: 0.71088 |  0:00:12s\n",
      "epoch 137| loss: 0.66058 | train_accuracy: 0.7335  | valid_accuracy: 0.71293 |  0:00:13s\n",
      "epoch 138| loss: 0.65949 | train_accuracy: 0.72891 | valid_accuracy: 0.71701 |  0:00:13s\n",
      "epoch 139| loss: 0.65724 | train_accuracy: 0.7267  | valid_accuracy: 0.71701 |  0:00:13s\n",
      "epoch 140| loss: 0.66348 | train_accuracy: 0.73265 | valid_accuracy: 0.70816 |  0:00:13s\n",
      "epoch 141| loss: 0.66089 | train_accuracy: 0.72483 | valid_accuracy: 0.71497 |  0:00:13s\n",
      "epoch 142| loss: 0.67509 | train_accuracy: 0.7301  | valid_accuracy: 0.71497 |  0:00:13s\n",
      "epoch 143| loss: 0.65925 | train_accuracy: 0.72789 | valid_accuracy: 0.70612 |  0:00:13s\n",
      "epoch 144| loss: 0.66713 | train_accuracy: 0.71973 | valid_accuracy: 0.69932 |  0:00:13s\n",
      "epoch 145| loss: 0.67167 | train_accuracy: 0.72347 | valid_accuracy: 0.70204 |  0:00:13s\n",
      "epoch 146| loss: 0.65993 | train_accuracy: 0.73163 | valid_accuracy: 0.70476 |  0:00:13s\n",
      "epoch 147| loss: 0.64753 | train_accuracy: 0.72772 | valid_accuracy: 0.71224 |  0:00:13s\n",
      "epoch 148| loss: 0.65702 | train_accuracy: 0.73827 | valid_accuracy: 0.71905 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 148 with best_epoch = 123 and best_valid_accuracy = 0.72177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.63328 | train_accuracy: 0.31088 | valid_accuracy: 0.32925 |  0:00:00s\n",
      "epoch 1  | loss: 1.1634  | train_accuracy: 0.32942 | valid_accuracy: 0.31837 |  0:00:00s\n",
      "epoch 2  | loss: 1.05347 | train_accuracy: 0.34728 | valid_accuracy: 0.32721 |  0:00:00s\n",
      "epoch 3  | loss: 1.00929 | train_accuracy: 0.38673 | valid_accuracy: 0.36871 |  0:00:00s\n",
      "epoch 4  | loss: 0.9748  | train_accuracy: 0.3915  | valid_accuracy: 0.38027 |  0:00:00s\n",
      "epoch 5  | loss: 0.95653 | train_accuracy: 0.4818  | valid_accuracy: 0.50068 |  0:00:00s\n",
      "epoch 6  | loss: 0.93961 | train_accuracy: 0.49116 | valid_accuracy: 0.50748 |  0:00:00s\n",
      "epoch 7  | loss: 0.92453 | train_accuracy: 0.49898 | valid_accuracy: 0.51156 |  0:00:00s\n",
      "epoch 8  | loss: 0.92116 | train_accuracy: 0.39218 | valid_accuracy: 0.43129 |  0:00:00s\n",
      "epoch 9  | loss: 0.92749 | train_accuracy: 0.5131  | valid_accuracy: 0.5449  |  0:00:00s\n",
      "epoch 10 | loss: 0.91544 | train_accuracy: 0.44813 | valid_accuracy: 0.48027 |  0:00:01s\n",
      "epoch 11 | loss: 0.91705 | train_accuracy: 0.47109 | valid_accuracy: 0.50068 |  0:00:01s\n",
      "epoch 12 | loss: 0.91136 | train_accuracy: 0.49099 | valid_accuracy: 0.52585 |  0:00:01s\n",
      "epoch 13 | loss: 0.89762 | train_accuracy: 0.45374 | valid_accuracy: 0.49252 |  0:00:01s\n",
      "epoch 14 | loss: 0.89869 | train_accuracy: 0.50629 | valid_accuracy: 0.54354 |  0:00:01s\n",
      "epoch 15 | loss: 0.89664 | train_accuracy: 0.49507 | valid_accuracy: 0.52449 |  0:00:01s\n",
      "epoch 16 | loss: 0.90025 | train_accuracy: 0.49388 | valid_accuracy: 0.48435 |  0:00:01s\n",
      "epoch 17 | loss: 0.88852 | train_accuracy: 0.47143 | valid_accuracy: 0.47143 |  0:00:01s\n",
      "epoch 18 | loss: 0.88682 | train_accuracy: 0.48741 | valid_accuracy: 0.48027 |  0:00:01s\n",
      "epoch 19 | loss: 0.88377 | train_accuracy: 0.52007 | valid_accuracy: 0.50068 |  0:00:01s\n",
      "epoch 20 | loss: 0.88092 | train_accuracy: 0.50901 | valid_accuracy: 0.4966  |  0:00:01s\n",
      "epoch 21 | loss: 0.88062 | train_accuracy: 0.4915  | valid_accuracy: 0.48707 |  0:00:02s\n",
      "epoch 22 | loss: 0.86537 | train_accuracy: 0.53946 | valid_accuracy: 0.53946 |  0:00:02s\n",
      "epoch 23 | loss: 0.85744 | train_accuracy: 0.50969 | valid_accuracy: 0.51156 |  0:00:02s\n",
      "epoch 24 | loss: 0.86387 | train_accuracy: 0.5398  | valid_accuracy: 0.5415  |  0:00:02s\n",
      "epoch 25 | loss: 0.86635 | train_accuracy: 0.54133 | valid_accuracy: 0.53878 |  0:00:02s\n",
      "epoch 26 | loss: 0.87406 | train_accuracy: 0.54269 | valid_accuracy: 0.53605 |  0:00:02s\n",
      "epoch 27 | loss: 0.87176 | train_accuracy: 0.54405 | valid_accuracy: 0.53129 |  0:00:02s\n",
      "epoch 28 | loss: 0.85596 | train_accuracy: 0.5318  | valid_accuracy: 0.53265 |  0:00:02s\n",
      "epoch 29 | loss: 0.87039 | train_accuracy: 0.56207 | valid_accuracy: 0.5585  |  0:00:02s\n",
      "epoch 30 | loss: 0.85254 | train_accuracy: 0.57279 | valid_accuracy: 0.57075 |  0:00:02s\n",
      "epoch 31 | loss: 0.83961 | train_accuracy: 0.56378 | valid_accuracy: 0.55918 |  0:00:03s\n",
      "epoch 32 | loss: 0.842   | train_accuracy: 0.56054 | valid_accuracy: 0.55646 |  0:00:03s\n",
      "epoch 33 | loss: 0.84259 | train_accuracy: 0.5699  | valid_accuracy: 0.56395 |  0:00:03s\n",
      "epoch 34 | loss: 0.83001 | train_accuracy: 0.57109 | valid_accuracy: 0.57687 |  0:00:03s\n",
      "epoch 35 | loss: 0.81813 | train_accuracy: 0.56973 | valid_accuracy: 0.56531 |  0:00:03s\n",
      "epoch 36 | loss: 0.82671 | train_accuracy: 0.57398 | valid_accuracy: 0.56871 |  0:00:03s\n",
      "epoch 37 | loss: 0.8149  | train_accuracy: 0.5852  | valid_accuracy: 0.57551 |  0:00:03s\n",
      "epoch 38 | loss: 0.82141 | train_accuracy: 0.59218 | valid_accuracy: 0.58571 |  0:00:03s\n",
      "epoch 39 | loss: 0.81801 | train_accuracy: 0.56565 | valid_accuracy: 0.56803 |  0:00:03s\n",
      "epoch 40 | loss: 0.80625 | train_accuracy: 0.59677 | valid_accuracy: 0.5966  |  0:00:03s\n",
      "epoch 41 | loss: 0.80337 | train_accuracy: 0.59065 | valid_accuracy: 0.58571 |  0:00:03s\n",
      "epoch 42 | loss: 0.80835 | train_accuracy: 0.60306 | valid_accuracy: 0.60544 |  0:00:04s\n",
      "epoch 43 | loss: 0.8089  | train_accuracy: 0.59099 | valid_accuracy: 0.58163 |  0:00:04s\n",
      "epoch 44 | loss: 0.81902 | train_accuracy: 0.59779 | valid_accuracy: 0.59932 |  0:00:04s\n",
      "epoch 45 | loss: 0.81254 | train_accuracy: 0.60714 | valid_accuracy: 0.60612 |  0:00:04s\n",
      "epoch 46 | loss: 0.79755 | train_accuracy: 0.61446 | valid_accuracy: 0.61497 |  0:00:04s\n",
      "epoch 47 | loss: 0.80427 | train_accuracy: 0.61718 | valid_accuracy: 0.61973 |  0:00:04s\n",
      "epoch 48 | loss: 0.82478 | train_accuracy: 0.6051  | valid_accuracy: 0.60272 |  0:00:04s\n",
      "epoch 49 | loss: 0.80279 | train_accuracy: 0.61922 | valid_accuracy: 0.62449 |  0:00:04s\n",
      "epoch 50 | loss: 0.79486 | train_accuracy: 0.63078 | valid_accuracy: 0.62993 |  0:00:04s\n",
      "epoch 51 | loss: 0.78982 | train_accuracy: 0.6199  | valid_accuracy: 0.61837 |  0:00:04s\n",
      "epoch 52 | loss: 0.79644 | train_accuracy: 0.62687 | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 53 | loss: 0.78428 | train_accuracy: 0.61888 | valid_accuracy: 0.62517 |  0:00:05s\n",
      "epoch 54 | loss: 0.79856 | train_accuracy: 0.6301  | valid_accuracy: 0.63401 |  0:00:05s\n",
      "epoch 55 | loss: 0.8027  | train_accuracy: 0.63895 | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 56 | loss: 0.78913 | train_accuracy: 0.6381  | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 57 | loss: 0.79844 | train_accuracy: 0.63997 | valid_accuracy: 0.63265 |  0:00:05s\n",
      "epoch 58 | loss: 0.78116 | train_accuracy: 0.64728 | valid_accuracy: 0.64558 |  0:00:05s\n",
      "epoch 59 | loss: 0.78662 | train_accuracy: 0.64286 | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 60 | loss: 0.78123 | train_accuracy: 0.64167 | valid_accuracy: 0.6415  |  0:00:05s\n",
      "epoch 61 | loss: 0.79268 | train_accuracy: 0.6335  | valid_accuracy: 0.63197 |  0:00:05s\n",
      "epoch 62 | loss: 0.77351 | train_accuracy: 0.64388 | valid_accuracy: 0.64558 |  0:00:05s\n",
      "epoch 63 | loss: 0.77454 | train_accuracy: 0.65391 | valid_accuracy: 0.64762 |  0:00:06s\n",
      "epoch 64 | loss: 0.78303 | train_accuracy: 0.65357 | valid_accuracy: 0.65646 |  0:00:06s\n",
      "epoch 65 | loss: 0.77998 | train_accuracy: 0.6585  | valid_accuracy: 0.64966 |  0:00:06s\n",
      "epoch 66 | loss: 0.77818 | train_accuracy: 0.65544 | valid_accuracy: 0.64966 |  0:00:06s\n",
      "epoch 67 | loss: 0.77642 | train_accuracy: 0.65935 | valid_accuracy: 0.64626 |  0:00:06s\n",
      "epoch 68 | loss: 0.76676 | train_accuracy: 0.65272 | valid_accuracy: 0.65442 |  0:00:06s\n",
      "epoch 69 | loss: 0.76712 | train_accuracy: 0.65816 | valid_accuracy: 0.66327 |  0:00:06s\n",
      "epoch 70 | loss: 0.76477 | train_accuracy: 0.66854 | valid_accuracy: 0.65578 |  0:00:06s\n",
      "epoch 71 | loss: 0.75988 | train_accuracy: 0.65425 | valid_accuracy: 0.65306 |  0:00:06s\n",
      "epoch 72 | loss: 0.75791 | train_accuracy: 0.66803 | valid_accuracy: 0.65986 |  0:00:06s\n",
      "epoch 73 | loss: 0.75885 | train_accuracy: 0.66701 | valid_accuracy: 0.66735 |  0:00:06s\n",
      "epoch 74 | loss: 0.75007 | train_accuracy: 0.66344 | valid_accuracy: 0.65986 |  0:00:07s\n",
      "epoch 75 | loss: 0.75339 | train_accuracy: 0.67364 | valid_accuracy: 0.65918 |  0:00:07s\n",
      "epoch 76 | loss: 0.75858 | train_accuracy: 0.6682  | valid_accuracy: 0.65442 |  0:00:07s\n",
      "epoch 77 | loss: 0.76584 | train_accuracy: 0.66514 | valid_accuracy: 0.65714 |  0:00:07s\n",
      "epoch 78 | loss: 0.76055 | train_accuracy: 0.66344 | valid_accuracy: 0.6483  |  0:00:07s\n",
      "epoch 79 | loss: 0.7632  | train_accuracy: 0.66752 | valid_accuracy: 0.66054 |  0:00:07s\n",
      "epoch 80 | loss: 0.75372 | train_accuracy: 0.66769 | valid_accuracy: 0.65578 |  0:00:07s\n",
      "epoch 81 | loss: 0.75598 | train_accuracy: 0.67211 | valid_accuracy: 0.66463 |  0:00:07s\n",
      "epoch 82 | loss: 0.7544  | train_accuracy: 0.66531 | valid_accuracy: 0.66395 |  0:00:07s\n",
      "epoch 83 | loss: 0.74702 | train_accuracy: 0.67789 | valid_accuracy: 0.67347 |  0:00:07s\n",
      "epoch 84 | loss: 0.74824 | train_accuracy: 0.67534 | valid_accuracy: 0.66327 |  0:00:08s\n",
      "epoch 85 | loss: 0.75237 | train_accuracy: 0.67228 | valid_accuracy: 0.66054 |  0:00:08s\n",
      "epoch 86 | loss: 0.75338 | train_accuracy: 0.67942 | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 87 | loss: 0.74859 | train_accuracy: 0.67364 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 88 | loss: 0.74723 | train_accuracy: 0.66854 | valid_accuracy: 0.67007 |  0:00:08s\n",
      "epoch 89 | loss: 0.75733 | train_accuracy: 0.68639 | valid_accuracy: 0.67143 |  0:00:08s\n",
      "epoch 90 | loss: 0.74772 | train_accuracy: 0.67806 | valid_accuracy: 0.66463 |  0:00:08s\n",
      "epoch 91 | loss: 0.72928 | train_accuracy: 0.67364 | valid_accuracy: 0.64898 |  0:00:08s\n",
      "epoch 92 | loss: 0.75516 | train_accuracy: 0.68112 | valid_accuracy: 0.66871 |  0:00:08s\n",
      "epoch 93 | loss: 0.73222 | train_accuracy: 0.68112 | valid_accuracy: 0.66259 |  0:00:08s\n",
      "epoch 94 | loss: 0.72943 | train_accuracy: 0.68656 | valid_accuracy: 0.66803 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 | loss: 0.72378 | train_accuracy: 0.68452 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 96 | loss: 0.73597 | train_accuracy: 0.69133 | valid_accuracy: 0.67755 |  0:00:09s\n",
      "epoch 97 | loss: 0.72877 | train_accuracy: 0.68316 | valid_accuracy: 0.67551 |  0:00:09s\n",
      "epoch 98 | loss: 0.72994 | train_accuracy: 0.68095 | valid_accuracy: 0.66667 |  0:00:09s\n",
      "epoch 99 | loss: 0.73126 | train_accuracy: 0.68078 | valid_accuracy: 0.67007 |  0:00:09s\n",
      "epoch 100| loss: 0.72379 | train_accuracy: 0.67806 | valid_accuracy: 0.66871 |  0:00:09s\n",
      "epoch 101| loss: 0.71546 | train_accuracy: 0.69728 | valid_accuracy: 0.67279 |  0:00:09s\n",
      "epoch 102| loss: 0.72084 | train_accuracy: 0.69337 | valid_accuracy: 0.66871 |  0:00:09s\n",
      "epoch 103| loss: 0.71907 | train_accuracy: 0.68656 | valid_accuracy: 0.65714 |  0:00:09s\n",
      "epoch 104| loss: 0.72024 | train_accuracy: 0.68861 | valid_accuracy: 0.68027 |  0:00:09s\n",
      "epoch 105| loss: 0.72881 | train_accuracy: 0.69473 | valid_accuracy: 0.67075 |  0:00:09s\n",
      "epoch 106| loss: 0.71584 | train_accuracy: 0.68895 | valid_accuracy: 0.67347 |  0:00:10s\n",
      "epoch 107| loss: 0.71317 | train_accuracy: 0.69762 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 108| loss: 0.72329 | train_accuracy: 0.6852  | valid_accuracy: 0.67551 |  0:00:10s\n",
      "epoch 109| loss: 0.72199 | train_accuracy: 0.69473 | valid_accuracy: 0.67755 |  0:00:10s\n",
      "epoch 110| loss: 0.71694 | train_accuracy: 0.69745 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 111| loss: 0.71848 | train_accuracy: 0.68673 | valid_accuracy: 0.66122 |  0:00:10s\n",
      "epoch 112| loss: 0.70954 | train_accuracy: 0.69354 | valid_accuracy: 0.67279 |  0:00:10s\n",
      "epoch 113| loss: 0.71738 | train_accuracy: 0.70102 | valid_accuracy: 0.67143 |  0:00:10s\n",
      "epoch 114| loss: 0.72049 | train_accuracy: 0.69439 | valid_accuracy: 0.67891 |  0:00:10s\n",
      "epoch 115| loss: 0.71702 | train_accuracy: 0.70306 | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 116| loss: 0.71098 | train_accuracy: 0.70051 | valid_accuracy: 0.67823 |  0:00:11s\n",
      "epoch 117| loss: 0.71916 | train_accuracy: 0.7051  | valid_accuracy: 0.67007 |  0:00:11s\n",
      "epoch 118| loss: 0.71042 | train_accuracy: 0.6898  | valid_accuracy: 0.66735 |  0:00:11s\n",
      "epoch 119| loss: 0.71061 | train_accuracy: 0.69847 | valid_accuracy: 0.68435 |  0:00:11s\n",
      "epoch 120| loss: 0.70595 | train_accuracy: 0.70459 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 121| loss: 0.71946 | train_accuracy: 0.68265 | valid_accuracy: 0.65646 |  0:00:11s\n",
      "epoch 122| loss: 0.71376 | train_accuracy: 0.70153 | valid_accuracy: 0.68095 |  0:00:11s\n",
      "epoch 123| loss: 0.71845 | train_accuracy: 0.69932 | valid_accuracy: 0.68639 |  0:00:11s\n",
      "epoch 124| loss: 0.70104 | train_accuracy: 0.70034 | valid_accuracy: 0.68571 |  0:00:11s\n",
      "epoch 125| loss: 0.71373 | train_accuracy: 0.70884 | valid_accuracy: 0.68435 |  0:00:11s\n",
      "epoch 126| loss: 0.70048 | train_accuracy: 0.70391 | valid_accuracy: 0.68571 |  0:00:12s\n",
      "epoch 127| loss: 0.70076 | train_accuracy: 0.70629 | valid_accuracy: 0.69048 |  0:00:12s\n",
      "epoch 128| loss: 0.70426 | train_accuracy: 0.70765 | valid_accuracy: 0.68571 |  0:00:12s\n",
      "epoch 129| loss: 0.70146 | train_accuracy: 0.71088 | valid_accuracy: 0.68299 |  0:00:12s\n",
      "epoch 130| loss: 0.70393 | train_accuracy: 0.70986 | valid_accuracy: 0.67687 |  0:00:12s\n",
      "epoch 131| loss: 0.69953 | train_accuracy: 0.69949 | valid_accuracy: 0.68163 |  0:00:12s\n",
      "epoch 132| loss: 0.68692 | train_accuracy: 0.7131  | valid_accuracy: 0.68776 |  0:00:12s\n",
      "epoch 133| loss: 0.69365 | train_accuracy: 0.7102  | valid_accuracy: 0.69116 |  0:00:12s\n",
      "epoch 134| loss: 0.70224 | train_accuracy: 0.69728 | valid_accuracy: 0.68231 |  0:00:12s\n",
      "epoch 135| loss: 0.69282 | train_accuracy: 0.70629 | valid_accuracy: 0.68299 |  0:00:12s\n",
      "epoch 136| loss: 0.69309 | train_accuracy: 0.72245 | valid_accuracy: 0.68844 |  0:00:12s\n",
      "epoch 137| loss: 0.69441 | train_accuracy: 0.71514 | valid_accuracy: 0.69116 |  0:00:13s\n",
      "epoch 138| loss: 0.69898 | train_accuracy: 0.70595 | valid_accuracy: 0.68571 |  0:00:13s\n",
      "epoch 139| loss: 0.69368 | train_accuracy: 0.70034 | valid_accuracy: 0.68503 |  0:00:13s\n",
      "epoch 140| loss: 0.70704 | train_accuracy: 0.7068  | valid_accuracy: 0.68435 |  0:00:13s\n",
      "epoch 141| loss: 0.70388 | train_accuracy: 0.71173 | valid_accuracy: 0.69932 |  0:00:13s\n",
      "epoch 142| loss: 0.69691 | train_accuracy: 0.70561 | valid_accuracy: 0.69388 |  0:00:13s\n",
      "epoch 143| loss: 0.68038 | train_accuracy: 0.70714 | valid_accuracy: 0.68912 |  0:00:13s\n",
      "epoch 144| loss: 0.68561 | train_accuracy: 0.7148  | valid_accuracy: 0.7     |  0:00:13s\n",
      "epoch 145| loss: 0.70392 | train_accuracy: 0.71037 | valid_accuracy: 0.68776 |  0:00:13s\n",
      "epoch 146| loss: 0.68684 | train_accuracy: 0.71412 | valid_accuracy: 0.6932  |  0:00:13s\n",
      "epoch 147| loss: 0.69816 | train_accuracy: 0.70816 | valid_accuracy: 0.69116 |  0:00:13s\n",
      "epoch 148| loss: 0.68734 | train_accuracy: 0.69864 | valid_accuracy: 0.68027 |  0:00:14s\n",
      "epoch 149| loss: 0.6867  | train_accuracy: 0.71224 | valid_accuracy: 0.69796 |  0:00:14s\n",
      "epoch 150| loss: 0.67938 | train_accuracy: 0.70459 | valid_accuracy: 0.69184 |  0:00:14s\n",
      "epoch 151| loss: 0.68976 | train_accuracy: 0.70204 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 152| loss: 0.69437 | train_accuracy: 0.70918 | valid_accuracy: 0.68571 |  0:00:14s\n",
      "epoch 153| loss: 0.69088 | train_accuracy: 0.70935 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 154| loss: 0.7025  | train_accuracy: 0.70918 | valid_accuracy: 0.69592 |  0:00:14s\n",
      "epoch 155| loss: 0.69481 | train_accuracy: 0.71241 | valid_accuracy: 0.68435 |  0:00:14s\n",
      "epoch 156| loss: 0.68492 | train_accuracy: 0.70799 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 157| loss: 0.67985 | train_accuracy: 0.71344 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 158| loss: 0.67658 | train_accuracy: 0.71463 | valid_accuracy: 0.68707 |  0:00:14s\n",
      "epoch 159| loss: 0.69397 | train_accuracy: 0.70833 | valid_accuracy: 0.68435 |  0:00:15s\n",
      "epoch 160| loss: 0.67755 | train_accuracy: 0.71582 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 161| loss: 0.67831 | train_accuracy: 0.7165  | valid_accuracy: 0.68776 |  0:00:15s\n",
      "epoch 162| loss: 0.68817 | train_accuracy: 0.72092 | valid_accuracy: 0.69592 |  0:00:15s\n",
      "epoch 163| loss: 0.67572 | train_accuracy: 0.72296 | valid_accuracy: 0.69864 |  0:00:15s\n",
      "epoch 164| loss: 0.69368 | train_accuracy: 0.72177 | valid_accuracy: 0.69864 |  0:00:15s\n",
      "epoch 165| loss: 0.69022 | train_accuracy: 0.72041 | valid_accuracy: 0.70204 |  0:00:15s\n",
      "epoch 166| loss: 0.66529 | train_accuracy: 0.71037 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 167| loss: 0.68208 | train_accuracy: 0.71378 | valid_accuracy: 0.68299 |  0:00:15s\n",
      "epoch 168| loss: 0.68055 | train_accuracy: 0.72687 | valid_accuracy: 0.69456 |  0:00:15s\n",
      "epoch 169| loss: 0.66762 | train_accuracy: 0.71667 | valid_accuracy: 0.69388 |  0:00:15s\n",
      "epoch 170| loss: 0.67002 | train_accuracy: 0.72177 | valid_accuracy: 0.69864 |  0:00:16s\n",
      "epoch 171| loss: 0.67963 | train_accuracy: 0.71939 | valid_accuracy: 0.68844 |  0:00:16s\n",
      "epoch 172| loss: 0.66539 | train_accuracy: 0.72364 | valid_accuracy: 0.69388 |  0:00:16s\n",
      "epoch 173| loss: 0.66571 | train_accuracy: 0.72517 | valid_accuracy: 0.7     |  0:00:16s\n",
      "epoch 174| loss: 0.6657  | train_accuracy: 0.72075 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 175| loss: 0.6648  | train_accuracy: 0.72432 | valid_accuracy: 0.6966  |  0:00:16s\n",
      "epoch 176| loss: 0.66868 | train_accuracy: 0.72313 | valid_accuracy: 0.70068 |  0:00:16s\n",
      "epoch 177| loss: 0.66952 | train_accuracy: 0.72959 | valid_accuracy: 0.70816 |  0:00:16s\n",
      "epoch 178| loss: 0.6705  | train_accuracy: 0.72245 | valid_accuracy: 0.69524 |  0:00:16s\n",
      "epoch 179| loss: 0.67791 | train_accuracy: 0.72262 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 180| loss: 0.66648 | train_accuracy: 0.72194 | valid_accuracy: 0.70408 |  0:00:17s\n",
      "epoch 181| loss: 0.66588 | train_accuracy: 0.72364 | valid_accuracy: 0.7     |  0:00:17s\n",
      "epoch 182| loss: 0.67022 | train_accuracy: 0.7216  | valid_accuracy: 0.68639 |  0:00:17s\n",
      "epoch 183| loss: 0.67812 | train_accuracy: 0.72415 | valid_accuracy: 0.69252 |  0:00:17s\n",
      "epoch 184| loss: 0.66393 | train_accuracy: 0.72296 | valid_accuracy: 0.69184 |  0:00:17s\n",
      "epoch 185| loss: 0.67565 | train_accuracy: 0.72517 | valid_accuracy: 0.7     |  0:00:17s\n",
      "epoch 186| loss: 0.67243 | train_accuracy: 0.72279 | valid_accuracy: 0.70136 |  0:00:17s\n",
      "epoch 187| loss: 0.65133 | train_accuracy: 0.71735 | valid_accuracy: 0.69932 |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188| loss: 0.68419 | train_accuracy: 0.72687 | valid_accuracy: 0.69524 |  0:00:17s\n",
      "epoch 189| loss: 0.67067 | train_accuracy: 0.7216  | valid_accuracy: 0.69388 |  0:00:17s\n",
      "epoch 190| loss: 0.67456 | train_accuracy: 0.72857 | valid_accuracy: 0.70544 |  0:00:18s\n",
      "epoch 191| loss: 0.65541 | train_accuracy: 0.72466 | valid_accuracy: 0.70272 |  0:00:18s\n",
      "epoch 192| loss: 0.66493 | train_accuracy: 0.72636 | valid_accuracy: 0.70476 |  0:00:18s\n",
      "epoch 193| loss: 0.66509 | train_accuracy: 0.72483 | valid_accuracy: 0.70816 |  0:00:18s\n",
      "epoch 194| loss: 0.67433 | train_accuracy: 0.72908 | valid_accuracy: 0.71088 |  0:00:18s\n",
      "epoch 195| loss: 0.66063 | train_accuracy: 0.73095 | valid_accuracy: 0.70136 |  0:00:18s\n",
      "epoch 196| loss: 0.66502 | train_accuracy: 0.72653 | valid_accuracy: 0.69252 |  0:00:18s\n",
      "epoch 197| loss: 0.67643 | train_accuracy: 0.72262 | valid_accuracy: 0.70136 |  0:00:18s\n",
      "epoch 198| loss: 0.65234 | train_accuracy: 0.72687 | valid_accuracy: 0.70476 |  0:00:18s\n",
      "epoch 199| loss: 0.66488 | train_accuracy: 0.72636 | valid_accuracy: 0.6966  |  0:00:18s\n",
      "epoch 200| loss: 0.66715 | train_accuracy: 0.73044 | valid_accuracy: 0.70748 |  0:00:18s\n",
      "epoch 201| loss: 0.67456 | train_accuracy: 0.72398 | valid_accuracy: 0.69796 |  0:00:19s\n",
      "epoch 202| loss: 0.65982 | train_accuracy: 0.72347 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 203| loss: 0.67493 | train_accuracy: 0.72721 | valid_accuracy: 0.69728 |  0:00:19s\n",
      "epoch 204| loss: 0.66155 | train_accuracy: 0.7267  | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 205| loss: 0.65949 | train_accuracy: 0.72585 | valid_accuracy: 0.7034  |  0:00:19s\n",
      "epoch 206| loss: 0.66424 | train_accuracy: 0.72925 | valid_accuracy: 0.70408 |  0:00:19s\n",
      "epoch 207| loss: 0.6639  | train_accuracy: 0.73112 | valid_accuracy: 0.7034  |  0:00:19s\n",
      "epoch 208| loss: 0.66023 | train_accuracy: 0.73095 | valid_accuracy: 0.7     |  0:00:19s\n",
      "epoch 209| loss: 0.65998 | train_accuracy: 0.73537 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 210| loss: 0.66857 | train_accuracy: 0.72585 | valid_accuracy: 0.70136 |  0:00:19s\n",
      "epoch 211| loss: 0.65461 | train_accuracy: 0.72279 | valid_accuracy: 0.7     |  0:00:19s\n",
      "epoch 212| loss: 0.66297 | train_accuracy: 0.72908 | valid_accuracy: 0.70272 |  0:00:20s\n",
      "epoch 213| loss: 0.66027 | train_accuracy: 0.7284  | valid_accuracy: 0.72041 |  0:00:20s\n",
      "epoch 214| loss: 0.67456 | train_accuracy: 0.73401 | valid_accuracy: 0.70816 |  0:00:20s\n",
      "epoch 215| loss: 0.65908 | train_accuracy: 0.7369  | valid_accuracy: 0.70408 |  0:00:20s\n",
      "epoch 216| loss: 0.65874 | train_accuracy: 0.73622 | valid_accuracy: 0.70272 |  0:00:20s\n",
      "epoch 217| loss: 0.64917 | train_accuracy: 0.73452 | valid_accuracy: 0.71088 |  0:00:20s\n",
      "epoch 218| loss: 0.64354 | train_accuracy: 0.73044 | valid_accuracy: 0.70748 |  0:00:20s\n",
      "epoch 219| loss: 0.64789 | train_accuracy: 0.73316 | valid_accuracy: 0.70476 |  0:00:20s\n",
      "epoch 220| loss: 0.66689 | train_accuracy: 0.7352  | valid_accuracy: 0.70408 |  0:00:20s\n",
      "epoch 221| loss: 0.66216 | train_accuracy: 0.72704 | valid_accuracy: 0.69456 |  0:00:20s\n",
      "epoch 222| loss: 0.65637 | train_accuracy: 0.72789 | valid_accuracy: 0.70476 |  0:00:21s\n",
      "epoch 223| loss: 0.67914 | train_accuracy: 0.73163 | valid_accuracy: 0.7068  |  0:00:21s\n",
      "epoch 224| loss: 0.65484 | train_accuracy: 0.73027 | valid_accuracy: 0.70408 |  0:00:21s\n",
      "epoch 225| loss: 0.65903 | train_accuracy: 0.72721 | valid_accuracy: 0.69796 |  0:00:21s\n",
      "epoch 226| loss: 0.65937 | train_accuracy: 0.73129 | valid_accuracy: 0.70544 |  0:00:21s\n",
      "epoch 227| loss: 0.64882 | train_accuracy: 0.73248 | valid_accuracy: 0.70544 |  0:00:21s\n",
      "epoch 228| loss: 0.67114 | train_accuracy: 0.72908 | valid_accuracy: 0.70136 |  0:00:21s\n",
      "epoch 229| loss: 0.64649 | train_accuracy: 0.73061 | valid_accuracy: 0.70952 |  0:00:21s\n",
      "epoch 230| loss: 0.64551 | train_accuracy: 0.73605 | valid_accuracy: 0.71088 |  0:00:21s\n",
      "epoch 231| loss: 0.64557 | train_accuracy: 0.73503 | valid_accuracy: 0.70816 |  0:00:21s\n",
      "epoch 232| loss: 0.66494 | train_accuracy: 0.73759 | valid_accuracy: 0.70476 |  0:00:21s\n",
      "epoch 233| loss: 0.65147 | train_accuracy: 0.73316 | valid_accuracy: 0.70748 |  0:00:22s\n",
      "epoch 234| loss: 0.64924 | train_accuracy: 0.72942 | valid_accuracy: 0.70408 |  0:00:22s\n",
      "epoch 235| loss: 0.65607 | train_accuracy: 0.73588 | valid_accuracy: 0.71293 |  0:00:22s\n",
      "epoch 236| loss: 0.65233 | train_accuracy: 0.73622 | valid_accuracy: 0.71293 |  0:00:22s\n",
      "epoch 237| loss: 0.6607  | train_accuracy: 0.73503 | valid_accuracy: 0.71156 |  0:00:22s\n",
      "epoch 238| loss: 0.64632 | train_accuracy: 0.73452 | valid_accuracy: 0.71497 |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 238 with best_epoch = 213 and best_valid_accuracy = 0.72041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.6219  | train_accuracy: 0.33588 | valid_accuracy: 0.33401 |  0:00:00s\n",
      "epoch 1  | loss: 1.16128 | train_accuracy: 0.31582 | valid_accuracy: 0.31769 |  0:00:00s\n",
      "epoch 2  | loss: 1.05408 | train_accuracy: 0.2949  | valid_accuracy: 0.30068 |  0:00:00s\n",
      "epoch 3  | loss: 0.99992 | train_accuracy: 0.37092 | valid_accuracy: 0.35442 |  0:00:00s\n",
      "epoch 4  | loss: 0.96247 | train_accuracy: 0.34762 | valid_accuracy: 0.3483  |  0:00:00s\n",
      "epoch 5  | loss: 0.95919 | train_accuracy: 0.37177 | valid_accuracy: 0.36395 |  0:00:00s\n",
      "epoch 6  | loss: 0.92373 | train_accuracy: 0.46616 | valid_accuracy: 0.45918 |  0:00:00s\n",
      "epoch 7  | loss: 0.91329 | train_accuracy: 0.53163 | valid_accuracy: 0.51701 |  0:00:00s\n",
      "epoch 8  | loss: 0.90408 | train_accuracy: 0.49558 | valid_accuracy: 0.48299 |  0:00:00s\n",
      "epoch 9  | loss: 0.87807 | train_accuracy: 0.40391 | valid_accuracy: 0.41156 |  0:00:00s\n",
      "epoch 10 | loss: 0.88828 | train_accuracy: 0.39422 | valid_accuracy: 0.40476 |  0:00:01s\n",
      "epoch 11 | loss: 0.87849 | train_accuracy: 0.39269 | valid_accuracy: 0.41293 |  0:00:01s\n",
      "epoch 12 | loss: 0.87732 | train_accuracy: 0.43367 | valid_accuracy: 0.44014 |  0:00:01s\n",
      "epoch 13 | loss: 0.8602  | train_accuracy: 0.41088 | valid_accuracy: 0.41973 |  0:00:01s\n",
      "epoch 14 | loss: 0.86205 | train_accuracy: 0.44524 | valid_accuracy: 0.44354 |  0:00:01s\n",
      "epoch 15 | loss: 0.8487  | train_accuracy: 0.39575 | valid_accuracy: 0.39864 |  0:00:01s\n",
      "epoch 16 | loss: 0.84122 | train_accuracy: 0.39983 | valid_accuracy: 0.39932 |  0:00:01s\n",
      "epoch 17 | loss: 0.84195 | train_accuracy: 0.5085  | valid_accuracy: 0.5     |  0:00:01s\n",
      "epoch 18 | loss: 0.83797 | train_accuracy: 0.54762 | valid_accuracy: 0.53061 |  0:00:01s\n",
      "epoch 19 | loss: 0.82605 | train_accuracy: 0.53741 | valid_accuracy: 0.51088 |  0:00:01s\n",
      "epoch 20 | loss: 0.82799 | train_accuracy: 0.55578 | valid_accuracy: 0.53401 |  0:00:01s\n",
      "epoch 21 | loss: 0.83243 | train_accuracy: 0.58078 | valid_accuracy: 0.58163 |  0:00:02s\n",
      "epoch 22 | loss: 0.82751 | train_accuracy: 0.56412 | valid_accuracy: 0.55102 |  0:00:02s\n",
      "epoch 23 | loss: 0.81681 | train_accuracy: 0.58299 | valid_accuracy: 0.58163 |  0:00:02s\n",
      "epoch 24 | loss: 0.8247  | train_accuracy: 0.58146 | valid_accuracy: 0.58231 |  0:00:02s\n",
      "epoch 25 | loss: 0.82333 | train_accuracy: 0.59048 | valid_accuracy: 0.58844 |  0:00:02s\n",
      "epoch 26 | loss: 0.80752 | train_accuracy: 0.58435 | valid_accuracy: 0.57619 |  0:00:02s\n",
      "epoch 27 | loss: 0.80979 | train_accuracy: 0.59949 | valid_accuracy: 0.59388 |  0:00:02s\n",
      "epoch 28 | loss: 0.79554 | train_accuracy: 0.59099 | valid_accuracy: 0.59184 |  0:00:02s\n",
      "epoch 29 | loss: 0.80974 | train_accuracy: 0.6034  | valid_accuracy: 0.59388 |  0:00:02s\n",
      "epoch 30 | loss: 0.80645 | train_accuracy: 0.60238 | valid_accuracy: 0.60068 |  0:00:02s\n",
      "epoch 31 | loss: 0.80875 | train_accuracy: 0.59847 | valid_accuracy: 0.60204 |  0:00:03s\n",
      "epoch 32 | loss: 0.80035 | train_accuracy: 0.6051  | valid_accuracy: 0.59932 |  0:00:03s\n",
      "epoch 33 | loss: 0.8038  | train_accuracy: 0.59201 | valid_accuracy: 0.58844 |  0:00:03s\n",
      "epoch 34 | loss: 0.80054 | train_accuracy: 0.58895 | valid_accuracy: 0.58844 |  0:00:03s\n",
      "epoch 35 | loss: 0.81981 | train_accuracy: 0.61156 | valid_accuracy: 0.59864 |  0:00:03s\n",
      "epoch 36 | loss: 0.80109 | train_accuracy: 0.62602 | valid_accuracy: 0.61565 |  0:00:03s\n",
      "epoch 37 | loss: 0.79156 | train_accuracy: 0.62874 | valid_accuracy: 0.60884 |  0:00:03s\n",
      "epoch 38 | loss: 0.79593 | train_accuracy: 0.62721 | valid_accuracy: 0.61905 |  0:00:03s\n",
      "epoch 39 | loss: 0.77731 | train_accuracy: 0.63639 | valid_accuracy: 0.61088 |  0:00:03s\n",
      "epoch 40 | loss: 0.7732  | train_accuracy: 0.62653 | valid_accuracy: 0.61701 |  0:00:03s\n",
      "epoch 41 | loss: 0.76396 | train_accuracy: 0.63299 | valid_accuracy: 0.62449 |  0:00:04s\n",
      "epoch 42 | loss: 0.7901  | train_accuracy: 0.62959 | valid_accuracy: 0.60884 |  0:00:04s\n",
      "epoch 43 | loss: 0.77527 | train_accuracy: 0.64371 | valid_accuracy: 0.62041 |  0:00:04s\n",
      "epoch 44 | loss: 0.77461 | train_accuracy: 0.65068 | valid_accuracy: 0.64558 |  0:00:04s\n",
      "epoch 45 | loss: 0.77889 | train_accuracy: 0.6449  | valid_accuracy: 0.61837 |  0:00:04s\n",
      "epoch 46 | loss: 0.76202 | train_accuracy: 0.64303 | valid_accuracy: 0.62177 |  0:00:04s\n",
      "epoch 47 | loss: 0.77282 | train_accuracy: 0.64252 | valid_accuracy: 0.62925 |  0:00:04s\n",
      "epoch 48 | loss: 0.7636  | train_accuracy: 0.64099 | valid_accuracy: 0.61769 |  0:00:04s\n",
      "epoch 49 | loss: 0.76856 | train_accuracy: 0.64507 | valid_accuracy: 0.63605 |  0:00:04s\n",
      "epoch 50 | loss: 0.75755 | train_accuracy: 0.64796 | valid_accuracy: 0.62993 |  0:00:04s\n",
      "epoch 51 | loss: 0.75795 | train_accuracy: 0.65646 | valid_accuracy: 0.63401 |  0:00:04s\n",
      "epoch 52 | loss: 0.76342 | train_accuracy: 0.66207 | valid_accuracy: 0.64286 |  0:00:05s\n",
      "epoch 53 | loss: 0.7654  | train_accuracy: 0.66224 | valid_accuracy: 0.65102 |  0:00:05s\n",
      "epoch 54 | loss: 0.75849 | train_accuracy: 0.65374 | valid_accuracy: 0.62449 |  0:00:05s\n",
      "epoch 55 | loss: 0.75705 | train_accuracy: 0.66276 | valid_accuracy: 0.63265 |  0:00:05s\n",
      "epoch 56 | loss: 0.76233 | train_accuracy: 0.65867 | valid_accuracy: 0.64762 |  0:00:05s\n",
      "epoch 57 | loss: 0.74436 | train_accuracy: 0.66088 | valid_accuracy: 0.63605 |  0:00:05s\n",
      "epoch 58 | loss: 0.7569  | train_accuracy: 0.6619  | valid_accuracy: 0.65578 |  0:00:05s\n",
      "epoch 59 | loss: 0.75672 | train_accuracy: 0.6602  | valid_accuracy: 0.63673 |  0:00:05s\n",
      "epoch 60 | loss: 0.74812 | train_accuracy: 0.67058 | valid_accuracy: 0.65986 |  0:00:05s\n",
      "epoch 61 | loss: 0.7322  | train_accuracy: 0.6665  | valid_accuracy: 0.65102 |  0:00:05s\n",
      "epoch 62 | loss: 0.75306 | train_accuracy: 0.67194 | valid_accuracy: 0.65238 |  0:00:05s\n",
      "epoch 63 | loss: 0.73929 | train_accuracy: 0.67177 | valid_accuracy: 0.64626 |  0:00:06s\n",
      "epoch 64 | loss: 0.75601 | train_accuracy: 0.67398 | valid_accuracy: 0.63946 |  0:00:06s\n",
      "epoch 65 | loss: 0.74223 | train_accuracy: 0.68639 | valid_accuracy: 0.64558 |  0:00:06s\n",
      "epoch 66 | loss: 0.72961 | train_accuracy: 0.66361 | valid_accuracy: 0.64082 |  0:00:06s\n",
      "epoch 67 | loss: 0.73276 | train_accuracy: 0.6835  | valid_accuracy: 0.6483  |  0:00:06s\n",
      "epoch 68 | loss: 0.74087 | train_accuracy: 0.68724 | valid_accuracy: 0.65102 |  0:00:06s\n",
      "epoch 69 | loss: 0.72479 | train_accuracy: 0.68878 | valid_accuracy: 0.66122 |  0:00:06s\n",
      "epoch 70 | loss: 0.73856 | train_accuracy: 0.69116 | valid_accuracy: 0.6585  |  0:00:06s\n",
      "epoch 71 | loss: 0.72579 | train_accuracy: 0.69167 | valid_accuracy: 0.66259 |  0:00:06s\n",
      "epoch 72 | loss: 0.72138 | train_accuracy: 0.68163 | valid_accuracy: 0.65102 |  0:00:06s\n",
      "epoch 73 | loss: 0.70753 | train_accuracy: 0.6898  | valid_accuracy: 0.67143 |  0:00:06s\n",
      "epoch 74 | loss: 0.72707 | train_accuracy: 0.6801  | valid_accuracy: 0.66395 |  0:00:07s\n",
      "epoch 75 | loss: 0.73329 | train_accuracy: 0.69133 | valid_accuracy: 0.66871 |  0:00:07s\n",
      "epoch 76 | loss: 0.72875 | train_accuracy: 0.69473 | valid_accuracy: 0.6585  |  0:00:07s\n",
      "epoch 77 | loss: 0.73537 | train_accuracy: 0.69133 | valid_accuracy: 0.66054 |  0:00:07s\n",
      "epoch 78 | loss: 0.72085 | train_accuracy: 0.69048 | valid_accuracy: 0.6551  |  0:00:07s\n",
      "epoch 79 | loss: 0.72167 | train_accuracy: 0.68095 | valid_accuracy: 0.65918 |  0:00:07s\n",
      "epoch 80 | loss: 0.72607 | train_accuracy: 0.68912 | valid_accuracy: 0.6551  |  0:00:07s\n",
      "epoch 81 | loss: 0.71988 | train_accuracy: 0.69388 | valid_accuracy: 0.66327 |  0:00:07s\n",
      "epoch 82 | loss: 0.70151 | train_accuracy: 0.6949  | valid_accuracy: 0.65986 |  0:00:07s\n",
      "epoch 83 | loss: 0.71526 | train_accuracy: 0.70238 | valid_accuracy: 0.67483 |  0:00:07s\n",
      "epoch 84 | loss: 0.70586 | train_accuracy: 0.69388 | valid_accuracy: 0.66531 |  0:00:08s\n",
      "epoch 85 | loss: 0.72074 | train_accuracy: 0.69286 | valid_accuracy: 0.66395 |  0:00:08s\n",
      "epoch 86 | loss: 0.72581 | train_accuracy: 0.69711 | valid_accuracy: 0.66327 |  0:00:08s\n",
      "epoch 87 | loss: 0.71131 | train_accuracy: 0.70085 | valid_accuracy: 0.66463 |  0:00:08s\n",
      "epoch 88 | loss: 0.71193 | train_accuracy: 0.68895 | valid_accuracy: 0.66531 |  0:00:08s\n",
      "epoch 89 | loss: 0.70614 | train_accuracy: 0.69524 | valid_accuracy: 0.66463 |  0:00:08s\n",
      "epoch 90 | loss: 0.70875 | train_accuracy: 0.70527 | valid_accuracy: 0.66667 |  0:00:08s\n",
      "epoch 91 | loss: 0.71469 | train_accuracy: 0.70833 | valid_accuracy: 0.67347 |  0:00:08s\n",
      "epoch 92 | loss: 0.70945 | train_accuracy: 0.6932  | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 93 | loss: 0.70376 | train_accuracy: 0.69745 | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 94 | loss: 0.70661 | train_accuracy: 0.70221 | valid_accuracy: 0.65578 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 | loss: 0.71226 | train_accuracy: 0.6983  | valid_accuracy: 0.66531 |  0:00:09s\n",
      "epoch 96 | loss: 0.71646 | train_accuracy: 0.70119 | valid_accuracy: 0.64626 |  0:00:09s\n",
      "epoch 97 | loss: 0.71079 | train_accuracy: 0.7017  | valid_accuracy: 0.6585  |  0:00:09s\n",
      "epoch 98 | loss: 0.70677 | train_accuracy: 0.69881 | valid_accuracy: 0.66259 |  0:00:09s\n",
      "epoch 99 | loss: 0.70854 | train_accuracy: 0.70799 | valid_accuracy: 0.65986 |  0:00:09s\n",
      "epoch 100| loss: 0.69734 | train_accuracy: 0.70714 | valid_accuracy: 0.67007 |  0:00:09s\n",
      "epoch 101| loss: 0.69255 | train_accuracy: 0.70527 | valid_accuracy: 0.66735 |  0:00:09s\n",
      "epoch 102| loss: 0.70392 | train_accuracy: 0.70187 | valid_accuracy: 0.66463 |  0:00:09s\n",
      "epoch 103| loss: 0.69382 | train_accuracy: 0.70595 | valid_accuracy: 0.65918 |  0:00:09s\n",
      "epoch 104| loss: 0.69596 | train_accuracy: 0.70714 | valid_accuracy: 0.66803 |  0:00:09s\n",
      "epoch 105| loss: 0.70403 | train_accuracy: 0.70714 | valid_accuracy: 0.66395 |  0:00:09s\n",
      "epoch 106| loss: 0.68784 | train_accuracy: 0.7148  | valid_accuracy: 0.67891 |  0:00:10s\n",
      "epoch 107| loss: 0.69637 | train_accuracy: 0.7119  | valid_accuracy: 0.66599 |  0:00:10s\n",
      "epoch 108| loss: 0.69557 | train_accuracy: 0.7182  | valid_accuracy: 0.67823 |  0:00:10s\n",
      "epoch 109| loss: 0.70309 | train_accuracy: 0.71224 | valid_accuracy: 0.67075 |  0:00:10s\n",
      "epoch 110| loss: 0.68704 | train_accuracy: 0.72092 | valid_accuracy: 0.67891 |  0:00:10s\n",
      "epoch 111| loss: 0.68757 | train_accuracy: 0.71922 | valid_accuracy: 0.67483 |  0:00:10s\n",
      "epoch 112| loss: 0.68668 | train_accuracy: 0.71105 | valid_accuracy: 0.66531 |  0:00:10s\n",
      "epoch 113| loss: 0.68587 | train_accuracy: 0.71837 | valid_accuracy: 0.67959 |  0:00:10s\n",
      "epoch 114| loss: 0.68086 | train_accuracy: 0.72228 | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 115| loss: 0.69128 | train_accuracy: 0.72024 | valid_accuracy: 0.67211 |  0:00:10s\n",
      "epoch 116| loss: 0.6848  | train_accuracy: 0.71701 | valid_accuracy: 0.67143 |  0:00:11s\n",
      "epoch 117| loss: 0.70199 | train_accuracy: 0.71327 | valid_accuracy: 0.65986 |  0:00:11s\n",
      "epoch 118| loss: 0.69577 | train_accuracy: 0.70731 | valid_accuracy: 0.66735 |  0:00:11s\n",
      "epoch 119| loss: 0.68636 | train_accuracy: 0.7051  | valid_accuracy: 0.66735 |  0:00:11s\n",
      "epoch 120| loss: 0.69102 | train_accuracy: 0.7131  | valid_accuracy: 0.66803 |  0:00:11s\n",
      "epoch 121| loss: 0.68252 | train_accuracy: 0.72211 | valid_accuracy: 0.68299 |  0:00:11s\n",
      "epoch 122| loss: 0.67979 | train_accuracy: 0.71803 | valid_accuracy: 0.67619 |  0:00:11s\n",
      "epoch 123| loss: 0.68873 | train_accuracy: 0.7085  | valid_accuracy: 0.67755 |  0:00:11s\n",
      "epoch 124| loss: 0.67694 | train_accuracy: 0.72092 | valid_accuracy: 0.68231 |  0:00:11s\n",
      "epoch 125| loss: 0.6856  | train_accuracy: 0.72585 | valid_accuracy: 0.68163 |  0:00:11s\n",
      "epoch 126| loss: 0.66768 | train_accuracy: 0.73061 | valid_accuracy: 0.68503 |  0:00:12s\n",
      "epoch 127| loss: 0.67207 | train_accuracy: 0.72449 | valid_accuracy: 0.69524 |  0:00:12s\n",
      "epoch 128| loss: 0.67068 | train_accuracy: 0.72143 | valid_accuracy: 0.68435 |  0:00:12s\n",
      "epoch 129| loss: 0.66212 | train_accuracy: 0.72364 | valid_accuracy: 0.67483 |  0:00:12s\n",
      "epoch 130| loss: 0.67708 | train_accuracy: 0.72891 | valid_accuracy: 0.68367 |  0:00:12s\n",
      "epoch 131| loss: 0.67846 | train_accuracy: 0.73214 | valid_accuracy: 0.68707 |  0:00:12s\n",
      "epoch 132| loss: 0.6588  | train_accuracy: 0.73571 | valid_accuracy: 0.68299 |  0:00:12s\n",
      "epoch 133| loss: 0.66209 | train_accuracy: 0.72806 | valid_accuracy: 0.67959 |  0:00:12s\n",
      "epoch 134| loss: 0.65954 | train_accuracy: 0.72755 | valid_accuracy: 0.68367 |  0:00:12s\n",
      "epoch 135| loss: 0.67586 | train_accuracy: 0.73197 | valid_accuracy: 0.68367 |  0:00:12s\n",
      "epoch 136| loss: 0.6664  | train_accuracy: 0.72738 | valid_accuracy: 0.69048 |  0:00:12s\n",
      "epoch 137| loss: 0.68195 | train_accuracy: 0.72874 | valid_accuracy: 0.68639 |  0:00:13s\n",
      "epoch 138| loss: 0.66158 | train_accuracy: 0.71412 | valid_accuracy: 0.67415 |  0:00:13s\n",
      "epoch 139| loss: 0.66703 | train_accuracy: 0.72347 | valid_accuracy: 0.68503 |  0:00:13s\n",
      "epoch 140| loss: 0.67375 | train_accuracy: 0.74252 | valid_accuracy: 0.70068 |  0:00:13s\n",
      "epoch 141| loss: 0.65439 | train_accuracy: 0.74218 | valid_accuracy: 0.7034  |  0:00:13s\n",
      "epoch 142| loss: 0.67469 | train_accuracy: 0.73163 | valid_accuracy: 0.69456 |  0:00:13s\n",
      "epoch 143| loss: 0.67645 | train_accuracy: 0.73673 | valid_accuracy: 0.69524 |  0:00:13s\n",
      "epoch 144| loss: 0.65464 | train_accuracy: 0.73793 | valid_accuracy: 0.68912 |  0:00:13s\n",
      "epoch 145| loss: 0.65806 | train_accuracy: 0.73231 | valid_accuracy: 0.70204 |  0:00:13s\n",
      "epoch 146| loss: 0.65527 | train_accuracy: 0.7284  | valid_accuracy: 0.68707 |  0:00:13s\n",
      "epoch 147| loss: 0.6601  | train_accuracy: 0.73316 | valid_accuracy: 0.69524 |  0:00:13s\n",
      "epoch 148| loss: 0.65679 | train_accuracy: 0.73861 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 149| loss: 0.66438 | train_accuracy: 0.7301  | valid_accuracy: 0.6898  |  0:00:14s\n",
      "epoch 150| loss: 0.6678  | train_accuracy: 0.74082 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 151| loss: 0.65209 | train_accuracy: 0.73741 | valid_accuracy: 0.69456 |  0:00:14s\n",
      "epoch 152| loss: 0.65583 | train_accuracy: 0.74252 | valid_accuracy: 0.69932 |  0:00:14s\n",
      "epoch 153| loss: 0.65125 | train_accuracy: 0.74864 | valid_accuracy: 0.7034  |  0:00:14s\n",
      "epoch 154| loss: 0.65518 | train_accuracy: 0.73333 | valid_accuracy: 0.68912 |  0:00:14s\n",
      "epoch 155| loss: 0.6519  | train_accuracy: 0.74405 | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 156| loss: 0.66137 | train_accuracy: 0.7335  | valid_accuracy: 0.69932 |  0:00:14s\n",
      "epoch 157| loss: 0.64363 | train_accuracy: 0.7335  | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 158| loss: 0.6656  | train_accuracy: 0.74609 | valid_accuracy: 0.69796 |  0:00:14s\n",
      "epoch 159| loss: 0.64492 | train_accuracy: 0.75017 | valid_accuracy: 0.7068  |  0:00:15s\n",
      "epoch 160| loss: 0.64964 | train_accuracy: 0.75391 | valid_accuracy: 0.71293 |  0:00:15s\n",
      "epoch 161| loss: 0.66294 | train_accuracy: 0.75578 | valid_accuracy: 0.70408 |  0:00:15s\n",
      "epoch 162| loss: 0.6418  | train_accuracy: 0.75255 | valid_accuracy: 0.70136 |  0:00:15s\n",
      "epoch 163| loss: 0.65226 | train_accuracy: 0.74575 | valid_accuracy: 0.69932 |  0:00:15s\n",
      "epoch 164| loss: 0.64865 | train_accuracy: 0.74762 | valid_accuracy: 0.70272 |  0:00:15s\n",
      "epoch 165| loss: 0.64872 | train_accuracy: 0.74082 | valid_accuracy: 0.68707 |  0:00:15s\n",
      "epoch 166| loss: 0.65339 | train_accuracy: 0.7517  | valid_accuracy: 0.70612 |  0:00:15s\n",
      "epoch 167| loss: 0.65696 | train_accuracy: 0.74337 | valid_accuracy: 0.70544 |  0:00:15s\n",
      "epoch 168| loss: 0.64017 | train_accuracy: 0.74847 | valid_accuracy: 0.69456 |  0:00:15s\n",
      "epoch 169| loss: 0.65208 | train_accuracy: 0.74286 | valid_accuracy: 0.70408 |  0:00:16s\n",
      "epoch 170| loss: 0.6398  | train_accuracy: 0.74694 | valid_accuracy: 0.70612 |  0:00:16s\n",
      "epoch 171| loss: 0.64604 | train_accuracy: 0.74626 | valid_accuracy: 0.69592 |  0:00:16s\n",
      "epoch 172| loss: 0.64341 | train_accuracy: 0.75017 | valid_accuracy: 0.70748 |  0:00:16s\n",
      "epoch 173| loss: 0.62955 | train_accuracy: 0.74082 | valid_accuracy: 0.69524 |  0:00:16s\n",
      "epoch 174| loss: 0.63625 | train_accuracy: 0.75323 | valid_accuracy: 0.7     |  0:00:16s\n",
      "epoch 175| loss: 0.6341  | train_accuracy: 0.75136 | valid_accuracy: 0.70612 |  0:00:16s\n",
      "epoch 176| loss: 0.64144 | train_accuracy: 0.75391 | valid_accuracy: 0.71565 |  0:00:16s\n",
      "epoch 177| loss: 0.64204 | train_accuracy: 0.73895 | valid_accuracy: 0.6932  |  0:00:16s\n",
      "epoch 178| loss: 0.63973 | train_accuracy: 0.74898 | valid_accuracy: 0.70884 |  0:00:16s\n",
      "epoch 179| loss: 0.6404  | train_accuracy: 0.74218 | valid_accuracy: 0.70204 |  0:00:16s\n",
      "epoch 180| loss: 0.63993 | train_accuracy: 0.74796 | valid_accuracy: 0.71156 |  0:00:17s\n",
      "epoch 181| loss: 0.63953 | train_accuracy: 0.74728 | valid_accuracy: 0.71429 |  0:00:17s\n",
      "epoch 182| loss: 0.64202 | train_accuracy: 0.75323 | valid_accuracy: 0.71224 |  0:00:17s\n",
      "epoch 183| loss: 0.62247 | train_accuracy: 0.75153 | valid_accuracy: 0.7102  |  0:00:17s\n",
      "epoch 184| loss: 0.63238 | train_accuracy: 0.75068 | valid_accuracy: 0.7068  |  0:00:17s\n",
      "epoch 185| loss: 0.64519 | train_accuracy: 0.75187 | valid_accuracy: 0.70272 |  0:00:17s\n",
      "epoch 186| loss: 0.62781 | train_accuracy: 0.75051 | valid_accuracy: 0.70884 |  0:00:17s\n",
      "epoch 187| loss: 0.63493 | train_accuracy: 0.74201 | valid_accuracy: 0.70136 |  0:00:17s\n",
      "epoch 188| loss: 0.63145 | train_accuracy: 0.75051 | valid_accuracy: 0.71156 |  0:00:17s\n",
      "epoch 189| loss: 0.64442 | train_accuracy: 0.74762 | valid_accuracy: 0.7     |  0:00:17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190| loss: 0.63957 | train_accuracy: 0.75102 | valid_accuracy: 0.70612 |  0:00:17s\n",
      "epoch 191| loss: 0.64267 | train_accuracy: 0.76173 | valid_accuracy: 0.72517 |  0:00:18s\n",
      "epoch 192| loss: 0.64347 | train_accuracy: 0.75085 | valid_accuracy: 0.71361 |  0:00:18s\n",
      "epoch 193| loss: 0.63297 | train_accuracy: 0.75357 | valid_accuracy: 0.71361 |  0:00:18s\n",
      "epoch 194| loss: 0.63961 | train_accuracy: 0.74711 | valid_accuracy: 0.69864 |  0:00:18s\n",
      "epoch 195| loss: 0.6404  | train_accuracy: 0.7466  | valid_accuracy: 0.6966  |  0:00:18s\n",
      "epoch 196| loss: 0.63606 | train_accuracy: 0.75544 | valid_accuracy: 0.71224 |  0:00:18s\n",
      "epoch 197| loss: 0.63664 | train_accuracy: 0.75816 | valid_accuracy: 0.71156 |  0:00:18s\n",
      "epoch 198| loss: 0.63927 | train_accuracy: 0.76037 | valid_accuracy: 0.71293 |  0:00:18s\n",
      "epoch 199| loss: 0.62694 | train_accuracy: 0.7551  | valid_accuracy: 0.7068  |  0:00:18s\n",
      "epoch 200| loss: 0.62261 | train_accuracy: 0.74847 | valid_accuracy: 0.7034  |  0:00:18s\n",
      "epoch 201| loss: 0.64087 | train_accuracy: 0.75731 | valid_accuracy: 0.71497 |  0:00:19s\n",
      "epoch 202| loss: 0.62742 | train_accuracy: 0.76463 | valid_accuracy: 0.71293 |  0:00:19s\n",
      "epoch 203| loss: 0.63286 | train_accuracy: 0.75119 | valid_accuracy: 0.71156 |  0:00:19s\n",
      "epoch 204| loss: 0.62704 | train_accuracy: 0.75    | valid_accuracy: 0.70408 |  0:00:19s\n",
      "epoch 205| loss: 0.63671 | train_accuracy: 0.75221 | valid_accuracy: 0.70816 |  0:00:19s\n",
      "epoch 206| loss: 0.64088 | train_accuracy: 0.75493 | valid_accuracy: 0.71293 |  0:00:19s\n",
      "epoch 207| loss: 0.62596 | train_accuracy: 0.75408 | valid_accuracy: 0.71224 |  0:00:19s\n",
      "epoch 208| loss: 0.6403  | train_accuracy: 0.75068 | valid_accuracy: 0.70884 |  0:00:19s\n",
      "epoch 209| loss: 0.63354 | train_accuracy: 0.76241 | valid_accuracy: 0.71769 |  0:00:19s\n",
      "epoch 210| loss: 0.637   | train_accuracy: 0.76139 | valid_accuracy: 0.71497 |  0:00:19s\n",
      "epoch 211| loss: 0.6327  | train_accuracy: 0.76139 | valid_accuracy: 0.71497 |  0:00:20s\n",
      "epoch 212| loss: 0.62751 | train_accuracy: 0.76156 | valid_accuracy: 0.70952 |  0:00:20s\n",
      "epoch 213| loss: 0.62389 | train_accuracy: 0.75867 | valid_accuracy: 0.70544 |  0:00:20s\n",
      "epoch 214| loss: 0.61694 | train_accuracy: 0.75969 | valid_accuracy: 0.71429 |  0:00:20s\n",
      "epoch 215| loss: 0.63406 | train_accuracy: 0.7534  | valid_accuracy: 0.7102  |  0:00:20s\n",
      "epoch 216| loss: 0.61557 | train_accuracy: 0.76378 | valid_accuracy: 0.71088 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 216 with best_epoch = 191 and best_valid_accuracy = 0.72517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:118: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.70919 | train_accuracy: 0.35629 | valid_accuracy: 0.35578 |  0:00:00s\n",
      "epoch 1  | loss: 1.22248 | train_accuracy: 0.38673 | valid_accuracy: 0.38095 |  0:00:00s\n",
      "epoch 2  | loss: 1.09514 | train_accuracy: 0.38299 | valid_accuracy: 0.36395 |  0:00:00s\n",
      "epoch 3  | loss: 1.03716 | train_accuracy: 0.40731 | valid_accuracy: 0.40612 |  0:00:00s\n",
      "epoch 4  | loss: 0.99247 | train_accuracy: 0.41769 | valid_accuracy: 0.41156 |  0:00:00s\n",
      "epoch 5  | loss: 0.97343 | train_accuracy: 0.42534 | valid_accuracy: 0.44082 |  0:00:00s\n",
      "epoch 6  | loss: 0.94536 | train_accuracy: 0.4835  | valid_accuracy: 0.50816 |  0:00:00s\n",
      "epoch 7  | loss: 0.93648 | train_accuracy: 0.48027 | valid_accuracy: 0.51633 |  0:00:00s\n",
      "epoch 8  | loss: 0.9163  | train_accuracy: 0.52075 | valid_accuracy: 0.54014 |  0:00:00s\n",
      "epoch 9  | loss: 0.90844 | train_accuracy: 0.49779 | valid_accuracy: 0.52313 |  0:00:00s\n",
      "epoch 10 | loss: 0.90103 | train_accuracy: 0.47789 | valid_accuracy: 0.49456 |  0:00:01s\n",
      "epoch 11 | loss: 0.89278 | train_accuracy: 0.48265 | valid_accuracy: 0.50748 |  0:00:01s\n",
      "epoch 12 | loss: 0.8876  | train_accuracy: 0.42568 | valid_accuracy: 0.43401 |  0:00:01s\n",
      "epoch 13 | loss: 0.87578 | train_accuracy: 0.45561 | valid_accuracy: 0.47075 |  0:00:01s\n",
      "epoch 14 | loss: 0.87895 | train_accuracy: 0.4233  | valid_accuracy: 0.44218 |  0:00:01s\n",
      "epoch 15 | loss: 0.87319 | train_accuracy: 0.44796 | valid_accuracy: 0.47143 |  0:00:01s\n",
      "epoch 16 | loss: 0.87235 | train_accuracy: 0.46361 | valid_accuracy: 0.48367 |  0:00:01s\n",
      "epoch 17 | loss: 0.8791  | train_accuracy: 0.48469 | valid_accuracy: 0.51361 |  0:00:01s\n",
      "epoch 18 | loss: 0.86393 | train_accuracy: 0.4733  | valid_accuracy: 0.48503 |  0:00:01s\n",
      "epoch 19 | loss: 0.85898 | train_accuracy: 0.49303 | valid_accuracy: 0.51156 |  0:00:01s\n",
      "epoch 20 | loss: 0.84622 | train_accuracy: 0.49966 | valid_accuracy: 0.51973 |  0:00:01s\n",
      "epoch 21 | loss: 0.84016 | train_accuracy: 0.46395 | valid_accuracy: 0.49048 |  0:00:02s\n",
      "epoch 22 | loss: 0.83505 | train_accuracy: 0.48044 | valid_accuracy: 0.49252 |  0:00:02s\n",
      "epoch 23 | loss: 0.83052 | train_accuracy: 0.52976 | valid_accuracy: 0.56939 |  0:00:02s\n",
      "epoch 24 | loss: 0.83713 | train_accuracy: 0.53759 | valid_accuracy: 0.55102 |  0:00:02s\n",
      "epoch 25 | loss: 0.83969 | train_accuracy: 0.54422 | valid_accuracy: 0.56803 |  0:00:02s\n",
      "epoch 26 | loss: 0.81891 | train_accuracy: 0.52279 | valid_accuracy: 0.5415  |  0:00:02s\n",
      "epoch 27 | loss: 0.81678 | train_accuracy: 0.53367 | valid_accuracy: 0.55034 |  0:00:02s\n",
      "epoch 28 | loss: 0.82559 | train_accuracy: 0.54201 | valid_accuracy: 0.55782 |  0:00:02s\n",
      "epoch 29 | loss: 0.81164 | train_accuracy: 0.59915 | valid_accuracy: 0.62993 |  0:00:02s\n",
      "epoch 30 | loss: 0.80494 | train_accuracy: 0.56156 | valid_accuracy: 0.58367 |  0:00:02s\n",
      "epoch 31 | loss: 0.8096  | train_accuracy: 0.56939 | valid_accuracy: 0.59184 |  0:00:02s\n",
      "epoch 32 | loss: 0.80265 | train_accuracy: 0.57194 | valid_accuracy: 0.6034  |  0:00:03s\n",
      "epoch 33 | loss: 0.80674 | train_accuracy: 0.55799 | valid_accuracy: 0.57823 |  0:00:03s\n",
      "epoch 34 | loss: 0.80593 | train_accuracy: 0.54286 | valid_accuracy: 0.55578 |  0:00:03s\n",
      "epoch 35 | loss: 0.80653 | train_accuracy: 0.53844 | valid_accuracy: 0.53878 |  0:00:03s\n",
      "epoch 36 | loss: 0.80307 | train_accuracy: 0.62075 | valid_accuracy: 0.6449  |  0:00:03s\n",
      "epoch 37 | loss: 0.80703 | train_accuracy: 0.61276 | valid_accuracy: 0.62517 |  0:00:03s\n",
      "epoch 38 | loss: 0.80296 | train_accuracy: 0.61037 | valid_accuracy: 0.63197 |  0:00:03s\n",
      "epoch 39 | loss: 0.81029 | train_accuracy: 0.62245 | valid_accuracy: 0.6449  |  0:00:03s\n",
      "epoch 40 | loss: 0.78922 | train_accuracy: 0.62449 | valid_accuracy: 0.64762 |  0:00:03s\n",
      "epoch 41 | loss: 0.78487 | train_accuracy: 0.62806 | valid_accuracy: 0.65578 |  0:00:03s\n",
      "epoch 42 | loss: 0.80557 | train_accuracy: 0.61905 | valid_accuracy: 0.6483  |  0:00:04s\n",
      "epoch 43 | loss: 0.7978  | train_accuracy: 0.61854 | valid_accuracy: 0.65782 |  0:00:04s\n",
      "epoch 44 | loss: 0.79125 | train_accuracy: 0.63673 | valid_accuracy: 0.6619  |  0:00:04s\n",
      "epoch 45 | loss: 0.7936  | train_accuracy: 0.64133 | valid_accuracy: 0.65986 |  0:00:04s\n",
      "epoch 46 | loss: 0.77043 | train_accuracy: 0.63282 | valid_accuracy: 0.6585  |  0:00:04s\n",
      "epoch 47 | loss: 0.77795 | train_accuracy: 0.63231 | valid_accuracy: 0.67143 |  0:00:04s\n",
      "epoch 48 | loss: 0.77955 | train_accuracy: 0.63963 | valid_accuracy: 0.6517  |  0:00:04s\n",
      "epoch 49 | loss: 0.78046 | train_accuracy: 0.62687 | valid_accuracy: 0.6483  |  0:00:04s\n",
      "epoch 50 | loss: 0.77017 | train_accuracy: 0.65748 | valid_accuracy: 0.66871 |  0:00:04s\n",
      "epoch 51 | loss: 0.7649  | train_accuracy: 0.65867 | valid_accuracy: 0.6619  |  0:00:04s\n",
      "epoch 52 | loss: 0.78074 | train_accuracy: 0.63861 | valid_accuracy: 0.6585  |  0:00:04s\n",
      "epoch 53 | loss: 0.77417 | train_accuracy: 0.65969 | valid_accuracy: 0.67415 |  0:00:05s\n",
      "epoch 54 | loss: 0.7625  | train_accuracy: 0.64439 | valid_accuracy: 0.66735 |  0:00:05s\n",
      "epoch 55 | loss: 0.76684 | train_accuracy: 0.63401 | valid_accuracy: 0.65578 |  0:00:05s\n",
      "epoch 56 | loss: 0.76779 | train_accuracy: 0.6585  | valid_accuracy: 0.67075 |  0:00:05s\n",
      "epoch 57 | loss: 0.77072 | train_accuracy: 0.66003 | valid_accuracy: 0.6585  |  0:00:05s\n",
      "epoch 58 | loss: 0.76995 | train_accuracy: 0.65527 | valid_accuracy: 0.66395 |  0:00:05s\n",
      "epoch 59 | loss: 0.75358 | train_accuracy: 0.65629 | valid_accuracy: 0.6619  |  0:00:05s\n",
      "epoch 60 | loss: 0.76431 | train_accuracy: 0.66684 | valid_accuracy: 0.6585  |  0:00:05s\n",
      "epoch 61 | loss: 0.76021 | train_accuracy: 0.65221 | valid_accuracy: 0.66599 |  0:00:05s\n",
      "epoch 62 | loss: 0.75012 | train_accuracy: 0.67228 | valid_accuracy: 0.66667 |  0:00:05s\n",
      "epoch 63 | loss: 0.75018 | train_accuracy: 0.66105 | valid_accuracy: 0.66259 |  0:00:06s\n",
      "epoch 64 | loss: 0.75549 | train_accuracy: 0.66786 | valid_accuracy: 0.67415 |  0:00:06s\n",
      "epoch 65 | loss: 0.75    | train_accuracy: 0.66922 | valid_accuracy: 0.66599 |  0:00:06s\n",
      "epoch 66 | loss: 0.75302 | train_accuracy: 0.66514 | valid_accuracy: 0.65918 |  0:00:06s\n",
      "epoch 67 | loss: 0.75451 | train_accuracy: 0.67466 | valid_accuracy: 0.68571 |  0:00:06s\n",
      "epoch 68 | loss: 0.75334 | train_accuracy: 0.67075 | valid_accuracy: 0.67823 |  0:00:06s\n",
      "epoch 69 | loss: 0.73638 | train_accuracy: 0.66395 | valid_accuracy: 0.67075 |  0:00:06s\n",
      "epoch 70 | loss: 0.74568 | train_accuracy: 0.68078 | valid_accuracy: 0.67075 |  0:00:06s\n",
      "epoch 71 | loss: 0.74633 | train_accuracy: 0.67262 | valid_accuracy: 0.67619 |  0:00:06s\n",
      "epoch 72 | loss: 0.75209 | train_accuracy: 0.66497 | valid_accuracy: 0.66054 |  0:00:06s\n",
      "epoch 73 | loss: 0.7526  | train_accuracy: 0.67313 | valid_accuracy: 0.66735 |  0:00:06s\n",
      "epoch 74 | loss: 0.74809 | train_accuracy: 0.67585 | valid_accuracy: 0.68231 |  0:00:07s\n",
      "epoch 75 | loss: 0.74267 | train_accuracy: 0.66446 | valid_accuracy: 0.67415 |  0:00:07s\n",
      "epoch 76 | loss: 0.74161 | train_accuracy: 0.66837 | valid_accuracy: 0.66395 |  0:00:07s\n",
      "epoch 77 | loss: 0.73502 | train_accuracy: 0.675   | valid_accuracy: 0.67687 |  0:00:07s\n",
      "epoch 78 | loss: 0.73984 | train_accuracy: 0.68265 | valid_accuracy: 0.68844 |  0:00:07s\n",
      "epoch 79 | loss: 0.7335  | train_accuracy: 0.68146 | valid_accuracy: 0.68299 |  0:00:07s\n",
      "epoch 80 | loss: 0.7397  | train_accuracy: 0.66973 | valid_accuracy: 0.67755 |  0:00:07s\n",
      "epoch 81 | loss: 0.7223  | train_accuracy: 0.68027 | valid_accuracy: 0.68299 |  0:00:07s\n",
      "epoch 82 | loss: 0.72656 | train_accuracy: 0.67721 | valid_accuracy: 0.68844 |  0:00:07s\n",
      "epoch 83 | loss: 0.71814 | train_accuracy: 0.68061 | valid_accuracy: 0.67687 |  0:00:07s\n",
      "epoch 84 | loss: 0.73281 | train_accuracy: 0.68997 | valid_accuracy: 0.68027 |  0:00:08s\n",
      "epoch 85 | loss: 0.72783 | train_accuracy: 0.6869  | valid_accuracy: 0.68095 |  0:00:08s\n",
      "epoch 86 | loss: 0.7297  | train_accuracy: 0.67075 | valid_accuracy: 0.65986 |  0:00:08s\n",
      "epoch 87 | loss: 0.72737 | train_accuracy: 0.68435 | valid_accuracy: 0.6932  |  0:00:08s\n",
      "epoch 88 | loss: 0.73552 | train_accuracy: 0.68929 | valid_accuracy: 0.68095 |  0:00:08s\n",
      "epoch 89 | loss: 0.72832 | train_accuracy: 0.67517 | valid_accuracy: 0.66259 |  0:00:08s\n",
      "epoch 90 | loss: 0.72246 | train_accuracy: 0.68469 | valid_accuracy: 0.68367 |  0:00:08s\n",
      "epoch 91 | loss: 0.716   | train_accuracy: 0.68895 | valid_accuracy: 0.69796 |  0:00:08s\n",
      "epoch 92 | loss: 0.72156 | train_accuracy: 0.68401 | valid_accuracy: 0.69388 |  0:00:08s\n",
      "epoch 93 | loss: 0.70686 | train_accuracy: 0.69014 | valid_accuracy: 0.69184 |  0:00:08s\n",
      "epoch 94 | loss: 0.72177 | train_accuracy: 0.69609 | valid_accuracy: 0.67755 |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 | loss: 0.72849 | train_accuracy: 0.6869  | valid_accuracy: 0.67483 |  0:00:09s\n",
      "epoch 96 | loss: 0.72823 | train_accuracy: 0.67364 | valid_accuracy: 0.67483 |  0:00:09s\n",
      "epoch 97 | loss: 0.7028  | train_accuracy: 0.68793 | valid_accuracy: 0.6619  |  0:00:09s\n",
      "epoch 98 | loss: 0.73194 | train_accuracy: 0.66224 | valid_accuracy: 0.65306 |  0:00:09s\n",
      "epoch 99 | loss: 0.71242 | train_accuracy: 0.67874 | valid_accuracy: 0.69048 |  0:00:09s\n",
      "epoch 100| loss: 0.71678 | train_accuracy: 0.67908 | valid_accuracy: 0.68571 |  0:00:09s\n",
      "epoch 101| loss: 0.6995  | train_accuracy: 0.69235 | valid_accuracy: 0.69456 |  0:00:09s\n",
      "epoch 102| loss: 0.69997 | train_accuracy: 0.70102 | valid_accuracy: 0.6966  |  0:00:09s\n",
      "epoch 103| loss: 0.72596 | train_accuracy: 0.68963 | valid_accuracy: 0.68299 |  0:00:09s\n",
      "epoch 104| loss: 0.70917 | train_accuracy: 0.68112 | valid_accuracy: 0.67347 |  0:00:09s\n",
      "epoch 105| loss: 0.69873 | train_accuracy: 0.68741 | valid_accuracy: 0.66939 |  0:00:09s\n",
      "epoch 106| loss: 0.70337 | train_accuracy: 0.70102 | valid_accuracy: 0.69116 |  0:00:10s\n",
      "epoch 107| loss: 0.69859 | train_accuracy: 0.69932 | valid_accuracy: 0.68503 |  0:00:10s\n",
      "epoch 108| loss: 0.70462 | train_accuracy: 0.70136 | valid_accuracy: 0.68912 |  0:00:10s\n",
      "epoch 109| loss: 0.71234 | train_accuracy: 0.70136 | valid_accuracy: 0.6966  |  0:00:10s\n",
      "epoch 110| loss: 0.70209 | train_accuracy: 0.70612 | valid_accuracy: 0.68367 |  0:00:10s\n",
      "epoch 111| loss: 0.70734 | train_accuracy: 0.69626 | valid_accuracy: 0.67619 |  0:00:10s\n",
      "epoch 112| loss: 0.70415 | train_accuracy: 0.70952 | valid_accuracy: 0.69388 |  0:00:10s\n",
      "epoch 113| loss: 0.70653 | train_accuracy: 0.69932 | valid_accuracy: 0.69252 |  0:00:10s\n",
      "epoch 114| loss: 0.69877 | train_accuracy: 0.69983 | valid_accuracy: 0.69048 |  0:00:10s\n",
      "epoch 115| loss: 0.6972  | train_accuracy: 0.70595 | valid_accuracy: 0.70204 |  0:00:10s\n",
      "epoch 116| loss: 0.6854  | train_accuracy: 0.69813 | valid_accuracy: 0.69252 |  0:00:11s\n",
      "epoch 117| loss: 0.70623 | train_accuracy: 0.70204 | valid_accuracy: 0.6898  |  0:00:11s\n",
      "epoch 118| loss: 0.69286 | train_accuracy: 0.70306 | valid_accuracy: 0.68503 |  0:00:11s\n",
      "epoch 119| loss: 0.68525 | train_accuracy: 0.72432 | valid_accuracy: 0.70136 |  0:00:11s\n",
      "epoch 120| loss: 0.70037 | train_accuracy: 0.69558 | valid_accuracy: 0.67891 |  0:00:11s\n",
      "epoch 121| loss: 0.69177 | train_accuracy: 0.70136 | valid_accuracy: 0.6932  |  0:00:11s\n",
      "epoch 122| loss: 0.69229 | train_accuracy: 0.69898 | valid_accuracy: 0.68299 |  0:00:11s\n",
      "epoch 123| loss: 0.68325 | train_accuracy: 0.7068  | valid_accuracy: 0.68095 |  0:00:11s\n",
      "epoch 124| loss: 0.68762 | train_accuracy: 0.71241 | valid_accuracy: 0.69864 |  0:00:11s\n",
      "epoch 125| loss: 0.68384 | train_accuracy: 0.71412 | valid_accuracy: 0.69388 |  0:00:11s\n",
      "epoch 126| loss: 0.68418 | train_accuracy: 0.70833 | valid_accuracy: 0.70408 |  0:00:11s\n",
      "epoch 127| loss: 0.69687 | train_accuracy: 0.7034  | valid_accuracy: 0.69388 |  0:00:12s\n",
      "epoch 128| loss: 0.69293 | train_accuracy: 0.70663 | valid_accuracy: 0.7     |  0:00:12s\n",
      "epoch 129| loss: 0.67165 | train_accuracy: 0.70799 | valid_accuracy: 0.69796 |  0:00:12s\n",
      "epoch 130| loss: 0.68036 | train_accuracy: 0.71037 | valid_accuracy: 0.70816 |  0:00:12s\n",
      "epoch 131| loss: 0.68229 | train_accuracy: 0.70136 | valid_accuracy: 0.6932  |  0:00:12s\n",
      "epoch 132| loss: 0.69585 | train_accuracy: 0.69014 | valid_accuracy: 0.67415 |  0:00:12s\n",
      "epoch 133| loss: 0.68014 | train_accuracy: 0.68793 | valid_accuracy: 0.68027 |  0:00:12s\n",
      "epoch 134| loss: 0.68824 | train_accuracy: 0.70459 | valid_accuracy: 0.70068 |  0:00:12s\n",
      "epoch 135| loss: 0.67856 | train_accuracy: 0.70901 | valid_accuracy: 0.69932 |  0:00:12s\n",
      "epoch 136| loss: 0.68705 | train_accuracy: 0.71395 | valid_accuracy: 0.69456 |  0:00:12s\n",
      "epoch 137| loss: 0.69097 | train_accuracy: 0.71735 | valid_accuracy: 0.70136 |  0:00:12s\n",
      "epoch 138| loss: 0.66959 | train_accuracy: 0.70697 | valid_accuracy: 0.68571 |  0:00:13s\n",
      "epoch 139| loss: 0.6957  | train_accuracy: 0.70918 | valid_accuracy: 0.68095 |  0:00:13s\n",
      "epoch 140| loss: 0.6821  | train_accuracy: 0.72483 | valid_accuracy: 0.69864 |  0:00:13s\n",
      "epoch 141| loss: 0.68127 | train_accuracy: 0.72041 | valid_accuracy: 0.70748 |  0:00:13s\n",
      "epoch 142| loss: 0.67355 | train_accuracy: 0.72806 | valid_accuracy: 0.71429 |  0:00:13s\n",
      "epoch 143| loss: 0.67225 | train_accuracy: 0.72007 | valid_accuracy: 0.69796 |  0:00:13s\n",
      "epoch 144| loss: 0.66875 | train_accuracy: 0.71803 | valid_accuracy: 0.69456 |  0:00:13s\n",
      "epoch 145| loss: 0.67671 | train_accuracy: 0.71871 | valid_accuracy: 0.7068  |  0:00:13s\n",
      "epoch 146| loss: 0.66122 | train_accuracy: 0.71769 | valid_accuracy: 0.70544 |  0:00:13s\n",
      "epoch 147| loss: 0.6755  | train_accuracy: 0.71378 | valid_accuracy: 0.7068  |  0:00:13s\n",
      "epoch 148| loss: 0.67187 | train_accuracy: 0.72313 | valid_accuracy: 0.71156 |  0:00:14s\n",
      "epoch 149| loss: 0.67601 | train_accuracy: 0.72126 | valid_accuracy: 0.70544 |  0:00:14s\n",
      "epoch 150| loss: 0.67938 | train_accuracy: 0.71803 | valid_accuracy: 0.69184 |  0:00:14s\n",
      "epoch 151| loss: 0.66364 | train_accuracy: 0.71973 | valid_accuracy: 0.70204 |  0:00:14s\n",
      "epoch 152| loss: 0.6513  | train_accuracy: 0.7131  | valid_accuracy: 0.69524 |  0:00:14s\n",
      "epoch 153| loss: 0.66936 | train_accuracy: 0.71718 | valid_accuracy: 0.69864 |  0:00:14s\n",
      "epoch 154| loss: 0.6607  | train_accuracy: 0.72075 | valid_accuracy: 0.69864 |  0:00:14s\n",
      "epoch 155| loss: 0.66062 | train_accuracy: 0.72143 | valid_accuracy: 0.69728 |  0:00:14s\n",
      "epoch 156| loss: 0.67371 | train_accuracy: 0.71327 | valid_accuracy: 0.69592 |  0:00:14s\n",
      "epoch 157| loss: 0.67578 | train_accuracy: 0.72653 | valid_accuracy: 0.70816 |  0:00:14s\n",
      "epoch 158| loss: 0.6687  | train_accuracy: 0.72024 | valid_accuracy: 0.7068  |  0:00:14s\n",
      "epoch 159| loss: 0.67012 | train_accuracy: 0.72432 | valid_accuracy: 0.70272 |  0:00:15s\n",
      "epoch 160| loss: 0.65796 | train_accuracy: 0.72585 | valid_accuracy: 0.7068  |  0:00:15s\n",
      "epoch 161| loss: 0.6724  | train_accuracy: 0.72194 | valid_accuracy: 0.7034  |  0:00:15s\n",
      "epoch 162| loss: 0.68397 | train_accuracy: 0.71105 | valid_accuracy: 0.68844 |  0:00:15s\n",
      "epoch 163| loss: 0.66335 | train_accuracy: 0.71633 | valid_accuracy: 0.69116 |  0:00:15s\n",
      "epoch 164| loss: 0.67116 | train_accuracy: 0.72194 | valid_accuracy: 0.70748 |  0:00:15s\n",
      "epoch 165| loss: 0.64854 | train_accuracy: 0.72041 | valid_accuracy: 0.70476 |  0:00:15s\n",
      "epoch 166| loss: 0.66246 | train_accuracy: 0.72024 | valid_accuracy: 0.70136 |  0:00:15s\n",
      "epoch 167| loss: 0.65984 | train_accuracy: 0.71497 | valid_accuracy: 0.70544 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 167 with best_epoch = 142 and best_valid_accuracy = 0.71429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresoft/anaconda3/envs/InternShelter/lib/python3.8/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Tabnet의 경우, epoch 가 일정하지 않기 때문에 loss 그래프의 평균을 알 수 없다.\n",
    "따라서, epoch 수가 가장 많았을 때의 loss 그래프를 시각화 하였다.\n",
    "'''\n",
    "import pytorch_tabnet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터를 나누기 위한 K 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "max_epochs = 0  # To track the maximum epoch count among all k-folds\n",
    "max_epochs_idx = -1  # To track the index of the k-fold with the maximum epoch count\n",
    "\n",
    "dict_train = {}\n",
    "dict_val = {}\n",
    "\n",
    "# K-fold 교차 검증 반복\n",
    "for k, (train_idx, val_idx) in enumerate(kf.split(x_train_50)):\n",
    "    X_train_fold, X_val_fold = x_train_50[train_idx], x_train_50[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_50[train_idx], y_train_50[val_idx]\n",
    "    \n",
    "    # 모델 초기화\n",
    "    clf = TabNetClassifier(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=3e-2),\n",
    "        scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type='sparsemax'\n",
    "    )\n",
    "\n",
    "    # 모델 학습\n",
    "    clf.fit(\n",
    "        X_train=X_train_fold, y_train=y_train_fold,\n",
    "        eval_set=[(X_train_fold, y_train_fold), (X_val_fold, y_val_fold)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=1000, patience=25,\n",
    "        from_unsupervised=unsupervised_model\n",
    "    )\n",
    "    \n",
    "    # Calculate the number of epochs\n",
    "    num_epochs = len(clf.history['loss'])\n",
    "    \n",
    "    # Track the maximum epoch count and its index\n",
    "    if num_epochs > max_epochs:\n",
    "        max_epochs = num_epochs\n",
    "        max_epochs_idx = k\n",
    "    \n",
    "    # fold 별 train, valid accuracy 저장\n",
    "    dict_train[k] = clf.history['train_accuracy']\n",
    "    dict_val[k] = clf.history['valid_accuracy']\n",
    "\n",
    "    \n",
    "# Plot the loss graph for the k-fold with the maximum epoch count\n",
    "plt.plot(dict_train[max_epochs_idx], label='train')\n",
    "plt.plot(dict_val[max_epochs_idx], label='valid')\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.title(f'model accuracy (K={max_epochs_idx}), Max Epochs = {max_epochs}')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:InternShelter]",
   "language": "python",
   "name": "conda-env-InternShelter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
